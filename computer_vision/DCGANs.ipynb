{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mAMLRlgphBh"
   },
   "source": [
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Basics\n",
    "2. GANs Paper Explained\n",
    "3. PyTorch GANs Achitecture\n",
    "4. Implement GANs for Creating MNIST\n",
    "5. [Implement DCGANs for Creating CIFAR10](#fifth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAy-TxEOp49M"
   },
   "source": [
    "# 5. Implement DCGANs for Creating CIFAR10 <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "\n",
    "Deep Convolutional Generative Adversarial Networks (DCGANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xu6b5IQ1whqX"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "ed65e8ac6d314af8b4c4908c8a5d3e0e",
      "97b883069dcc4d80a5200827a618cd82",
      "d3516e3930da478386af4320927303a5",
      "c4c02e6c5cc1442da5f82e4fe8437b14",
      "51bb2203b2c8436985123397a5322832",
      "1022b1f98fb04113adea5ee1c7ddb5d4",
      "747c99e7cd314117b69b5889a16f3c81",
      "8f4015d442564d5f8fdb86eddfdf4eab",
      "8d5e4f090f534819a4c2fa72d821c5d0",
      "d17b5d3c58d4486b80e97259d5745125",
      "554a039878ac4cafb2d238a84d480910"
     ]
    },
    "id": "223PMoDIxyVT",
    "outputId": "5e280a3c-3210-4dea-81ab-3929d7b37afe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:317: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed65e8ac6d314af8b4c4908c8a5d3e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to .\n"
     ]
    }
   ],
   "source": [
    "# Setting hyperparameters\n",
    "batchSize = 64 \n",
    "imageSize = 64 # size of the generated images (64x64).\n",
    "\n",
    "# Creating the transformations\n",
    "transform = transforms.Compose([transforms.Scale(imageSize),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) \n",
    "\n",
    "# Download the training set and apply the transformations.\n",
    "dataset = dset.CIFAR10(root = '.', download = True, transform = transform) \n",
    "# Get the batches of the images of the training set \n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, \n",
    "                                         shuffle = True, num_workers = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WndegZAWxyeC"
   },
   "outputs": [],
   "source": [
    "# The weights_init function takes as input a neural network and initializes all weights.\n",
    "def weights_init(net):\n",
    "    classname = net.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        net.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        net.weight.data.normal_(1.0, 0.02)\n",
    "        net.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bMqG8463FgN"
   },
   "source": [
    "`nn.ConvTranspose2d`: Inverse convolution - CNN takes an image as input and outputs a vector. Inverse CNN takes a vector as input and outputs an image. G uses inverse convolution because the role of it is to generate fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnxqEsRL6cVP",
    "outputId": "b485895c-854e-4794-8907-e1c5dfbf2885"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the generator\n",
    "class G(nn.Module): \n",
    "\n",
    "    def __init__(self): \n",
    "        super(G, self).__init__() \n",
    "        self.main = nn.Sequential( \n",
    "            nn.ConvTranspose2d(in_channels = 100, out_channels = 512, kernel_size = 4,\n",
    "                               stride = 1, padding = 0, bias = False), # inversed convolution\n",
    "            nn.BatchNorm2d(512), # normalize all the features along the dimension of the batch.\n",
    "            nn.ReLU(True), # inplace is true\n",
    "            nn.ConvTranspose2d(in_channels = 512, out_channels = 256, kernel_size = 4,\n",
    "                               stride = 2, padding = 1, bias = False), \n",
    "            nn.BatchNorm2d(256), \n",
    "            nn.ReLU(True), \n",
    "            nn.ConvTranspose2d(in_channels = 256, out_channels = 128, kernel_size = 4,\n",
    "                               stride = 2, padding = 1, bias = False), \n",
    "            nn.BatchNorm2d(128), \n",
    "            nn.ReLU(True), \n",
    "            nn.ConvTranspose2d(in_channels = 128, out_channels = 64, kernel_size = 4,\n",
    "                               stride = 2, padding = 1, bias = False), \n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(True), \n",
    "            nn.ConvTranspose2d(in_channels = 64, out_channels = 3, kernel_size = 4,\n",
    "                               stride = 2, padding = 1, bias = False), \n",
    "            nn.Tanh() # stay between -1 and +1\n",
    "        )\n",
    "\n",
    "    def forward(self, input): \n",
    "        output = self.main(input) \n",
    "        return output \n",
    "\n",
    "# Initiate the generator\n",
    "netG = G() \n",
    "netG.apply(weights_init) # initialize all the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWzQR5377wko"
   },
   "source": [
    "`nn.LeakyReLU`: $f(x) = \\max(0,x) + negative\\_slope * \\min(0,x)$. D works better with LeakyReLU than a normal ReLU.\n",
    "\n",
    "Note that the size of output of each layer in D is getting larger, as opposite to the sizes of output in each layer of G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eywqpwZ89IcA",
    "outputId": "6cd7f18c-c98c-4d6c-f729-79ed248a1576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the discriminator\n",
    "class D(nn.Module): \n",
    "\n",
    "    def __init__(self): \n",
    "        super(D, self).__init__()\n",
    "        self.main = nn.Sequential( \n",
    "            nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 4, stride = 2, padding = 1, bias = False), # input channels match the output of the generator\n",
    "            nn.LeakyReLU(0.2, inplace = True), # negative slope = 0.2, \n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(128), # normalize all the features along the dimension of the batch.\n",
    "            nn.LeakyReLU(0.2, inplace = True), \n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace = True), \n",
    "            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace = True), \n",
    "            nn.Conv2d(in_channels = 512, out_channels = 1, kernel_size = 4, stride = 1, padding = 0, bias = False),\n",
    "            nn.Sigmoid() #  stay between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input): \n",
    "        output = self.main(input) \n",
    "        return output.view(-1) \n",
    "\n",
    "# Initiate the discriminator\n",
    "netD = D() \n",
    "netD.apply(weights_init) # initialize all the weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaZUZsiCj4en"
   },
   "source": [
    "The training implementation contains two steps:\n",
    "\n",
    "1. To update the weights of the D: Train the D by giving it a real image and set the target to one (real), and then do another training by giving it a fake image and set the target to zero (fake). Some of the fake images are created by generator.\n",
    "\n",
    "2. To update the weights of the G: Feed the fake image to the D to get an output (a value between 0 and 1). Set a new target to 1 (real), and then compute the loss between the output of the D and the new target (always 1). We will backpropagate this error into the G.\n",
    "\n",
    "\n",
    "Note:\n",
    "\n",
    "* `fake` is a torch variable because a output of torch model is also a torch variable. So it contains not only the tensor of teh predictions (numbers between 0 and 1), but also the gradients. However, we are not going to use this gradient after back prop the error back to the D. We absolutely don't care of the gradient of the output with respect to the weights of G, it's not a part of the considerations in stochastic gradient descent. So we detach the gradients of the `fake` variable. This will save some memory and speed up the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEAY3mbHpfb6",
    "outputId": "3b2d4128-d35e-45ea-8273-4e9975a7a08b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "[6/25][215/782] Loss_D: 0.2558 Loss_G: 5.0468\n",
      "[6/25][216/782] Loss_D: 0.1389 Loss_G: 4.4549\n",
      "[6/25][217/782] Loss_D: 0.1857 Loss_G: 3.3671\n",
      "[6/25][218/782] Loss_D: 0.0967 Loss_G: 3.8697\n",
      "[6/25][219/782] Loss_D: 1.0872 Loss_G: 8.7437\n",
      "[6/25][220/782] Loss_D: 2.3229 Loss_G: 2.2508\n",
      "[6/25][221/782] Loss_D: 0.7488 Loss_G: 3.3362\n",
      "[6/25][222/782] Loss_D: 0.7358 Loss_G: 2.3009\n",
      "[6/25][223/782] Loss_D: 0.8468 Loss_G: 6.8381\n",
      "[6/25][224/782] Loss_D: 2.1058 Loss_G: 0.7371\n",
      "[6/25][225/782] Loss_D: 1.9039 Loss_G: 7.5653\n",
      "[6/25][226/782] Loss_D: 0.9998 Loss_G: 2.2322\n",
      "[6/25][227/782] Loss_D: 0.5030 Loss_G: 3.9101\n",
      "[6/25][228/782] Loss_D: 0.3710 Loss_G: 3.6902\n",
      "[6/25][229/782] Loss_D: 0.2724 Loss_G: 3.7632\n",
      "[6/25][230/782] Loss_D: 0.2961 Loss_G: 4.1897\n",
      "[6/25][231/782] Loss_D: 0.4764 Loss_G: 2.6042\n",
      "[6/25][232/782] Loss_D: 0.3858 Loss_G: 3.9581\n",
      "[6/25][233/782] Loss_D: 0.2632 Loss_G: 4.1515\n",
      "[6/25][234/782] Loss_D: 0.3514 Loss_G: 3.8092\n",
      "[6/25][235/782] Loss_D: 0.2664 Loss_G: 5.2569\n",
      "[6/25][236/782] Loss_D: 0.6768 Loss_G: 1.9626\n",
      "[6/25][237/782] Loss_D: 0.6832 Loss_G: 6.6095\n",
      "[6/25][238/782] Loss_D: 0.5305 Loss_G: 4.0632\n",
      "[6/25][239/782] Loss_D: 0.1362 Loss_G: 3.4144\n",
      "[6/25][240/782] Loss_D: 0.2378 Loss_G: 3.4921\n",
      "[6/25][241/782] Loss_D: 0.2009 Loss_G: 4.3762\n",
      "[6/25][242/782] Loss_D: 0.2780 Loss_G: 4.2963\n",
      "[6/25][243/782] Loss_D: 0.2241 Loss_G: 3.9529\n",
      "[6/25][244/782] Loss_D: 0.1386 Loss_G: 4.0196\n",
      "[6/25][245/782] Loss_D: 0.1373 Loss_G: 4.4450\n",
      "[6/25][246/782] Loss_D: 0.1931 Loss_G: 3.2910\n",
      "[6/25][247/782] Loss_D: 0.1381 Loss_G: 4.1127\n",
      "[6/25][248/782] Loss_D: 0.1842 Loss_G: 5.2710\n",
      "[6/25][249/782] Loss_D: 0.1494 Loss_G: 4.8971\n",
      "[6/25][250/782] Loss_D: 0.1645 Loss_G: 3.6170\n",
      "[6/25][251/782] Loss_D: 0.0449 Loss_G: 3.9031\n",
      "[6/25][252/782] Loss_D: 0.1142 Loss_G: 4.8413\n",
      "[6/25][253/782] Loss_D: 0.1091 Loss_G: 5.3209\n",
      "[6/25][254/782] Loss_D: 0.0591 Loss_G: 5.4668\n",
      "[6/25][255/782] Loss_D: 0.0453 Loss_G: 5.4465\n",
      "[6/25][256/782] Loss_D: 0.0829 Loss_G: 4.0194\n",
      "[6/25][257/782] Loss_D: 0.1230 Loss_G: 4.3323\n",
      "[6/25][258/782] Loss_D: 0.0510 Loss_G: 4.9433\n",
      "[6/25][259/782] Loss_D: 0.0878 Loss_G: 4.3534\n",
      "[6/25][260/782] Loss_D: 0.0577 Loss_G: 4.8405\n",
      "[6/25][261/782] Loss_D: 0.1877 Loss_G: 2.9635\n",
      "[6/25][262/782] Loss_D: 0.1122 Loss_G: 3.8365\n",
      "[6/25][263/782] Loss_D: 0.1311 Loss_G: 4.2907\n",
      "[6/25][264/782] Loss_D: 0.0417 Loss_G: 5.2404\n",
      "[6/25][265/782] Loss_D: 0.0833 Loss_G: 4.3373\n",
      "[6/25][266/782] Loss_D: 0.0598 Loss_G: 4.4511\n",
      "[6/25][267/782] Loss_D: 0.0686 Loss_G: 4.4811\n",
      "[6/25][268/782] Loss_D: 0.0586 Loss_G: 4.5067\n",
      "[6/25][269/782] Loss_D: 0.1007 Loss_G: 4.0846\n",
      "[6/25][270/782] Loss_D: 0.0360 Loss_G: 5.1045\n",
      "[6/25][271/782] Loss_D: 0.0637 Loss_G: 4.3526\n",
      "[6/25][272/782] Loss_D: 0.0422 Loss_G: 4.5435\n",
      "[6/25][273/782] Loss_D: 0.0608 Loss_G: 4.4260\n",
      "[6/25][274/782] Loss_D: 0.0509 Loss_G: 4.6748\n",
      "[6/25][275/782] Loss_D: 0.0620 Loss_G: 4.6667\n",
      "[6/25][276/782] Loss_D: 0.0589 Loss_G: 5.0869\n",
      "[6/25][277/782] Loss_D: 0.0314 Loss_G: 4.5815\n",
      "[6/25][278/782] Loss_D: 0.0729 Loss_G: 4.5189\n",
      "[6/25][279/782] Loss_D: 0.0544 Loss_G: 5.3396\n",
      "[6/25][280/782] Loss_D: 0.1247 Loss_G: 4.7177\n",
      "[6/25][281/782] Loss_D: 0.0508 Loss_G: 5.7045\n",
      "[6/25][282/782] Loss_D: 0.0931 Loss_G: 3.5052\n",
      "[6/25][283/782] Loss_D: 0.0323 Loss_G: 4.7096\n",
      "[6/25][284/782] Loss_D: 0.0288 Loss_G: 4.5533\n",
      "[6/25][285/782] Loss_D: 0.0235 Loss_G: 4.8814\n",
      "[6/25][286/782] Loss_D: 0.2197 Loss_G: 7.3234\n",
      "[6/25][287/782] Loss_D: 0.8509 Loss_G: 5.1390\n",
      "[6/25][288/782] Loss_D: 0.7039 Loss_G: 0.5835\n",
      "[6/25][289/782] Loss_D: 4.1409 Loss_G: 11.3286\n",
      "[6/25][290/782] Loss_D: 7.2557 Loss_G: 3.8093\n",
      "[6/25][291/782] Loss_D: 1.5114 Loss_G: 0.0706\n",
      "[6/25][292/782] Loss_D: 3.3252 Loss_G: 2.3827\n",
      "[6/25][293/782] Loss_D: 0.7354 Loss_G: 4.4927\n",
      "[6/25][294/782] Loss_D: 1.7959 Loss_G: 1.1782\n",
      "[6/25][295/782] Loss_D: 1.1377 Loss_G: 1.5213\n",
      "[6/25][296/782] Loss_D: 0.9117 Loss_G: 3.2294\n",
      "[6/25][297/782] Loss_D: 1.3390 Loss_G: 1.0466\n",
      "[6/25][298/782] Loss_D: 0.7431 Loss_G: 2.3315\n",
      "[6/25][299/782] Loss_D: 0.7681 Loss_G: 2.2611\n",
      "[6/25][300/782] Loss_D: 0.8057 Loss_G: 1.6343\n",
      "[6/25][301/782] Loss_D: 0.7875 Loss_G: 1.9250\n",
      "[6/25][302/782] Loss_D: 0.8798 Loss_G: 1.6989\n",
      "[6/25][303/782] Loss_D: 0.7938 Loss_G: 1.8899\n",
      "[6/25][304/782] Loss_D: 0.9434 Loss_G: 1.7339\n",
      "[6/25][305/782] Loss_D: 0.8578 Loss_G: 1.8950\n",
      "[6/25][306/782] Loss_D: 1.0348 Loss_G: 1.7496\n",
      "[6/25][307/782] Loss_D: 0.9622 Loss_G: 1.6191\n",
      "[6/25][308/782] Loss_D: 1.2239 Loss_G: 2.0430\n",
      "[6/25][309/782] Loss_D: 1.0652 Loss_G: 1.8982\n",
      "[6/25][310/782] Loss_D: 0.8095 Loss_G: 1.7208\n",
      "[6/25][311/782] Loss_D: 0.8411 Loss_G: 1.7918\n",
      "[6/25][312/782] Loss_D: 1.0004 Loss_G: 2.3825\n",
      "[6/25][313/782] Loss_D: 1.0091 Loss_G: 1.1095\n",
      "[6/25][314/782] Loss_D: 0.8520 Loss_G: 2.9717\n",
      "[6/25][315/782] Loss_D: 0.8935 Loss_G: 1.4564\n",
      "[6/25][316/782] Loss_D: 1.0315 Loss_G: 2.3391\n",
      "[6/25][317/782] Loss_D: 0.8777 Loss_G: 1.3999\n",
      "[6/25][318/782] Loss_D: 0.9124 Loss_G: 2.5558\n",
      "[6/25][319/782] Loss_D: 0.7260 Loss_G: 1.9052\n",
      "[6/25][320/782] Loss_D: 0.9910 Loss_G: 1.7189\n",
      "[6/25][321/782] Loss_D: 0.9251 Loss_G: 2.3268\n",
      "[6/25][322/782] Loss_D: 1.0344 Loss_G: 1.0224\n",
      "[6/25][323/782] Loss_D: 1.3461 Loss_G: 4.1028\n",
      "[6/25][324/782] Loss_D: 1.4237 Loss_G: 1.1410\n",
      "[6/25][325/782] Loss_D: 0.9038 Loss_G: 2.4102\n",
      "[6/25][326/782] Loss_D: 0.7619 Loss_G: 2.2770\n",
      "[6/25][327/782] Loss_D: 0.6515 Loss_G: 1.8829\n",
      "[6/25][328/782] Loss_D: 0.6981 Loss_G: 3.1865\n",
      "[6/25][329/782] Loss_D: 0.8393 Loss_G: 1.9238\n",
      "[6/25][330/782] Loss_D: 1.0308 Loss_G: 2.6944\n",
      "[6/25][331/782] Loss_D: 0.9648 Loss_G: 1.3953\n",
      "[6/25][332/782] Loss_D: 1.0313 Loss_G: 2.9848\n",
      "[6/25][333/782] Loss_D: 0.9839 Loss_G: 1.9815\n",
      "[6/25][334/782] Loss_D: 1.0211 Loss_G: 1.8901\n",
      "[6/25][335/782] Loss_D: 0.8973 Loss_G: 2.2703\n",
      "[6/25][336/782] Loss_D: 1.0736 Loss_G: 2.3787\n",
      "[6/25][337/782] Loss_D: 0.9267 Loss_G: 1.4101\n",
      "[6/25][338/782] Loss_D: 1.1665 Loss_G: 2.9424\n",
      "[6/25][339/782] Loss_D: 1.1753 Loss_G: 0.8854\n",
      "[6/25][340/782] Loss_D: 1.3992 Loss_G: 4.0986\n",
      "[6/25][341/782] Loss_D: 1.5842 Loss_G: 0.5785\n",
      "[6/25][342/782] Loss_D: 1.4760 Loss_G: 4.3957\n",
      "[6/25][343/782] Loss_D: 1.1495 Loss_G: 0.6565\n",
      "[6/25][344/782] Loss_D: 1.1488 Loss_G: 4.5948\n",
      "[6/25][345/782] Loss_D: 1.1221 Loss_G: 1.3544\n",
      "[6/25][346/782] Loss_D: 0.7212 Loss_G: 2.4650\n",
      "[6/25][347/782] Loss_D: 0.8549 Loss_G: 4.1454\n",
      "[6/25][348/782] Loss_D: 1.6914 Loss_G: 0.9478\n",
      "[6/25][349/782] Loss_D: 1.0040 Loss_G: 2.7632\n",
      "[6/25][350/782] Loss_D: 0.7801 Loss_G: 2.7504\n",
      "[6/25][351/782] Loss_D: 1.1252 Loss_G: 0.9956\n",
      "[6/25][352/782] Loss_D: 1.5058 Loss_G: 3.8409\n",
      "[6/25][353/782] Loss_D: 1.0586 Loss_G: 1.5813\n",
      "[6/25][354/782] Loss_D: 0.8598 Loss_G: 2.9718\n",
      "[6/25][355/782] Loss_D: 0.8622 Loss_G: 1.6346\n",
      "[6/25][356/782] Loss_D: 1.3110 Loss_G: 3.1878\n",
      "[6/25][357/782] Loss_D: 1.4771 Loss_G: 1.0112\n",
      "[6/25][358/782] Loss_D: 1.3949 Loss_G: 3.8440\n",
      "[6/25][359/782] Loss_D: 1.3341 Loss_G: 1.1965\n",
      "[6/25][360/782] Loss_D: 1.2956 Loss_G: 3.8791\n",
      "[6/25][361/782] Loss_D: 0.9334 Loss_G: 1.9744\n",
      "[6/25][362/782] Loss_D: 0.7330 Loss_G: 2.2895\n",
      "[6/25][363/782] Loss_D: 0.7464 Loss_G: 2.9014\n",
      "[6/25][364/782] Loss_D: 1.3465 Loss_G: 1.2111\n",
      "[6/25][365/782] Loss_D: 1.1308 Loss_G: 3.0178\n",
      "[6/25][366/782] Loss_D: 1.0279 Loss_G: 1.8438\n",
      "[6/25][367/782] Loss_D: 1.0353 Loss_G: 2.5994\n",
      "[6/25][368/782] Loss_D: 0.9108 Loss_G: 2.1691\n",
      "[6/25][369/782] Loss_D: 0.9988 Loss_G: 2.0076\n",
      "[6/25][370/782] Loss_D: 0.7994 Loss_G: 2.6295\n",
      "[6/25][371/782] Loss_D: 0.8751 Loss_G: 2.7041\n",
      "[6/25][372/782] Loss_D: 0.9557 Loss_G: 1.7797\n",
      "[6/25][373/782] Loss_D: 0.9860 Loss_G: 1.7236\n",
      "[6/25][374/782] Loss_D: 0.7846 Loss_G: 3.7219\n",
      "[6/25][375/782] Loss_D: 0.8087 Loss_G: 2.1005\n",
      "[6/25][376/782] Loss_D: 0.5456 Loss_G: 1.8568\n",
      "[6/25][377/782] Loss_D: 1.0459 Loss_G: 3.6021\n",
      "[6/25][378/782] Loss_D: 1.0037 Loss_G: 1.6616\n",
      "[6/25][379/782] Loss_D: 0.9799 Loss_G: 2.5229\n",
      "[6/25][380/782] Loss_D: 0.6442 Loss_G: 2.9592\n",
      "[6/25][381/782] Loss_D: 0.7520 Loss_G: 1.8601\n",
      "[6/25][382/782] Loss_D: 0.9352 Loss_G: 3.4280\n",
      "[6/25][383/782] Loss_D: 0.8870 Loss_G: 1.3407\n",
      "[6/25][384/782] Loss_D: 0.7096 Loss_G: 2.9758\n",
      "[6/25][385/782] Loss_D: 0.6033 Loss_G: 1.9392\n",
      "[6/25][386/782] Loss_D: 0.8250 Loss_G: 4.1914\n",
      "[6/25][387/782] Loss_D: 0.5559 Loss_G: 2.8465\n",
      "[6/25][388/782] Loss_D: 0.4211 Loss_G: 2.0911\n",
      "[6/25][389/782] Loss_D: 0.5821 Loss_G: 3.5944\n",
      "[6/25][390/782] Loss_D: 0.9146 Loss_G: 1.4975\n",
      "[6/25][391/782] Loss_D: 0.8055 Loss_G: 2.3672\n",
      "[6/25][392/782] Loss_D: 0.6200 Loss_G: 3.4403\n",
      "[6/25][393/782] Loss_D: 0.9241 Loss_G: 1.2591\n",
      "[6/25][394/782] Loss_D: 1.0809 Loss_G: 3.5715\n",
      "[6/25][395/782] Loss_D: 1.4412 Loss_G: 0.6362\n",
      "[6/25][396/782] Loss_D: 1.3200 Loss_G: 3.5847\n",
      "[6/25][397/782] Loss_D: 0.5858 Loss_G: 2.8668\n",
      "[6/25][398/782] Loss_D: 0.6961 Loss_G: 1.4250\n",
      "[6/25][399/782] Loss_D: 0.8837 Loss_G: 3.6630\n",
      "[6/25][400/782] Loss_D: 1.0304 Loss_G: 1.5998\n",
      "[6/25][401/782] Loss_D: 0.7643 Loss_G: 2.9404\n",
      "[6/25][402/782] Loss_D: 0.9474 Loss_G: 1.8314\n",
      "[6/25][403/782] Loss_D: 0.6678 Loss_G: 2.4798\n",
      "[6/25][404/782] Loss_D: 0.5405 Loss_G: 2.6006\n",
      "[6/25][405/782] Loss_D: 0.7287 Loss_G: 2.0798\n",
      "[6/25][406/782] Loss_D: 0.7960 Loss_G: 3.1474\n",
      "[6/25][407/782] Loss_D: 0.5848 Loss_G: 2.1738\n",
      "[6/25][408/782] Loss_D: 0.6919 Loss_G: 2.2605\n",
      "[6/25][409/782] Loss_D: 0.6499 Loss_G: 2.4714\n",
      "[6/25][410/782] Loss_D: 0.5073 Loss_G: 2.7222\n",
      "[6/25][411/782] Loss_D: 0.6005 Loss_G: 1.9235\n",
      "[6/25][412/782] Loss_D: 0.6371 Loss_G: 3.0908\n",
      "[6/25][413/782] Loss_D: 0.5154 Loss_G: 2.6340\n",
      "[6/25][414/782] Loss_D: 0.5716 Loss_G: 1.8263\n",
      "[6/25][415/782] Loss_D: 0.6465 Loss_G: 3.3045\n",
      "[6/25][416/782] Loss_D: 0.6785 Loss_G: 1.9530\n",
      "[6/25][417/782] Loss_D: 0.4655 Loss_G: 2.3671\n",
      "[6/25][418/782] Loss_D: 0.3810 Loss_G: 2.6822\n",
      "[6/25][419/782] Loss_D: 0.3806 Loss_G: 2.5742\n",
      "[6/25][420/782] Loss_D: 0.5534 Loss_G: 2.3240\n",
      "[6/25][421/782] Loss_D: 0.4072 Loss_G: 2.6751\n",
      "[6/25][422/782] Loss_D: 0.4496 Loss_G: 2.6394\n",
      "[6/25][423/782] Loss_D: 0.5697 Loss_G: 2.3860\n",
      "[6/25][424/782] Loss_D: 0.4381 Loss_G: 2.9803\n",
      "[6/25][425/782] Loss_D: 0.5184 Loss_G: 2.2675\n",
      "[6/25][426/782] Loss_D: 0.3814 Loss_G: 2.7828\n",
      "[6/25][427/782] Loss_D: 0.4051 Loss_G: 2.5996\n",
      "[6/25][428/782] Loss_D: 0.5047 Loss_G: 3.0112\n",
      "[6/25][429/782] Loss_D: 0.4796 Loss_G: 1.7986\n",
      "[6/25][430/782] Loss_D: 0.5836 Loss_G: 3.6541\n",
      "[6/25][431/782] Loss_D: 0.7647 Loss_G: 1.1116\n",
      "[6/25][432/782] Loss_D: 0.8101 Loss_G: 4.4955\n",
      "[6/25][433/782] Loss_D: 0.8426 Loss_G: 0.9790\n",
      "[6/25][434/782] Loss_D: 1.2373 Loss_G: 4.9799\n",
      "[6/25][435/782] Loss_D: 1.2341 Loss_G: 0.2359\n",
      "[6/25][436/782] Loss_D: 2.4198 Loss_G: 7.3829\n",
      "[6/25][437/782] Loss_D: 3.4446 Loss_G: 2.1107\n",
      "[6/25][438/782] Loss_D: 0.5981 Loss_G: 1.8867\n",
      "[6/25][439/782] Loss_D: 0.6180 Loss_G: 3.4210\n",
      "[6/25][440/782] Loss_D: 0.6322 Loss_G: 2.2848\n",
      "[6/25][441/782] Loss_D: 0.6839 Loss_G: 2.5446\n",
      "[6/25][442/782] Loss_D: 0.7166 Loss_G: 2.3452\n",
      "[6/25][443/782] Loss_D: 0.7291 Loss_G: 2.2198\n",
      "[6/25][444/782] Loss_D: 0.6359 Loss_G: 2.6354\n",
      "[6/25][445/782] Loss_D: 0.8255 Loss_G: 1.6388\n",
      "[6/25][446/782] Loss_D: 0.5665 Loss_G: 2.8227\n",
      "[6/25][447/782] Loss_D: 0.4008 Loss_G: 3.0089\n",
      "[6/25][448/782] Loss_D: 0.3324 Loss_G: 2.7253\n",
      "[6/25][449/782] Loss_D: 0.3852 Loss_G: 2.9282\n",
      "[6/25][450/782] Loss_D: 0.5892 Loss_G: 1.9540\n",
      "[6/25][451/782] Loss_D: 0.4606 Loss_G: 3.6699\n",
      "[6/25][452/782] Loss_D: 0.3329 Loss_G: 3.1718\n",
      "[6/25][453/782] Loss_D: 0.3455 Loss_G: 2.4962\n",
      "[6/25][454/782] Loss_D: 0.4580 Loss_G: 2.7374\n",
      "[6/25][455/782] Loss_D: 0.3174 Loss_G: 2.8574\n",
      "[6/25][456/782] Loss_D: 0.3513 Loss_G: 2.9026\n",
      "[6/25][457/782] Loss_D: 0.3912 Loss_G: 2.7188\n",
      "[6/25][458/782] Loss_D: 0.3163 Loss_G: 2.5518\n",
      "[6/25][459/782] Loss_D: 0.4393 Loss_G: 3.5026\n",
      "[6/25][460/782] Loss_D: 0.3243 Loss_G: 2.9095\n",
      "[6/25][461/782] Loss_D: 0.3553 Loss_G: 2.3261\n",
      "[6/25][462/782] Loss_D: 0.2844 Loss_G: 3.4865\n",
      "[6/25][463/782] Loss_D: 0.2019 Loss_G: 3.6017\n",
      "[6/25][464/782] Loss_D: 0.3279 Loss_G: 2.4051\n",
      "[6/25][465/782] Loss_D: 0.3370 Loss_G: 3.8758\n",
      "[6/25][466/782] Loss_D: 0.3698 Loss_G: 2.6656\n",
      "[6/25][467/782] Loss_D: 0.2057 Loss_G: 3.1512\n",
      "[6/25][468/782] Loss_D: 0.1739 Loss_G: 3.9493\n",
      "[6/25][469/782] Loss_D: 0.3890 Loss_G: 2.6132\n",
      "[6/25][470/782] Loss_D: 0.2861 Loss_G: 2.4541\n",
      "[6/25][471/782] Loss_D: 0.3133 Loss_G: 4.5928\n",
      "[6/25][472/782] Loss_D: 0.2074 Loss_G: 3.7148\n",
      "[6/25][473/782] Loss_D: 0.0965 Loss_G: 3.4662\n",
      "[6/25][474/782] Loss_D: 0.2120 Loss_G: 3.6927\n",
      "[6/25][475/782] Loss_D: 0.1709 Loss_G: 3.5038\n",
      "[6/25][476/782] Loss_D: 0.1508 Loss_G: 4.2247\n",
      "[6/25][477/782] Loss_D: 0.2290 Loss_G: 3.0241\n",
      "[6/25][478/782] Loss_D: 0.6034 Loss_G: 8.2738\n",
      "[6/25][479/782] Loss_D: 2.5181 Loss_G: 0.1325\n",
      "[6/25][480/782] Loss_D: 2.4461 Loss_G: 9.4363\n",
      "[6/25][481/782] Loss_D: 5.5317 Loss_G: 1.6675\n",
      "[6/25][482/782] Loss_D: 1.2077 Loss_G: 1.0612\n",
      "[6/25][483/782] Loss_D: 1.0858 Loss_G: 4.7115\n",
      "[6/25][484/782] Loss_D: 1.7204 Loss_G: 0.4427\n",
      "[6/25][485/782] Loss_D: 1.7830 Loss_G: 4.8054\n",
      "[6/25][486/782] Loss_D: 1.0268 Loss_G: 2.1660\n",
      "[6/25][487/782] Loss_D: 0.6906 Loss_G: 2.5938\n",
      "[6/25][488/782] Loss_D: 0.9331 Loss_G: 2.8236\n",
      "[6/25][489/782] Loss_D: 0.7747 Loss_G: 2.3980\n",
      "[6/25][490/782] Loss_D: 0.6762 Loss_G: 2.9536\n",
      "[6/25][491/782] Loss_D: 0.6966 Loss_G: 3.4116\n",
      "[6/25][492/782] Loss_D: 0.6825 Loss_G: 2.1894\n",
      "[6/25][493/782] Loss_D: 0.6985 Loss_G: 6.3299\n",
      "[6/25][494/782] Loss_D: 0.6974 Loss_G: 3.9230\n",
      "[6/25][495/782] Loss_D: 0.2923 Loss_G: 3.0634\n",
      "[6/25][496/782] Loss_D: 0.2851 Loss_G: 4.0977\n",
      "[6/25][497/782] Loss_D: 0.2495 Loss_G: 3.5199\n",
      "[6/25][498/782] Loss_D: 0.2825 Loss_G: 4.4458\n",
      "[6/25][499/782] Loss_D: 0.1474 Loss_G: 4.2865\n",
      "[6/25][500/782] Loss_D: 0.5079 Loss_G: 1.7734\n",
      "[6/25][501/782] Loss_D: 0.5962 Loss_G: 5.6691\n",
      "[6/25][502/782] Loss_D: 0.2744 Loss_G: 4.6397\n",
      "[6/25][503/782] Loss_D: 0.1835 Loss_G: 3.2107\n",
      "[6/25][504/782] Loss_D: 0.2185 Loss_G: 3.9028\n",
      "[6/25][505/782] Loss_D: 0.1450 Loss_G: 4.1412\n",
      "[6/25][506/782] Loss_D: 0.1968 Loss_G: 3.8868\n",
      "[6/25][507/782] Loss_D: 0.1415 Loss_G: 3.9069\n",
      "[6/25][508/782] Loss_D: 0.2424 Loss_G: 3.3448\n",
      "[6/25][509/782] Loss_D: 0.1804 Loss_G: 4.6692\n",
      "[6/25][510/782] Loss_D: 0.1377 Loss_G: 4.7197\n",
      "[6/25][511/782] Loss_D: 0.2355 Loss_G: 3.2415\n",
      "[6/25][512/782] Loss_D: 0.1344 Loss_G: 4.2452\n",
      "[6/25][513/782] Loss_D: 0.1141 Loss_G: 5.3421\n",
      "[6/25][514/782] Loss_D: 0.0835 Loss_G: 4.8380\n",
      "[6/25][515/782] Loss_D: 0.0695 Loss_G: 4.6358\n",
      "[6/25][516/782] Loss_D: 0.0360 Loss_G: 4.8170\n",
      "[6/25][517/782] Loss_D: 0.0792 Loss_G: 4.2355\n",
      "[6/25][518/782] Loss_D: 0.0564 Loss_G: 4.6770\n",
      "[6/25][519/782] Loss_D: 0.1277 Loss_G: 4.5060\n",
      "[6/25][520/782] Loss_D: 0.0833 Loss_G: 4.2323\n",
      "[6/25][521/782] Loss_D: 0.0741 Loss_G: 4.1820\n",
      "[6/25][522/782] Loss_D: 0.2222 Loss_G: 4.3400\n",
      "[6/25][523/782] Loss_D: 0.0859 Loss_G: 4.3900\n",
      "[6/25][524/782] Loss_D: 0.0377 Loss_G: 4.8224\n",
      "[6/25][525/782] Loss_D: 0.0630 Loss_G: 4.6574\n",
      "[6/25][526/782] Loss_D: 0.0414 Loss_G: 4.2844\n",
      "[6/25][527/782] Loss_D: 0.1107 Loss_G: 4.1498\n",
      "[6/25][528/782] Loss_D: 0.0809 Loss_G: 4.2791\n",
      "[6/25][529/782] Loss_D: 0.0854 Loss_G: 4.6454\n",
      "[6/25][530/782] Loss_D: 0.0959 Loss_G: 4.2547\n",
      "[6/25][531/782] Loss_D: 0.0574 Loss_G: 4.5181\n",
      "[6/25][532/782] Loss_D: 0.1099 Loss_G: 4.2901\n",
      "[6/25][533/782] Loss_D: 0.1928 Loss_G: 5.8098\n",
      "[6/25][534/782] Loss_D: 0.1438 Loss_G: 6.0829\n",
      "[6/25][535/782] Loss_D: 0.0736 Loss_G: 4.2689\n",
      "[6/25][536/782] Loss_D: 0.0797 Loss_G: 3.9649\n",
      "[6/25][537/782] Loss_D: 0.0753 Loss_G: 4.5094\n",
      "[6/25][538/782] Loss_D: 0.0328 Loss_G: 5.3738\n",
      "[6/25][539/782] Loss_D: 0.1567 Loss_G: 5.3091\n",
      "[6/25][540/782] Loss_D: 0.4128 Loss_G: 3.3144\n",
      "[6/25][541/782] Loss_D: 0.0323 Loss_G: 3.3652\n",
      "[6/25][542/782] Loss_D: 0.1463 Loss_G: 6.5167\n",
      "[6/25][543/782] Loss_D: 0.2150 Loss_G: 6.5381\n",
      "[6/25][544/782] Loss_D: 0.7566 Loss_G: 5.6611\n",
      "[6/25][545/782] Loss_D: 0.2536 Loss_G: 1.2263\n",
      "[6/25][546/782] Loss_D: 1.7161 Loss_G: 10.5124\n",
      "[6/25][547/782] Loss_D: 5.2647 Loss_G: 2.4941\n",
      "[6/25][548/782] Loss_D: 0.7938 Loss_G: 0.4911\n",
      "[6/25][549/782] Loss_D: 1.9748 Loss_G: 4.9838\n",
      "[6/25][550/782] Loss_D: 1.5344 Loss_G: 1.2907\n",
      "[6/25][551/782] Loss_D: 0.8305 Loss_G: 2.5817\n",
      "[6/25][552/782] Loss_D: 0.6775 Loss_G: 2.9865\n",
      "[6/25][553/782] Loss_D: 0.6868 Loss_G: 2.0017\n",
      "[6/25][554/782] Loss_D: 0.9098 Loss_G: 2.0527\n",
      "[6/25][555/782] Loss_D: 0.8745 Loss_G: 2.4541\n",
      "[6/25][556/782] Loss_D: 0.9210 Loss_G: 1.5813\n",
      "[6/25][557/782] Loss_D: 1.1384 Loss_G: 2.1537\n",
      "[6/25][558/782] Loss_D: 0.9535 Loss_G: 2.3415\n",
      "[6/25][559/782] Loss_D: 0.9732 Loss_G: 1.1090\n",
      "[6/25][560/782] Loss_D: 1.0759 Loss_G: 4.0742\n",
      "[6/25][561/782] Loss_D: 1.1770 Loss_G: 1.7876\n",
      "[6/25][562/782] Loss_D: 0.6550 Loss_G: 1.5811\n",
      "[6/25][563/782] Loss_D: 0.6936 Loss_G: 3.2620\n",
      "[6/25][564/782] Loss_D: 0.6539 Loss_G: 2.7095\n",
      "[6/25][565/782] Loss_D: 0.6309 Loss_G: 2.2986\n",
      "[6/25][566/782] Loss_D: 0.4802 Loss_G: 2.0516\n",
      "[6/25][567/782] Loss_D: 1.0085 Loss_G: 3.3130\n",
      "[6/25][568/782] Loss_D: 0.7422 Loss_G: 2.2584\n",
      "[6/25][569/782] Loss_D: 0.5474 Loss_G: 2.2664\n",
      "[6/25][570/782] Loss_D: 0.6380 Loss_G: 2.3748\n",
      "[6/25][571/782] Loss_D: 0.4129 Loss_G: 3.0542\n",
      "[6/25][572/782] Loss_D: 0.7388 Loss_G: 1.8777\n",
      "[6/25][573/782] Loss_D: 0.7826 Loss_G: 3.0335\n",
      "[6/25][574/782] Loss_D: 0.6846 Loss_G: 1.7024\n",
      "[6/25][575/782] Loss_D: 0.9042 Loss_G: 4.6190\n",
      "[6/25][576/782] Loss_D: 0.4978 Loss_G: 3.1414\n",
      "[6/25][577/782] Loss_D: 0.6004 Loss_G: 1.3322\n",
      "[6/25][578/782] Loss_D: 0.9116 Loss_G: 4.5499\n",
      "[6/25][579/782] Loss_D: 0.4213 Loss_G: 3.0347\n",
      "[6/25][580/782] Loss_D: 0.4818 Loss_G: 1.6786\n",
      "[6/25][581/782] Loss_D: 0.6455 Loss_G: 4.0824\n",
      "[6/25][582/782] Loss_D: 0.4137 Loss_G: 2.9493\n",
      "[6/25][583/782] Loss_D: 0.4700 Loss_G: 2.6171\n",
      "[6/25][584/782] Loss_D: 0.3791 Loss_G: 3.4628\n",
      "[6/25][585/782] Loss_D: 0.4859 Loss_G: 2.1117\n",
      "[6/25][586/782] Loss_D: 0.7028 Loss_G: 5.3970\n",
      "[6/25][587/782] Loss_D: 0.7051 Loss_G: 1.8861\n",
      "[6/25][588/782] Loss_D: 0.6972 Loss_G: 5.5008\n",
      "[6/25][589/782] Loss_D: 0.1755 Loss_G: 5.3102\n",
      "[6/25][590/782] Loss_D: 0.2477 Loss_G: 2.8953\n",
      "[6/25][591/782] Loss_D: 0.3481 Loss_G: 5.0250\n",
      "[6/25][592/782] Loss_D: 0.2839 Loss_G: 3.8168\n",
      "[6/25][593/782] Loss_D: 0.1132 Loss_G: 3.5353\n",
      "[6/25][594/782] Loss_D: 0.1744 Loss_G: 4.7951\n",
      "[6/25][595/782] Loss_D: 0.1341 Loss_G: 4.4911\n",
      "[6/25][596/782] Loss_D: 0.1226 Loss_G: 3.6640\n",
      "[6/25][597/782] Loss_D: 0.2138 Loss_G: 4.4473\n",
      "[6/25][598/782] Loss_D: 0.1239 Loss_G: 4.3070\n",
      "[6/25][599/782] Loss_D: 0.0879 Loss_G: 3.7027\n",
      "[6/25][600/782] Loss_D: 0.0695 Loss_G: 4.2190\n",
      "[6/25][601/782] Loss_D: 0.0657 Loss_G: 4.5487\n",
      "[6/25][602/782] Loss_D: 0.0658 Loss_G: 4.3571\n",
      "[6/25][603/782] Loss_D: 0.1581 Loss_G: 4.3772\n",
      "[6/25][604/782] Loss_D: 0.0495 Loss_G: 4.7815\n",
      "[6/25][605/782] Loss_D: 0.1514 Loss_G: 4.1294\n",
      "[6/25][606/782] Loss_D: 0.1498 Loss_G: 4.1084\n",
      "[6/25][607/782] Loss_D: 0.0615 Loss_G: 3.7074\n",
      "[6/25][608/782] Loss_D: 0.0808 Loss_G: 4.2041\n",
      "[6/25][609/782] Loss_D: 0.1088 Loss_G: 5.0323\n",
      "[6/25][610/782] Loss_D: 0.1154 Loss_G: 4.2057\n",
      "[6/25][611/782] Loss_D: 0.0881 Loss_G: 3.9390\n",
      "[6/25][612/782] Loss_D: 0.0441 Loss_G: 4.2405\n",
      "[6/25][613/782] Loss_D: 0.0637 Loss_G: 4.3031\n",
      "[6/25][614/782] Loss_D: 0.0873 Loss_G: 4.3453\n",
      "[6/25][615/782] Loss_D: 0.1422 Loss_G: 3.7436\n",
      "[6/25][616/782] Loss_D: 0.0520 Loss_G: 4.0358\n",
      "[6/25][617/782] Loss_D: 0.3830 Loss_G: 8.3296\n",
      "[6/25][618/782] Loss_D: 2.4403 Loss_G: 3.0788\n",
      "[6/25][619/782] Loss_D: 1.6139 Loss_G: 0.0179\n",
      "[6/25][620/782] Loss_D: 4.7414 Loss_G: 4.3735\n",
      "[6/25][621/782] Loss_D: 0.8457 Loss_G: 2.3120\n",
      "[6/25][622/782] Loss_D: 0.8470 Loss_G: 2.0449\n",
      "[6/25][623/782] Loss_D: 0.8577 Loss_G: 1.8999\n",
      "[6/25][624/782] Loss_D: 0.6088 Loss_G: 2.5546\n",
      "[6/25][625/782] Loss_D: 0.6771 Loss_G: 2.0346\n",
      "[6/25][626/782] Loss_D: 0.5494 Loss_G: 3.7307\n",
      "[6/25][627/782] Loss_D: 1.5981 Loss_G: 0.3588\n",
      "[6/25][628/782] Loss_D: 1.9383 Loss_G: 4.7278\n",
      "[6/25][629/782] Loss_D: 0.9231 Loss_G: 2.4112\n",
      "[6/25][630/782] Loss_D: 0.6970 Loss_G: 1.1360\n",
      "[6/25][631/782] Loss_D: 1.0799 Loss_G: 3.7784\n",
      "[6/25][632/782] Loss_D: 0.8359 Loss_G: 2.1264\n",
      "[6/25][633/782] Loss_D: 0.6656 Loss_G: 1.6946\n",
      "[6/25][634/782] Loss_D: 0.7976 Loss_G: 3.4022\n",
      "[6/25][635/782] Loss_D: 0.6221 Loss_G: 2.6022\n",
      "[6/25][636/782] Loss_D: 0.5364 Loss_G: 1.9094\n",
      "[6/25][637/782] Loss_D: 0.6106 Loss_G: 3.4504\n",
      "[6/25][638/782] Loss_D: 0.8077 Loss_G: 1.4119\n",
      "[6/25][639/782] Loss_D: 0.8475 Loss_G: 4.1466\n",
      "[6/25][640/782] Loss_D: 0.8419 Loss_G: 1.8256\n",
      "[6/25][641/782] Loss_D: 0.5582 Loss_G: 2.8754\n",
      "[6/25][642/782] Loss_D: 0.4623 Loss_G: 2.7839\n",
      "[6/25][643/782] Loss_D: 0.4076 Loss_G: 3.2111\n",
      "[6/25][644/782] Loss_D: 0.4777 Loss_G: 2.5920\n",
      "[6/25][645/782] Loss_D: 0.4381 Loss_G: 1.8497\n",
      "[6/25][646/782] Loss_D: 0.7891 Loss_G: 5.5175\n",
      "[6/25][647/782] Loss_D: 1.1690 Loss_G: 1.4613\n",
      "[6/25][648/782] Loss_D: 0.8136 Loss_G: 3.6756\n",
      "[6/25][649/782] Loss_D: 0.4272 Loss_G: 2.9195\n",
      "[6/25][650/782] Loss_D: 0.5522 Loss_G: 1.8024\n",
      "[6/25][651/782] Loss_D: 0.7288 Loss_G: 3.3798\n",
      "[6/25][652/782] Loss_D: 0.6195 Loss_G: 2.0979\n",
      "[6/25][653/782] Loss_D: 0.4915 Loss_G: 2.6127\n",
      "[6/25][654/782] Loss_D: 0.3922 Loss_G: 3.7329\n",
      "[6/25][655/782] Loss_D: 1.0561 Loss_G: 0.5745\n",
      "[6/25][656/782] Loss_D: 1.6133 Loss_G: 5.6335\n",
      "[6/25][657/782] Loss_D: 1.0618 Loss_G: 2.0827\n",
      "[6/25][658/782] Loss_D: 0.5009 Loss_G: 1.8459\n",
      "[6/25][659/782] Loss_D: 0.7377 Loss_G: 4.0334\n",
      "[6/25][660/782] Loss_D: 0.8927 Loss_G: 1.9012\n",
      "[6/25][661/782] Loss_D: 0.6323 Loss_G: 2.7829\n",
      "[6/25][662/782] Loss_D: 0.6958 Loss_G: 2.7531\n",
      "[6/25][663/782] Loss_D: 0.5066 Loss_G: 2.4540\n",
      "[6/25][664/782] Loss_D: 0.7878 Loss_G: 2.3940\n",
      "[6/25][665/782] Loss_D: 0.8916 Loss_G: 3.6082\n",
      "[6/25][666/782] Loss_D: 1.0487 Loss_G: 1.1291\n",
      "[6/25][667/782] Loss_D: 1.0598 Loss_G: 4.7810\n",
      "[6/25][668/782] Loss_D: 0.4311 Loss_G: 3.5407\n",
      "[6/25][669/782] Loss_D: 0.2992 Loss_G: 2.3977\n",
      "[6/25][670/782] Loss_D: 0.4014 Loss_G: 3.0430\n",
      "[6/25][671/782] Loss_D: 0.2845 Loss_G: 3.4843\n",
      "[6/25][672/782] Loss_D: 0.7077 Loss_G: 1.3840\n",
      "[6/25][673/782] Loss_D: 0.6896 Loss_G: 3.8791\n",
      "[6/25][674/782] Loss_D: 0.4553 Loss_G: 2.9805\n",
      "[6/25][675/782] Loss_D: 0.4249 Loss_G: 2.9712\n",
      "[6/25][676/782] Loss_D: 0.6040 Loss_G: 2.0258\n",
      "[6/25][677/782] Loss_D: 0.4639 Loss_G: 3.6853\n",
      "[6/25][678/782] Loss_D: 0.5648 Loss_G: 1.9634\n",
      "[6/25][679/782] Loss_D: 0.4894 Loss_G: 3.6067\n",
      "[6/25][680/782] Loss_D: 0.4574 Loss_G: 2.2275\n",
      "[6/25][681/782] Loss_D: 0.5147 Loss_G: 3.6914\n",
      "[6/25][682/782] Loss_D: 0.4935 Loss_G: 2.4147\n",
      "[6/25][683/782] Loss_D: 0.4424 Loss_G: 2.6310\n",
      "[6/25][684/782] Loss_D: 0.6326 Loss_G: 4.0465\n",
      "[6/25][685/782] Loss_D: 0.6090 Loss_G: 1.0176\n",
      "[6/25][686/782] Loss_D: 0.9164 Loss_G: 5.5050\n",
      "[6/25][687/782] Loss_D: 1.3587 Loss_G: 1.4029\n",
      "[6/25][688/782] Loss_D: 1.0175 Loss_G: 5.7307\n",
      "[6/25][689/782] Loss_D: 1.1135 Loss_G: 1.8460\n",
      "[6/25][690/782] Loss_D: 0.6691 Loss_G: 3.9872\n",
      "[6/25][691/782] Loss_D: 0.4408 Loss_G: 2.5302\n",
      "[6/25][692/782] Loss_D: 0.4100 Loss_G: 3.1077\n",
      "[6/25][693/782] Loss_D: 0.4528 Loss_G: 3.8931\n",
      "[6/25][694/782] Loss_D: 0.4704 Loss_G: 2.4542\n",
      "[6/25][695/782] Loss_D: 0.4824 Loss_G: 2.3417\n",
      "[6/25][696/782] Loss_D: 0.4439 Loss_G: 4.1795\n",
      "[6/25][697/782] Loss_D: 0.4245 Loss_G: 2.0862\n",
      "[6/25][698/782] Loss_D: 0.3981 Loss_G: 4.7055\n",
      "[6/25][699/782] Loss_D: 0.4427 Loss_G: 2.1302\n",
      "[6/25][700/782] Loss_D: 0.5205 Loss_G: 6.6872\n",
      "[6/25][701/782] Loss_D: 0.9352 Loss_G: 2.7534\n",
      "[6/25][702/782] Loss_D: 0.2437 Loss_G: 3.4565\n",
      "[6/25][703/782] Loss_D: 0.2611 Loss_G: 4.5591\n",
      "[6/25][704/782] Loss_D: 0.3248 Loss_G: 2.1175\n",
      "[6/25][705/782] Loss_D: 0.5787 Loss_G: 5.9129\n",
      "[6/25][706/782] Loss_D: 1.4982 Loss_G: 0.2464\n",
      "[6/25][707/782] Loss_D: 2.6187 Loss_G: 7.1538\n",
      "[6/25][708/782] Loss_D: 4.3536 Loss_G: 1.2460\n",
      "[6/25][709/782] Loss_D: 1.2262 Loss_G: 1.3635\n",
      "[6/25][710/782] Loss_D: 0.8948 Loss_G: 3.9975\n",
      "[6/25][711/782] Loss_D: 1.3471 Loss_G: 1.2897\n",
      "[6/25][712/782] Loss_D: 0.8039 Loss_G: 2.3014\n",
      "[6/25][713/782] Loss_D: 0.5484 Loss_G: 3.2406\n",
      "[6/25][714/782] Loss_D: 0.7264 Loss_G: 1.9575\n",
      "[6/25][715/782] Loss_D: 0.8179 Loss_G: 3.5977\n",
      "[6/25][716/782] Loss_D: 1.0534 Loss_G: 1.3257\n",
      "[6/25][717/782] Loss_D: 0.8886 Loss_G: 4.0614\n",
      "[6/25][718/782] Loss_D: 0.2922 Loss_G: 3.9881\n",
      "[6/25][719/782] Loss_D: 0.3307 Loss_G: 2.3858\n",
      "[6/25][720/782] Loss_D: 0.3596 Loss_G: 4.3805\n",
      "[6/25][721/782] Loss_D: 0.1620 Loss_G: 4.3173\n",
      "[6/25][722/782] Loss_D: 0.3997 Loss_G: 1.8195\n",
      "[6/25][723/782] Loss_D: 0.3333 Loss_G: 4.9495\n",
      "[6/25][724/782] Loss_D: 0.2233 Loss_G: 3.9741\n",
      "[6/25][725/782] Loss_D: 0.1273 Loss_G: 3.8313\n",
      "[6/25][726/782] Loss_D: 0.1173 Loss_G: 3.8561\n",
      "[6/25][727/782] Loss_D: 0.0777 Loss_G: 3.9685\n",
      "[6/25][728/782] Loss_D: 0.0740 Loss_G: 4.1187\n",
      "[6/25][729/782] Loss_D: 0.0930 Loss_G: 4.2994\n",
      "[6/25][730/782] Loss_D: 0.0711 Loss_G: 4.4945\n",
      "[6/25][731/782] Loss_D: 0.1196 Loss_G: 4.1636\n",
      "[6/25][732/782] Loss_D: 0.1765 Loss_G: 3.5298\n",
      "[6/25][733/782] Loss_D: 0.5707 Loss_G: 7.5835\n",
      "[6/25][734/782] Loss_D: 1.6709 Loss_G: 3.5455\n",
      "[6/25][735/782] Loss_D: 1.0741 Loss_G: 0.1194\n",
      "[6/25][736/782] Loss_D: 1.8089 Loss_G: 7.7333\n",
      "[6/25][737/782] Loss_D: 2.2404 Loss_G: 0.4979\n",
      "[6/25][738/782] Loss_D: 1.9564 Loss_G: 3.9600\n",
      "[6/25][739/782] Loss_D: 1.0440 Loss_G: 1.3918\n",
      "[6/25][740/782] Loss_D: 0.6700 Loss_G: 3.5961\n",
      "[6/25][741/782] Loss_D: 0.6697 Loss_G: 2.7434\n",
      "[6/25][742/782] Loss_D: 0.6190 Loss_G: 1.5949\n",
      "[6/25][743/782] Loss_D: 1.2512 Loss_G: 4.3321\n",
      "[6/25][744/782] Loss_D: 1.8262 Loss_G: 0.5215\n",
      "[6/25][745/782] Loss_D: 1.3644 Loss_G: 4.6454\n",
      "[6/25][746/782] Loss_D: 0.9462 Loss_G: 1.2360\n",
      "[6/25][747/782] Loss_D: 0.8630 Loss_G: 3.7814\n",
      "[6/25][748/782] Loss_D: 0.4141 Loss_G: 3.0794\n",
      "[6/25][749/782] Loss_D: 0.6262 Loss_G: 1.3010\n",
      "[6/25][750/782] Loss_D: 0.9561 Loss_G: 5.2640\n",
      "[6/25][751/782] Loss_D: 0.9335 Loss_G: 1.8258\n",
      "[6/25][752/782] Loss_D: 0.7541 Loss_G: 3.0406\n",
      "[6/25][753/782] Loss_D: 0.3809 Loss_G: 3.1169\n",
      "[6/25][754/782] Loss_D: 1.1751 Loss_G: 5.4087\n",
      "[6/25][755/782] Loss_D: 1.4568 Loss_G: 0.7822\n",
      "[6/25][756/782] Loss_D: 1.9499 Loss_G: 6.6491\n",
      "[6/25][757/782] Loss_D: 2.3642 Loss_G: 1.2339\n",
      "[6/25][758/782] Loss_D: 1.3960 Loss_G: 4.3879\n",
      "[6/25][759/782] Loss_D: 0.8767 Loss_G: 1.4509\n",
      "[6/25][760/782] Loss_D: 0.5740 Loss_G: 3.5253\n",
      "[6/25][761/782] Loss_D: 0.1545 Loss_G: 4.2729\n",
      "[6/25][762/782] Loss_D: 0.3472 Loss_G: 2.5646\n",
      "[6/25][763/782] Loss_D: 0.5891 Loss_G: 2.9197\n",
      "[6/25][764/782] Loss_D: 0.2815 Loss_G: 4.0711\n",
      "[6/25][765/782] Loss_D: 0.8347 Loss_G: 4.4757\n",
      "[6/25][766/782] Loss_D: 1.1157 Loss_G: 2.4038\n",
      "[6/25][767/782] Loss_D: 2.2318 Loss_G: 7.0831\n",
      "[6/25][768/782] Loss_D: 1.5972 Loss_G: 1.2495\n",
      "[6/25][769/782] Loss_D: 0.6636 Loss_G: 3.3872\n",
      "[6/25][770/782] Loss_D: 0.3651 Loss_G: 4.8739\n",
      "[6/25][771/782] Loss_D: 0.5245 Loss_G: 2.9529\n",
      "[6/25][772/782] Loss_D: 0.3275 Loss_G: 2.9031\n",
      "[6/25][773/782] Loss_D: 0.7202 Loss_G: 6.1994\n",
      "[6/25][774/782] Loss_D: 1.6491 Loss_G: 1.3461\n",
      "[6/25][775/782] Loss_D: 1.2186 Loss_G: 6.4046\n",
      "[6/25][776/782] Loss_D: 1.4715 Loss_G: 1.2215\n",
      "[6/25][777/782] Loss_D: 0.9421 Loss_G: 4.3624\n",
      "[6/25][778/782] Loss_D: 0.3088 Loss_G: 4.0948\n",
      "[6/25][779/782] Loss_D: 0.2984 Loss_G: 2.8550\n",
      "[6/25][780/782] Loss_D: 0.2380 Loss_G: 2.7221\n",
      "[6/25][781/782] Loss_D: 0.5511 Loss_G: 5.3141\n",
      "[7/25][0/782] Loss_D: 0.2573 Loss_G: 3.5045\n",
      "[7/25][1/782] Loss_D: 0.2953 Loss_G: 2.6888\n",
      "[7/25][2/782] Loss_D: 0.6125 Loss_G: 5.9579\n",
      "[7/25][3/782] Loss_D: 0.9732 Loss_G: 2.9297\n",
      "[7/25][4/782] Loss_D: 0.4299 Loss_G: 3.5575\n",
      "[7/25][5/782] Loss_D: 0.2140 Loss_G: 3.9012\n",
      "[7/25][6/782] Loss_D: 0.2337 Loss_G: 3.0998\n",
      "[7/25][7/782] Loss_D: 0.2707 Loss_G: 4.9434\n",
      "[7/25][8/782] Loss_D: 0.3541 Loss_G: 3.0245\n",
      "[7/25][9/782] Loss_D: 0.0914 Loss_G: 3.3853\n",
      "[7/25][10/782] Loss_D: 0.2394 Loss_G: 4.4766\n",
      "[7/25][11/782] Loss_D: 0.1551 Loss_G: 4.5598\n",
      "[7/25][12/782] Loss_D: 0.2914 Loss_G: 3.2900\n",
      "[7/25][13/782] Loss_D: 0.1048 Loss_G: 3.4163\n",
      "[7/25][14/782] Loss_D: 0.2991 Loss_G: 5.2649\n",
      "[7/25][15/782] Loss_D: 0.5252 Loss_G: 4.3911\n",
      "[7/25][16/782] Loss_D: 0.2688 Loss_G: 1.9438\n",
      "[7/25][17/782] Loss_D: 0.7053 Loss_G: 6.4141\n",
      "[7/25][18/782] Loss_D: 3.0792 Loss_G: 0.9149\n",
      "[7/25][19/782] Loss_D: 1.3451 Loss_G: 5.5549\n",
      "[7/25][20/782] Loss_D: 0.9813 Loss_G: 2.2552\n",
      "[7/25][21/782] Loss_D: 0.4140 Loss_G: 2.7999\n",
      "[7/25][22/782] Loss_D: 0.4044 Loss_G: 4.5810\n",
      "[7/25][23/782] Loss_D: 0.4932 Loss_G: 2.5486\n",
      "[7/25][24/782] Loss_D: 0.5105 Loss_G: 3.6038\n",
      "[7/25][25/782] Loss_D: 0.2635 Loss_G: 3.4989\n",
      "[7/25][26/782] Loss_D: 0.3311 Loss_G: 3.3835\n",
      "[7/25][27/782] Loss_D: 0.3499 Loss_G: 3.4281\n",
      "[7/25][28/782] Loss_D: 0.1269 Loss_G: 4.1317\n",
      "[7/25][29/782] Loss_D: 0.1267 Loss_G: 3.8435\n",
      "[7/25][30/782] Loss_D: 0.0751 Loss_G: 3.9219\n",
      "[7/25][31/782] Loss_D: 0.1591 Loss_G: 3.7857\n",
      "[7/25][32/782] Loss_D: 0.1752 Loss_G: 3.6444\n",
      "[7/25][33/782] Loss_D: 0.1140 Loss_G: 3.8073\n",
      "[7/25][34/782] Loss_D: 0.1116 Loss_G: 4.1612\n",
      "[7/25][35/782] Loss_D: 0.1475 Loss_G: 3.7928\n",
      "[7/25][36/782] Loss_D: 0.1119 Loss_G: 4.1275\n",
      "[7/25][37/782] Loss_D: 0.1059 Loss_G: 4.0454\n",
      "[7/25][38/782] Loss_D: 0.1674 Loss_G: 3.3490\n",
      "[7/25][39/782] Loss_D: 0.1366 Loss_G: 4.0558\n",
      "[7/25][40/782] Loss_D: 0.0479 Loss_G: 5.0309\n",
      "[7/25][41/782] Loss_D: 0.1096 Loss_G: 3.9185\n",
      "[7/25][42/782] Loss_D: 0.1308 Loss_G: 4.1060\n",
      "[7/25][43/782] Loss_D: 0.0411 Loss_G: 4.5675\n",
      "[7/25][44/782] Loss_D: 0.1346 Loss_G: 3.2607\n",
      "[7/25][45/782] Loss_D: 0.0799 Loss_G: 3.9080\n",
      "[7/25][46/782] Loss_D: 0.0538 Loss_G: 4.2839\n",
      "[7/25][47/782] Loss_D: 0.0404 Loss_G: 4.6049\n",
      "[7/25][48/782] Loss_D: 0.0396 Loss_G: 4.7465\n",
      "[7/25][49/782] Loss_D: 0.1081 Loss_G: 4.2583\n",
      "[7/25][50/782] Loss_D: 0.0611 Loss_G: 4.6609\n",
      "[7/25][51/782] Loss_D: 0.1759 Loss_G: 3.4026\n",
      "[7/25][52/782] Loss_D: 0.0869 Loss_G: 4.0241\n",
      "[7/25][53/782] Loss_D: 0.0634 Loss_G: 4.2250\n",
      "[7/25][54/782] Loss_D: 0.0916 Loss_G: 4.3925\n",
      "[7/25][55/782] Loss_D: 0.0616 Loss_G: 4.6454\n",
      "[7/25][56/782] Loss_D: 0.0656 Loss_G: 4.5196\n",
      "[7/25][57/782] Loss_D: 0.0728 Loss_G: 4.4677\n",
      "[7/25][58/782] Loss_D: 0.1914 Loss_G: 3.9738\n",
      "[7/25][59/782] Loss_D: 0.0949 Loss_G: 4.8241\n",
      "[7/25][60/782] Loss_D: 0.1257 Loss_G: 4.6484\n",
      "[7/25][61/782] Loss_D: 0.0460 Loss_G: 4.4899\n",
      "[7/25][62/782] Loss_D: 0.3082 Loss_G: 7.7781\n",
      "[7/25][63/782] Loss_D: 0.1650 Loss_G: 7.7138\n",
      "[7/25][64/782] Loss_D: 0.1636 Loss_G: 6.1217\n",
      "[7/25][65/782] Loss_D: 0.0322 Loss_G: 4.5809\n",
      "[7/25][66/782] Loss_D: 0.0471 Loss_G: 4.1021\n",
      "[7/25][67/782] Loss_D: 0.0328 Loss_G: 4.6656\n",
      "[7/25][68/782] Loss_D: 0.0096 Loss_G: 5.8049\n",
      "[7/25][69/782] Loss_D: 0.1567 Loss_G: 5.8876\n",
      "[7/25][70/782] Loss_D: 0.0696 Loss_G: 5.7723\n",
      "[7/25][71/782] Loss_D: 0.0511 Loss_G: 5.0421\n",
      "[7/25][72/782] Loss_D: 0.0559 Loss_G: 4.2218\n",
      "[7/25][73/782] Loss_D: 0.1325 Loss_G: 4.5186\n",
      "[7/25][74/782] Loss_D: 0.0440 Loss_G: 4.7486\n",
      "[7/25][75/782] Loss_D: 0.1399 Loss_G: 4.0924\n",
      "[7/25][76/782] Loss_D: 0.0607 Loss_G: 4.7736\n",
      "[7/25][77/782] Loss_D: 0.0472 Loss_G: 4.5300\n",
      "[7/25][78/782] Loss_D: 0.0538 Loss_G: 4.5837\n",
      "[7/25][79/782] Loss_D: 0.0682 Loss_G: 4.5106\n",
      "[7/25][80/782] Loss_D: 0.0350 Loss_G: 4.8348\n",
      "[7/25][81/782] Loss_D: 0.0900 Loss_G: 4.5139\n",
      "[7/25][82/782] Loss_D: 0.0460 Loss_G: 5.5521\n",
      "[7/25][83/782] Loss_D: 0.0649 Loss_G: 4.9666\n",
      "[7/25][84/782] Loss_D: 0.0644 Loss_G: 3.9156\n",
      "[7/25][85/782] Loss_D: 0.0462 Loss_G: 4.3831\n",
      "[7/25][86/782] Loss_D: 0.0220 Loss_G: 5.3550\n",
      "[7/25][87/782] Loss_D: 0.1184 Loss_G: 5.4999\n",
      "[7/25][88/782] Loss_D: 0.0278 Loss_G: 6.0890\n",
      "[7/25][89/782] Loss_D: 0.1105 Loss_G: 4.3496\n",
      "[7/25][90/782] Loss_D: 0.0160 Loss_G: 5.1881\n",
      "[7/25][91/782] Loss_D: 0.0717 Loss_G: 4.4221\n",
      "[7/25][92/782] Loss_D: 0.0374 Loss_G: 4.8265\n",
      "[7/25][93/782] Loss_D: 0.0389 Loss_G: 5.6005\n",
      "[7/25][94/782] Loss_D: 0.0878 Loss_G: 3.8946\n",
      "[7/25][95/782] Loss_D: 0.0190 Loss_G: 4.9517\n",
      "[7/25][96/782] Loss_D: 0.0419 Loss_G: 4.5025\n",
      "[7/25][97/782] Loss_D: 0.1101 Loss_G: 5.4349\n",
      "[7/25][98/782] Loss_D: 0.0481 Loss_G: 5.5944\n",
      "[7/25][99/782] Loss_D: 0.0456 Loss_G: 4.6150\n",
      "[7/25][100/782] Loss_D: 0.0269 Loss_G: 4.9801\n",
      "[7/25][101/782] Loss_D: 0.0518 Loss_G: 4.5488\n",
      "[7/25][102/782] Loss_D: 0.1028 Loss_G: 5.2446\n",
      "[7/25][103/782] Loss_D: 0.0445 Loss_G: 5.3897\n",
      "[7/25][104/782] Loss_D: 0.1508 Loss_G: 3.7314\n",
      "[7/25][105/782] Loss_D: 0.0198 Loss_G: 4.3326\n",
      "[7/25][106/782] Loss_D: 0.6381 Loss_G: 11.0429\n",
      "[7/25][107/782] Loss_D: 2.8931 Loss_G: 7.5482\n",
      "[7/25][108/782] Loss_D: 2.9091 Loss_G: 0.0539\n",
      "[7/25][109/782] Loss_D: 3.2584 Loss_G: 6.6662\n",
      "[7/25][110/782] Loss_D: 1.2222 Loss_G: 4.1181\n",
      "[7/25][111/782] Loss_D: 0.1745 Loss_G: 2.5554\n",
      "[7/25][112/782] Loss_D: 0.4212 Loss_G: 3.4943\n",
      "[7/25][113/782] Loss_D: 0.2184 Loss_G: 4.0541\n",
      "[7/25][114/782] Loss_D: 0.4270 Loss_G: 2.6976\n",
      "[7/25][115/782] Loss_D: 0.8483 Loss_G: 5.8453\n",
      "[7/25][116/782] Loss_D: 1.2470 Loss_G: 1.2486\n",
      "[7/25][117/782] Loss_D: 1.1921 Loss_G: 5.7426\n",
      "[7/25][118/782] Loss_D: 0.7686 Loss_G: 2.9346\n",
      "[7/25][119/782] Loss_D: 0.4625 Loss_G: 2.2980\n",
      "[7/25][120/782] Loss_D: 0.5922 Loss_G: 4.5061\n",
      "[7/25][121/782] Loss_D: 0.6631 Loss_G: 2.1141\n",
      "[7/25][122/782] Loss_D: 0.3678 Loss_G: 3.0825\n",
      "[7/25][123/782] Loss_D: 0.5813 Loss_G: 4.3897\n",
      "[7/25][124/782] Loss_D: 0.4481 Loss_G: 3.2498\n",
      "[7/25][125/782] Loss_D: 0.9255 Loss_G: 3.9650\n",
      "[7/25][126/782] Loss_D: 1.1622 Loss_G: 0.8014\n",
      "[7/25][127/782] Loss_D: 1.6036 Loss_G: 7.0518\n",
      "[7/25][128/782] Loss_D: 0.8928 Loss_G: 5.0034\n",
      "[7/25][129/782] Loss_D: 0.3420 Loss_G: 2.1113\n",
      "[7/25][130/782] Loss_D: 0.5722 Loss_G: 3.2611\n",
      "[7/25][131/782] Loss_D: 0.2159 Loss_G: 4.1686\n",
      "[7/25][132/782] Loss_D: 0.2301 Loss_G: 3.4581\n",
      "[7/25][133/782] Loss_D: 0.5207 Loss_G: 2.0806\n",
      "[7/25][134/782] Loss_D: 0.5683 Loss_G: 3.2025\n",
      "[7/25][135/782] Loss_D: 0.3984 Loss_G: 4.0853\n",
      "[7/25][136/782] Loss_D: 1.0498 Loss_G: 1.1060\n",
      "[7/25][137/782] Loss_D: 0.8506 Loss_G: 4.4231\n",
      "[7/25][138/782] Loss_D: 0.3347 Loss_G: 3.8198\n",
      "[7/25][139/782] Loss_D: 0.3586 Loss_G: 2.5224\n",
      "[7/25][140/782] Loss_D: 0.3227 Loss_G: 2.9362\n",
      "[7/25][141/782] Loss_D: 0.3742 Loss_G: 3.7542\n",
      "[7/25][142/782] Loss_D: 0.4143 Loss_G: 2.7124\n",
      "[7/25][143/782] Loss_D: 0.4811 Loss_G: 2.8954\n",
      "[7/25][144/782] Loss_D: 0.5021 Loss_G: 2.7970\n",
      "[7/25][145/782] Loss_D: 0.4214 Loss_G: 3.5963\n",
      "[7/25][146/782] Loss_D: 0.3804 Loss_G: 2.7281\n",
      "[7/25][147/782] Loss_D: 0.3864 Loss_G: 2.7567\n",
      "[7/25][148/782] Loss_D: 0.5211 Loss_G: 4.4181\n",
      "[7/25][149/782] Loss_D: 0.6475 Loss_G: 2.0607\n",
      "[7/25][150/782] Loss_D: 0.3470 Loss_G: 2.8997\n",
      "[7/25][151/782] Loss_D: 0.5017 Loss_G: 2.7387\n",
      "[7/25][152/782] Loss_D: 0.6347 Loss_G: 2.9330\n",
      "[7/25][153/782] Loss_D: 0.4726 Loss_G: 3.9072\n",
      "[7/25][154/782] Loss_D: 0.6656 Loss_G: 1.4430\n",
      "[7/25][155/782] Loss_D: 0.8954 Loss_G: 5.1984\n",
      "[7/25][156/782] Loss_D: 0.8817 Loss_G: 2.1905\n",
      "[7/25][157/782] Loss_D: 0.3083 Loss_G: 2.4699\n",
      "[7/25][158/782] Loss_D: 0.4995 Loss_G: 4.0001\n",
      "[7/25][159/782] Loss_D: 0.3525 Loss_G: 3.2020\n",
      "[7/25][160/782] Loss_D: 0.3864 Loss_G: 2.1717\n",
      "[7/25][161/782] Loss_D: 0.4299 Loss_G: 3.3749\n",
      "[7/25][162/782] Loss_D: 0.4059 Loss_G: 2.9442\n",
      "[7/25][163/782] Loss_D: 0.4022 Loss_G: 3.2888\n",
      "[7/25][164/782] Loss_D: 0.3797 Loss_G: 2.6682\n",
      "[7/25][165/782] Loss_D: 0.2758 Loss_G: 3.1927\n",
      "[7/25][166/782] Loss_D: 0.5635 Loss_G: 1.4131\n",
      "[7/25][167/782] Loss_D: 0.7539 Loss_G: 5.1216\n",
      "[7/25][168/782] Loss_D: 0.6389 Loss_G: 2.5510\n",
      "[7/25][169/782] Loss_D: 0.4304 Loss_G: 2.1769\n",
      "[7/25][170/782] Loss_D: 0.4165 Loss_G: 4.0192\n",
      "[7/25][171/782] Loss_D: 0.3685 Loss_G: 2.9480\n",
      "[7/25][172/782] Loss_D: 0.3424 Loss_G: 2.8718\n",
      "[7/25][173/782] Loss_D: 0.2810 Loss_G: 3.0964\n",
      "[7/25][174/782] Loss_D: 0.2772 Loss_G: 2.7229\n",
      "[7/25][175/782] Loss_D: 0.2922 Loss_G: 4.0570\n",
      "[7/25][176/782] Loss_D: 0.3299 Loss_G: 2.3682\n",
      "[7/25][177/782] Loss_D: 0.2133 Loss_G: 4.1526\n",
      "[7/25][178/782] Loss_D: 0.3294 Loss_G: 1.8447\n",
      "[7/25][179/782] Loss_D: 0.5578 Loss_G: 6.9135\n",
      "[7/25][180/782] Loss_D: 1.0667 Loss_G: 2.1547\n",
      "[7/25][181/782] Loss_D: 0.4025 Loss_G: 5.1978\n",
      "[7/25][182/782] Loss_D: 0.1116 Loss_G: 4.8815\n",
      "[7/25][183/782] Loss_D: 0.4526 Loss_G: 1.4690\n",
      "[7/25][184/782] Loss_D: 0.6415 Loss_G: 6.3476\n",
      "[7/25][185/782] Loss_D: 0.2476 Loss_G: 5.0478\n",
      "[7/25][186/782] Loss_D: 0.2431 Loss_G: 2.3975\n",
      "[7/25][187/782] Loss_D: 0.3525 Loss_G: 5.3364\n",
      "[7/25][188/782] Loss_D: 0.1664 Loss_G: 4.4396\n",
      "[7/25][189/782] Loss_D: 0.0945 Loss_G: 3.8932\n",
      "[7/25][190/782] Loss_D: 0.0521 Loss_G: 4.6900\n",
      "[7/25][191/782] Loss_D: 0.1305 Loss_G: 3.9242\n",
      "[7/25][192/782] Loss_D: 0.2390 Loss_G: 5.3521\n",
      "[7/25][193/782] Loss_D: 0.4784 Loss_G: 2.2153\n",
      "[7/25][194/782] Loss_D: 0.2745 Loss_G: 4.7944\n",
      "[7/25][195/782] Loss_D: 0.1030 Loss_G: 4.7593\n",
      "[7/25][196/782] Loss_D: 0.1206 Loss_G: 4.1481\n",
      "[7/25][197/782] Loss_D: 0.0931 Loss_G: 4.2610\n",
      "[7/25][198/782] Loss_D: 0.0648 Loss_G: 4.7794\n",
      "[7/25][199/782] Loss_D: 0.2244 Loss_G: 6.1507\n",
      "[7/25][200/782] Loss_D: 0.2240 Loss_G: 3.9398\n",
      "[7/25][201/782] Loss_D: 0.1134 Loss_G: 3.6266\n",
      "[7/25][202/782] Loss_D: 0.0728 Loss_G: 4.7516\n",
      "[7/25][203/782] Loss_D: 0.0573 Loss_G: 4.8010\n",
      "[7/25][204/782] Loss_D: 0.0550 Loss_G: 4.8458\n",
      "[7/25][205/782] Loss_D: 0.0294 Loss_G: 4.9896\n",
      "[7/25][206/782] Loss_D: 0.0712 Loss_G: 4.5309\n",
      "[7/25][207/782] Loss_D: 0.0414 Loss_G: 4.9162\n",
      "[7/25][208/782] Loss_D: 0.1576 Loss_G: 5.0216\n",
      "[7/25][209/782] Loss_D: 0.0373 Loss_G: 5.3729\n",
      "[7/25][210/782] Loss_D: 0.0545 Loss_G: 4.6059\n",
      "[7/25][211/782] Loss_D: 0.1078 Loss_G: 3.6145\n",
      "[7/25][212/782] Loss_D: 0.0309 Loss_G: 4.5458\n",
      "[7/25][213/782] Loss_D: 0.4442 Loss_G: 8.2638\n",
      "[7/25][214/782] Loss_D: 1.6018 Loss_G: 5.2565\n",
      "[7/25][215/782] Loss_D: 1.1010 Loss_G: 0.0407\n",
      "[7/25][216/782] Loss_D: 2.5200 Loss_G: 8.2615\n",
      "[7/25][217/782] Loss_D: 2.8472 Loss_G: 0.9770\n",
      "[7/25][218/782] Loss_D: 1.4783 Loss_G: 5.7768\n",
      "[7/25][219/782] Loss_D: 0.4225 Loss_G: 3.8243\n",
      "[7/25][220/782] Loss_D: 0.3713 Loss_G: 2.8757\n",
      "[7/25][221/782] Loss_D: 1.1072 Loss_G: 4.1620\n",
      "[7/25][222/782] Loss_D: 1.7034 Loss_G: 0.7635\n",
      "[7/25][223/782] Loss_D: 2.0814 Loss_G: 5.5521\n",
      "[7/25][224/782] Loss_D: 0.9473 Loss_G: 3.4709\n",
      "[7/25][225/782] Loss_D: 0.4722 Loss_G: 2.2284\n",
      "[7/25][226/782] Loss_D: 0.9207 Loss_G: 4.7674\n",
      "[7/25][227/782] Loss_D: 0.6846 Loss_G: 3.1228\n",
      "[7/25][228/782] Loss_D: 0.7613 Loss_G: 1.6784\n",
      "[7/25][229/782] Loss_D: 1.0212 Loss_G: 4.4697\n",
      "[7/25][230/782] Loss_D: 0.6458 Loss_G: 2.9865\n",
      "[7/25][231/782] Loss_D: 0.6095 Loss_G: 2.2421\n",
      "[7/25][232/782] Loss_D: 0.5176 Loss_G: 2.5237\n",
      "[7/25][233/782] Loss_D: 0.9973 Loss_G: 6.9628\n",
      "[7/25][234/782] Loss_D: 2.3101 Loss_G: 1.0303\n",
      "[7/25][235/782] Loss_D: 0.6081 Loss_G: 3.9405\n",
      "[7/25][236/782] Loss_D: 0.2895 Loss_G: 3.5026\n",
      "[7/25][237/782] Loss_D: 0.4792 Loss_G: 4.4351\n",
      "[7/25][238/782] Loss_D: 0.6556 Loss_G: 1.9614\n",
      "[7/25][239/782] Loss_D: 0.9330 Loss_G: 6.6131\n",
      "[7/25][240/782] Loss_D: 1.4710 Loss_G: 1.6786\n",
      "[7/25][241/782] Loss_D: 1.3361 Loss_G: 6.8047\n",
      "[7/25][242/782] Loss_D: 1.3582 Loss_G: 2.4139\n",
      "[7/25][243/782] Loss_D: 0.3961 Loss_G: 2.7946\n",
      "[7/25][244/782] Loss_D: 0.7018 Loss_G: 5.4238\n",
      "[7/25][245/782] Loss_D: 0.7726 Loss_G: 3.0868\n",
      "[7/25][246/782] Loss_D: 0.4011 Loss_G: 2.3799\n",
      "[7/25][247/782] Loss_D: 0.9074 Loss_G: 4.8384\n",
      "[7/25][248/782] Loss_D: 0.8984 Loss_G: 1.9456\n",
      "[7/25][249/782] Loss_D: 0.9755 Loss_G: 4.5584\n",
      "[7/25][250/782] Loss_D: 0.4868 Loss_G: 3.3161\n",
      "[7/25][251/782] Loss_D: 0.4384 Loss_G: 2.1287\n",
      "[7/25][252/782] Loss_D: 0.6259 Loss_G: 4.3090\n",
      "[7/25][253/782] Loss_D: 0.2410 Loss_G: 4.1503\n",
      "[7/25][254/782] Loss_D: 0.2761 Loss_G: 2.7349\n",
      "[7/25][255/782] Loss_D: 0.2941 Loss_G: 4.0422\n",
      "[7/25][256/782] Loss_D: 0.1434 Loss_G: 5.0152\n",
      "[7/25][257/782] Loss_D: 0.3255 Loss_G: 2.5494\n",
      "[7/25][258/782] Loss_D: 0.2685 Loss_G: 5.7053\n",
      "[7/25][259/782] Loss_D: 0.1906 Loss_G: 4.5456\n",
      "[7/25][260/782] Loss_D: 0.1038 Loss_G: 4.3034\n",
      "[7/25][261/782] Loss_D: 0.0626 Loss_G: 4.4869\n",
      "[7/25][262/782] Loss_D: 0.0610 Loss_G: 4.3672\n",
      "[7/25][263/782] Loss_D: 0.1172 Loss_G: 4.0895\n",
      "[7/25][264/782] Loss_D: 0.1285 Loss_G: 3.8669\n",
      "[7/25][265/782] Loss_D: 0.0953 Loss_G: 4.4200\n",
      "[7/25][266/782] Loss_D: 0.2307 Loss_G: 5.2059\n",
      "[7/25][267/782] Loss_D: 0.4249 Loss_G: 2.7280\n",
      "[7/25][268/782] Loss_D: 0.3363 Loss_G: 5.7096\n",
      "[7/25][269/782] Loss_D: 0.1398 Loss_G: 4.7553\n",
      "[7/25][270/782] Loss_D: 0.0676 Loss_G: 4.9768\n",
      "[7/25][271/782] Loss_D: 0.0392 Loss_G: 4.6569\n",
      "[7/25][272/782] Loss_D: 0.1681 Loss_G: 5.4487\n",
      "[7/25][273/782] Loss_D: 0.1207 Loss_G: 4.6657\n",
      "[7/25][274/782] Loss_D: 0.0628 Loss_G: 4.6726\n",
      "[7/25][275/782] Loss_D: 0.0477 Loss_G: 4.4319\n",
      "[7/25][276/782] Loss_D: 0.0525 Loss_G: 4.4965\n",
      "[7/25][277/782] Loss_D: 0.1914 Loss_G: 5.2479\n",
      "[7/25][278/782] Loss_D: 0.1546 Loss_G: 4.1261\n",
      "[7/25][279/782] Loss_D: 0.0430 Loss_G: 4.2961\n",
      "[7/25][280/782] Loss_D: 0.0476 Loss_G: 4.3770\n",
      "[7/25][281/782] Loss_D: 0.0904 Loss_G: 4.5655\n",
      "[7/25][282/782] Loss_D: 0.0414 Loss_G: 4.9098\n",
      "[7/25][283/782] Loss_D: 0.0478 Loss_G: 4.8946\n",
      "[7/25][284/782] Loss_D: 0.0389 Loss_G: 4.5485\n",
      "[7/25][285/782] Loss_D: 0.0774 Loss_G: 4.1864\n",
      "[7/25][286/782] Loss_D: 0.0334 Loss_G: 4.9643\n",
      "[7/25][287/782] Loss_D: 0.0824 Loss_G: 4.2614\n",
      "[7/25][288/782] Loss_D: 0.0597 Loss_G: 4.4335\n",
      "[7/25][289/782] Loss_D: 0.1835 Loss_G: 5.8076\n",
      "[7/25][290/782] Loss_D: 0.2481 Loss_G: 4.9782\n",
      "[7/25][291/782] Loss_D: 0.0510 Loss_G: 3.4614\n",
      "[7/25][292/782] Loss_D: 0.0455 Loss_G: 4.2182\n",
      "[7/25][293/782] Loss_D: 0.1279 Loss_G: 5.7501\n",
      "[7/25][294/782] Loss_D: 0.0611 Loss_G: 5.1914\n",
      "[7/25][295/782] Loss_D: 0.0463 Loss_G: 4.9019\n",
      "[7/25][296/782] Loss_D: 0.0884 Loss_G: 4.9452\n",
      "[7/25][297/782] Loss_D: 0.2820 Loss_G: 7.2284\n",
      "[7/25][298/782] Loss_D: 0.8350 Loss_G: 5.4858\n",
      "[7/25][299/782] Loss_D: 0.9174 Loss_G: 0.0009\n",
      "[7/25][300/782] Loss_D: 9.7047 Loss_G: 6.4292\n",
      "[7/25][301/782] Loss_D: 1.5566 Loss_G: 1.8435\n",
      "[7/25][302/782] Loss_D: 0.9755 Loss_G: 2.4252\n",
      "[7/25][303/782] Loss_D: 0.8119 Loss_G: 2.9584\n",
      "[7/25][304/782] Loss_D: 0.7269 Loss_G: 2.1622\n",
      "[7/25][305/782] Loss_D: 0.5551 Loss_G: 3.6635\n",
      "[7/25][306/782] Loss_D: 1.3308 Loss_G: 0.3013\n",
      "[7/25][307/782] Loss_D: 2.1881 Loss_G: 5.0348\n",
      "[7/25][308/782] Loss_D: 1.4648 Loss_G: 1.4699\n",
      "[7/25][309/782] Loss_D: 1.1997 Loss_G: 5.1246\n",
      "[7/25][310/782] Loss_D: 1.1165 Loss_G: 1.4322\n",
      "[7/25][311/782] Loss_D: 0.7481 Loss_G: 1.6169\n",
      "[7/25][312/782] Loss_D: 0.9332 Loss_G: 4.4108\n",
      "[7/25][313/782] Loss_D: 0.7739 Loss_G: 2.2585\n",
      "[7/25][314/782] Loss_D: 0.5868 Loss_G: 2.7157\n",
      "[7/25][315/782] Loss_D: 0.7300 Loss_G: 2.0467\n",
      "[7/25][316/782] Loss_D: 0.5823 Loss_G: 2.2612\n",
      "[7/25][317/782] Loss_D: 0.8955 Loss_G: 3.2568\n",
      "[7/25][318/782] Loss_D: 0.8654 Loss_G: 1.0137\n",
      "[7/25][319/782] Loss_D: 0.9598 Loss_G: 4.3462\n",
      "[7/25][320/782] Loss_D: 0.9513 Loss_G: 1.7049\n",
      "[7/25][321/782] Loss_D: 0.7002 Loss_G: 2.9964\n",
      "[7/25][322/782] Loss_D: 0.4541 Loss_G: 3.3378\n",
      "[7/25][323/782] Loss_D: 0.6430 Loss_G: 2.0440\n",
      "[7/25][324/782] Loss_D: 0.8061 Loss_G: 3.6899\n",
      "[7/25][325/782] Loss_D: 0.5889 Loss_G: 2.4326\n",
      "[7/25][326/782] Loss_D: 0.4712 Loss_G: 3.1877\n",
      "[7/25][327/782] Loss_D: 0.4869 Loss_G: 2.5680\n",
      "[7/25][328/782] Loss_D: 0.6689 Loss_G: 4.2332\n",
      "[7/25][329/782] Loss_D: 0.3032 Loss_G: 2.9524\n",
      "[7/25][330/782] Loss_D: 0.3575 Loss_G: 3.1122\n",
      "[7/25][331/782] Loss_D: 0.3718 Loss_G: 5.5547\n",
      "[7/25][332/782] Loss_D: 0.8022 Loss_G: 1.3363\n",
      "[7/25][333/782] Loss_D: 1.0398 Loss_G: 5.6728\n",
      "[7/25][334/782] Loss_D: 0.8472 Loss_G: 2.8784\n",
      "[7/25][335/782] Loss_D: 0.3544 Loss_G: 3.6278\n",
      "[7/25][336/782] Loss_D: 0.4204 Loss_G: 2.5743\n",
      "[7/25][337/782] Loss_D: 0.3749 Loss_G: 4.0658\n",
      "[7/25][338/782] Loss_D: 0.2051 Loss_G: 4.0132\n",
      "[7/25][339/782] Loss_D: 0.3433 Loss_G: 2.4233\n",
      "[7/25][340/782] Loss_D: 0.5382 Loss_G: 6.3872\n",
      "[7/25][341/782] Loss_D: 0.9854 Loss_G: 3.0940\n",
      "[7/25][342/782] Loss_D: 0.4608 Loss_G: 5.7886\n",
      "[7/25][343/782] Loss_D: 1.2108 Loss_G: 0.3473\n",
      "[7/25][344/782] Loss_D: 2.2790 Loss_G: 7.0161\n",
      "[7/25][345/782] Loss_D: 1.4195 Loss_G: 3.9704\n",
      "[7/25][346/782] Loss_D: 0.3395 Loss_G: 2.1160\n",
      "[7/25][347/782] Loss_D: 0.6403 Loss_G: 3.7672\n",
      "[7/25][348/782] Loss_D: 0.2976 Loss_G: 3.8035\n",
      "[7/25][349/782] Loss_D: 0.3245 Loss_G: 2.9092\n",
      "[7/25][350/782] Loss_D: 0.2640 Loss_G: 3.8889\n",
      "[7/25][351/782] Loss_D: 0.2072 Loss_G: 3.4869\n",
      "[7/25][352/782] Loss_D: 0.3535 Loss_G: 3.3973\n",
      "[7/25][353/782] Loss_D: 0.5157 Loss_G: 2.1043\n",
      "[7/25][354/782] Loss_D: 0.5319 Loss_G: 4.3594\n",
      "[7/25][355/782] Loss_D: 0.3842 Loss_G: 3.3769\n",
      "[7/25][356/782] Loss_D: 0.2025 Loss_G: 3.4450\n",
      "[7/25][357/782] Loss_D: 0.1630 Loss_G: 3.6547\n",
      "[7/25][358/782] Loss_D: 0.2254 Loss_G: 4.0873\n",
      "[7/25][359/782] Loss_D: 0.2174 Loss_G: 3.3019\n",
      "[7/25][360/782] Loss_D: 0.1652 Loss_G: 4.0564\n",
      "[7/25][361/782] Loss_D: 0.1078 Loss_G: 4.3653\n",
      "[7/25][362/782] Loss_D: 0.1182 Loss_G: 3.8679\n",
      "[7/25][363/782] Loss_D: 0.0879 Loss_G: 3.8657\n",
      "[7/25][364/782] Loss_D: 0.1472 Loss_G: 3.4948\n",
      "[7/25][365/782] Loss_D: 0.1032 Loss_G: 4.0079\n",
      "[7/25][366/782] Loss_D: 0.1234 Loss_G: 4.5459\n",
      "[7/25][367/782] Loss_D: 0.1096 Loss_G: 4.2024\n",
      "[7/25][368/782] Loss_D: 0.1084 Loss_G: 3.6290\n",
      "[7/25][369/782] Loss_D: 0.0680 Loss_G: 3.9850\n",
      "[7/25][370/782] Loss_D: 0.6129 Loss_G: 9.1358\n",
      "[7/25][371/782] Loss_D: 3.3262 Loss_G: 4.9335\n",
      "[7/25][372/782] Loss_D: 2.8143 Loss_G: 0.0089\n",
      "[7/25][373/782] Loss_D: 6.4615 Loss_G: 1.9994\n",
      "[7/25][374/782] Loss_D: 0.7910 Loss_G: 5.3592\n",
      "[7/25][375/782] Loss_D: 2.3361 Loss_G: 1.2394\n",
      "[7/25][376/782] Loss_D: 0.7244 Loss_G: 1.7090\n",
      "[7/25][377/782] Loss_D: 0.8133 Loss_G: 3.5287\n",
      "[7/25][378/782] Loss_D: 0.8116 Loss_G: 2.0640\n",
      "[7/25][379/782] Loss_D: 0.5558 Loss_G: 1.7922\n",
      "[7/25][380/782] Loss_D: 0.8298 Loss_G: 2.8451\n",
      "[7/25][381/782] Loss_D: 0.6477 Loss_G: 2.4865\n",
      "[7/25][382/782] Loss_D: 0.5168 Loss_G: 2.0255\n",
      "[7/25][383/782] Loss_D: 0.8209 Loss_G: 3.1184\n",
      "[7/25][384/782] Loss_D: 0.6103 Loss_G: 2.3383\n",
      "[7/25][385/782] Loss_D: 0.4401 Loss_G: 2.2767\n",
      "[7/25][386/782] Loss_D: 0.6532 Loss_G: 3.0742\n",
      "[7/25][387/782] Loss_D: 0.8825 Loss_G: 1.7897\n",
      "[7/25][388/782] Loss_D: 0.7212 Loss_G: 4.8140\n",
      "[7/25][389/782] Loss_D: 0.7647 Loss_G: 2.1185\n",
      "[7/25][390/782] Loss_D: 0.4840 Loss_G: 3.6944\n",
      "[7/25][391/782] Loss_D: 0.1537 Loss_G: 4.2418\n",
      "[7/25][392/782] Loss_D: 0.4473 Loss_G: 2.6254\n",
      "[7/25][393/782] Loss_D: 0.5491 Loss_G: 5.8916\n",
      "[7/25][394/782] Loss_D: 0.8350 Loss_G: 1.0338\n",
      "[7/25][395/782] Loss_D: 1.2012 Loss_G: 6.9901\n",
      "[7/25][396/782] Loss_D: 2.1518 Loss_G: 1.3626\n",
      "[7/25][397/782] Loss_D: 1.5366 Loss_G: 6.3783\n",
      "[7/25][398/782] Loss_D: 1.3192 Loss_G: 2.1409\n",
      "[7/25][399/782] Loss_D: 0.5041 Loss_G: 3.0195\n",
      "[7/25][400/782] Loss_D: 0.5401 Loss_G: 4.4727\n",
      "[7/25][401/782] Loss_D: 0.5545 Loss_G: 3.2075\n",
      "[7/25][402/782] Loss_D: 0.3989 Loss_G: 2.4882\n",
      "[7/25][403/782] Loss_D: 0.5587 Loss_G: 4.9963\n",
      "[7/25][404/782] Loss_D: 0.4067 Loss_G: 3.6363\n",
      "[7/25][405/782] Loss_D: 0.2953 Loss_G: 2.7957\n",
      "[7/25][406/782] Loss_D: 0.6110 Loss_G: 6.3915\n",
      "[7/25][407/782] Loss_D: 1.0711 Loss_G: 2.1962\n",
      "[7/25][408/782] Loss_D: 0.7734 Loss_G: 5.8900\n",
      "[7/25][409/782] Loss_D: 2.2020 Loss_G: 0.9948\n",
      "[7/25][410/782] Loss_D: 1.2484 Loss_G: 3.9127\n",
      "[7/25][411/782] Loss_D: 0.6319 Loss_G: 2.8887\n",
      "[7/25][412/782] Loss_D: 0.3314 Loss_G: 2.2510\n",
      "[7/25][413/782] Loss_D: 0.3888 Loss_G: 3.1370\n",
      "[7/25][414/782] Loss_D: 0.3224 Loss_G: 2.9521\n",
      "[7/25][415/782] Loss_D: 0.3162 Loss_G: 2.9104\n",
      "[7/25][416/782] Loss_D: 0.3569 Loss_G: 2.8145\n",
      "[7/25][417/782] Loss_D: 0.4676 Loss_G: 3.4673\n",
      "[7/25][418/782] Loss_D: 0.2603 Loss_G: 3.7379\n",
      "[7/25][419/782] Loss_D: 0.1707 Loss_G: 3.3500\n",
      "[7/25][420/782] Loss_D: 0.1980 Loss_G: 3.4690\n",
      "[7/25][421/782] Loss_D: 0.0831 Loss_G: 4.0000\n",
      "[7/25][422/782] Loss_D: 0.1704 Loss_G: 4.2615\n",
      "[7/25][423/782] Loss_D: 0.1318 Loss_G: 4.1722\n",
      "[7/25][424/782] Loss_D: 0.1836 Loss_G: 3.8575\n",
      "[7/25][425/782] Loss_D: 0.1623 Loss_G: 3.6782\n",
      "[7/25][426/782] Loss_D: 0.1349 Loss_G: 3.9134\n",
      "[7/25][427/782] Loss_D: 0.1361 Loss_G: 4.6798\n",
      "[7/25][428/782] Loss_D: 0.0937 Loss_G: 4.5814\n",
      "[7/25][429/782] Loss_D: 0.1096 Loss_G: 3.9847\n",
      "[7/25][430/782] Loss_D: 0.1597 Loss_G: 4.3272\n",
      "[7/25][431/782] Loss_D: 0.2178 Loss_G: 3.6258\n",
      "[7/25][432/782] Loss_D: 0.0628 Loss_G: 3.6231\n",
      "[7/25][433/782] Loss_D: 0.1762 Loss_G: 4.9946\n",
      "[7/25][434/782] Loss_D: 0.2021 Loss_G: 3.6527\n",
      "[7/25][435/782] Loss_D: 0.1408 Loss_G: 3.5385\n",
      "[7/25][436/782] Loss_D: 0.1057 Loss_G: 4.3943\n",
      "[7/25][437/782] Loss_D: 0.0806 Loss_G: 4.4754\n",
      "[7/25][438/782] Loss_D: 0.1075 Loss_G: 3.8632\n",
      "[7/25][439/782] Loss_D: 0.0656 Loss_G: 4.2483\n",
      "[7/25][440/782] Loss_D: 0.0472 Loss_G: 4.6103\n",
      "[7/25][441/782] Loss_D: 0.4830 Loss_G: 7.3716\n",
      "[7/25][442/782] Loss_D: 1.8023 Loss_G: 5.2586\n",
      "[7/25][443/782] Loss_D: 1.7591 Loss_G: 0.0472\n",
      "[7/25][444/782] Loss_D: 1.7147 Loss_G: 6.4493\n",
      "[7/25][445/782] Loss_D: 0.3910 Loss_G: 5.3559\n",
      "[7/25][446/782] Loss_D: 0.5684 Loss_G: 1.1453\n",
      "[7/25][447/782] Loss_D: 0.8141 Loss_G: 5.3257\n",
      "[7/25][448/782] Loss_D: 0.2657 Loss_G: 4.8906\n",
      "[7/25][449/782] Loss_D: 0.3714 Loss_G: 2.8975\n",
      "[7/25][450/782] Loss_D: 0.6388 Loss_G: 5.9841\n",
      "[7/25][451/782] Loss_D: 1.6694 Loss_G: 2.4341\n",
      "[7/25][452/782] Loss_D: 1.6302 Loss_G: 5.1332\n",
      "[7/25][453/782] Loss_D: 0.9738 Loss_G: 2.9501\n",
      "[7/25][454/782] Loss_D: 0.4725 Loss_G: 1.6236\n",
      "[7/25][455/782] Loss_D: 1.3432 Loss_G: 4.3168\n",
      "[7/25][456/782] Loss_D: 0.7041 Loss_G: 3.2176\n",
      "[7/25][457/782] Loss_D: 0.4126 Loss_G: 2.2187\n",
      "[7/25][458/782] Loss_D: 0.4436 Loss_G: 2.9497\n",
      "[7/25][459/782] Loss_D: 0.7367 Loss_G: 4.9423\n",
      "[7/25][460/782] Loss_D: 0.8480 Loss_G: 2.4161\n",
      "[7/25][461/782] Loss_D: 0.3322 Loss_G: 2.2028\n",
      "[7/25][462/782] Loss_D: 0.3570 Loss_G: 3.7168\n",
      "[7/25][463/782] Loss_D: 0.4610 Loss_G: 4.9822\n",
      "[7/25][464/782] Loss_D: 0.5833 Loss_G: 3.0711\n",
      "[7/25][465/782] Loss_D: 0.2423 Loss_G: 2.9903\n",
      "[7/25][466/782] Loss_D: 0.7950 Loss_G: 4.3011\n",
      "[7/25][467/782] Loss_D: 0.3857 Loss_G: 3.9808\n",
      "[7/25][468/782] Loss_D: 0.2563 Loss_G: 3.6743\n",
      "[7/25][469/782] Loss_D: 0.0689 Loss_G: 5.2464\n",
      "[7/25][470/782] Loss_D: 0.1403 Loss_G: 4.4147\n",
      "[7/25][471/782] Loss_D: 0.0950 Loss_G: 3.1979\n",
      "[7/25][472/782] Loss_D: 0.7057 Loss_G: 6.1913\n",
      "[7/25][473/782] Loss_D: 0.4451 Loss_G: 3.7557\n",
      "[7/25][474/782] Loss_D: 0.2038 Loss_G: 3.0351\n",
      "[7/25][475/782] Loss_D: 0.0998 Loss_G: 4.1209\n",
      "[7/25][476/782] Loss_D: 0.2102 Loss_G: 4.5128\n",
      "[7/25][477/782] Loss_D: 0.4060 Loss_G: 6.2785\n",
      "[7/25][478/782] Loss_D: 2.0704 Loss_G: 2.7906\n",
      "[7/25][479/782] Loss_D: 2.2251 Loss_G: 8.0056\n",
      "[7/25][480/782] Loss_D: 3.5999 Loss_G: 3.5727\n",
      "[7/25][481/782] Loss_D: 0.5986 Loss_G: 0.5261\n",
      "[7/25][482/782] Loss_D: 1.3545 Loss_G: 3.8225\n",
      "[7/25][483/782] Loss_D: 0.3532 Loss_G: 3.9318\n",
      "[7/25][484/782] Loss_D: 0.4233 Loss_G: 2.5828\n",
      "[7/25][485/782] Loss_D: 0.2475 Loss_G: 2.9869\n",
      "[7/25][486/782] Loss_D: 0.6550 Loss_G: 3.4970\n",
      "[7/25][487/782] Loss_D: 0.9997 Loss_G: 1.4088\n",
      "[7/25][488/782] Loss_D: 0.6619 Loss_G: 4.3853\n",
      "[7/25][489/782] Loss_D: 0.6486 Loss_G: 1.3402\n",
      "[7/25][490/782] Loss_D: 2.3588 Loss_G: 8.4807\n",
      "[7/25][491/782] Loss_D: 3.5665 Loss_G: 1.4920\n",
      "[7/25][492/782] Loss_D: 0.6300 Loss_G: 1.3809\n",
      "[7/25][493/782] Loss_D: 1.0136 Loss_G: 4.6897\n",
      "[7/25][494/782] Loss_D: 0.8254 Loss_G: 2.9585\n",
      "[7/25][495/782] Loss_D: 0.4096 Loss_G: 1.7344\n",
      "[7/25][496/782] Loss_D: 1.0698 Loss_G: 4.0937\n",
      "[7/25][497/782] Loss_D: 1.1713 Loss_G: 1.6952\n",
      "[7/25][498/782] Loss_D: 0.6013 Loss_G: 2.8302\n",
      "[7/25][499/782] Loss_D: 0.4276 Loss_G: 3.0363\n",
      "[7/25][500/782] Loss_D: 0.4562 Loss_G: 2.8155\n",
      "[7/25][501/782] Loss_D: 0.3700 Loss_G: 2.9337\n",
      "[7/25][502/782] Loss_D: 0.3960 Loss_G: 3.0554\n",
      "[7/25][503/782] Loss_D: 0.3437 Loss_G: 3.9068\n",
      "[7/25][504/782] Loss_D: 0.3755 Loss_G: 2.5456\n",
      "[7/25][505/782] Loss_D: 0.3755 Loss_G: 2.5929\n",
      "[7/25][506/782] Loss_D: 0.2517 Loss_G: 3.8500\n",
      "[7/25][507/782] Loss_D: 0.2034 Loss_G: 3.4367\n",
      "[7/25][508/782] Loss_D: 0.2411 Loss_G: 2.8020\n",
      "[7/25][509/782] Loss_D: 0.2462 Loss_G: 3.2914\n",
      "[7/25][510/782] Loss_D: 0.2139 Loss_G: 3.8956\n",
      "[7/25][511/782] Loss_D: 0.1901 Loss_G: 3.5511\n",
      "[7/25][512/782] Loss_D: 0.0634 Loss_G: 4.0832\n",
      "[7/25][513/782] Loss_D: 0.1853 Loss_G: 3.1375\n",
      "[7/25][514/782] Loss_D: 0.1586 Loss_G: 3.4089\n",
      "[7/25][515/782] Loss_D: 0.1185 Loss_G: 3.8278\n",
      "[7/25][516/782] Loss_D: 0.0831 Loss_G: 4.2787\n",
      "[7/25][517/782] Loss_D: 0.1349 Loss_G: 3.8044\n",
      "[7/25][518/782] Loss_D: 0.1260 Loss_G: 3.6835\n",
      "[7/25][519/782] Loss_D: 0.0804 Loss_G: 3.7566\n",
      "[7/25][520/782] Loss_D: 0.2762 Loss_G: 4.4029\n",
      "[7/25][521/782] Loss_D: 0.1539 Loss_G: 4.1918\n",
      "[7/25][522/782] Loss_D: 0.0493 Loss_G: 4.3395\n",
      "[7/25][523/782] Loss_D: 0.0822 Loss_G: 3.9045\n",
      "[7/25][524/782] Loss_D: 0.1130 Loss_G: 3.5302\n",
      "[7/25][525/782] Loss_D: 0.0743 Loss_G: 3.9679\n",
      "[7/25][526/782] Loss_D: 0.0915 Loss_G: 3.5964\n",
      "[7/25][527/782] Loss_D: 0.1785 Loss_G: 4.1634\n",
      "[7/25][528/782] Loss_D: 0.0880 Loss_G: 4.3221\n",
      "[7/25][529/782] Loss_D: 0.1697 Loss_G: 3.5536\n",
      "[7/25][530/782] Loss_D: 0.2201 Loss_G: 4.4059\n",
      "[7/25][531/782] Loss_D: 0.0485 Loss_G: 5.3056\n",
      "[7/25][532/782] Loss_D: 0.2190 Loss_G: 2.7913\n",
      "[7/25][533/782] Loss_D: 0.1425 Loss_G: 4.0435\n",
      "[7/25][534/782] Loss_D: 0.0775 Loss_G: 4.5410\n",
      "[7/25][535/782] Loss_D: 0.0987 Loss_G: 4.2907\n",
      "[7/25][536/782] Loss_D: 0.1887 Loss_G: 3.3898\n",
      "[7/25][537/782] Loss_D: 0.0935 Loss_G: 3.7251\n",
      "[7/25][538/782] Loss_D: 0.1064 Loss_G: 3.9528\n",
      "[7/25][539/782] Loss_D: 0.0787 Loss_G: 3.9974\n",
      "[7/25][540/782] Loss_D: 0.0921 Loss_G: 3.9429\n",
      "[7/25][541/782] Loss_D: 0.0753 Loss_G: 4.2499\n",
      "[7/25][542/782] Loss_D: 0.0651 Loss_G: 4.5869\n",
      "[7/25][543/782] Loss_D: 0.1214 Loss_G: 3.7660\n",
      "[7/25][544/782] Loss_D: 0.0992 Loss_G: 4.0656\n",
      "[7/25][545/782] Loss_D: 0.0405 Loss_G: 4.7183\n",
      "[7/25][546/782] Loss_D: 0.0784 Loss_G: 4.4824\n",
      "[7/25][547/782] Loss_D: 0.0924 Loss_G: 4.2523\n",
      "[7/25][548/782] Loss_D: 0.0772 Loss_G: 4.4125\n",
      "[7/25][549/782] Loss_D: 0.0452 Loss_G: 4.7279\n",
      "[7/25][550/782] Loss_D: 0.0194 Loss_G: 5.4984\n",
      "[7/25][551/782] Loss_D: 0.0671 Loss_G: 3.9781\n",
      "[7/25][552/782] Loss_D: 0.0632 Loss_G: 4.1081\n",
      "[7/25][553/782] Loss_D: 0.0472 Loss_G: 4.4387\n",
      "[7/25][554/782] Loss_D: 0.0882 Loss_G: 4.2882\n",
      "[7/25][555/782] Loss_D: 0.0686 Loss_G: 4.7931\n",
      "[7/25][556/782] Loss_D: 0.0363 Loss_G: 4.7200\n",
      "[7/25][557/782] Loss_D: 0.0360 Loss_G: 4.5504\n",
      "[7/25][558/782] Loss_D: 0.0584 Loss_G: 4.7040\n",
      "[7/25][559/782] Loss_D: 0.0632 Loss_G: 4.5751\n",
      "[7/25][560/782] Loss_D: 0.0447 Loss_G: 4.6317\n",
      "[7/25][561/782] Loss_D: 0.0632 Loss_G: 5.0058\n",
      "[7/25][562/782] Loss_D: 0.1491 Loss_G: 6.2824\n",
      "[7/25][563/782] Loss_D: 0.0805 Loss_G: 6.5980\n",
      "[7/25][564/782] Loss_D: 0.0766 Loss_G: 4.1197\n",
      "[7/25][565/782] Loss_D: 0.0186 Loss_G: 6.3736\n",
      "[7/25][566/782] Loss_D: 0.0715 Loss_G: 5.0702\n",
      "[7/25][567/782] Loss_D: 0.0256 Loss_G: 5.6478\n",
      "[7/25][568/782] Loss_D: 0.0215 Loss_G: 5.6933\n",
      "[7/25][569/782] Loss_D: 0.0267 Loss_G: 4.8860\n",
      "[7/25][570/782] Loss_D: 0.0159 Loss_G: 5.4825\n",
      "[7/25][571/782] Loss_D: 0.0554 Loss_G: 4.3515\n",
      "[7/25][572/782] Loss_D: 0.0208 Loss_G: 5.4364\n",
      "[7/25][573/782] Loss_D: 0.0493 Loss_G: 4.6636\n",
      "[7/25][574/782] Loss_D: 0.0348 Loss_G: 5.3148\n",
      "[7/25][575/782] Loss_D: 0.0344 Loss_G: 4.7382\n",
      "[7/25][576/782] Loss_D: 0.0528 Loss_G: 4.6014\n",
      "[7/25][577/782] Loss_D: 0.0588 Loss_G: 4.3619\n",
      "[7/25][578/782] Loss_D: 0.0393 Loss_G: 4.8072\n",
      "[7/25][579/782] Loss_D: 0.0814 Loss_G: 4.5634\n",
      "[7/25][580/782] Loss_D: 0.0306 Loss_G: 5.2039\n",
      "[7/25][581/782] Loss_D: 0.0401 Loss_G: 4.6073\n",
      "[7/25][582/782] Loss_D: 0.0477 Loss_G: 4.9188\n",
      "[7/25][583/782] Loss_D: 0.0656 Loss_G: 4.4224\n",
      "[7/25][584/782] Loss_D: 0.0673 Loss_G: 5.0637\n",
      "[7/25][585/782] Loss_D: 0.0382 Loss_G: 5.2373\n",
      "[7/25][586/782] Loss_D: 0.0657 Loss_G: 5.3733\n",
      "[7/25][587/782] Loss_D: 0.1555 Loss_G: 5.4387\n",
      "[7/25][588/782] Loss_D: 0.2544 Loss_G: 3.7177\n",
      "[7/25][589/782] Loss_D: 0.0263 Loss_G: 3.9065\n",
      "[7/25][590/782] Loss_D: 1.4393 Loss_G: 15.6154\n",
      "[7/25][591/782] Loss_D: 7.8357 Loss_G: 9.7365\n",
      "[7/25][592/782] Loss_D: 1.9915 Loss_G: 0.5647\n",
      "[7/25][593/782] Loss_D: 2.8170 Loss_G: 4.6740\n",
      "[7/25][594/782] Loss_D: 0.4927 Loss_G: 3.9631\n",
      "[7/25][595/782] Loss_D: 0.5543 Loss_G: 1.6762\n",
      "[7/25][596/782] Loss_D: 1.0801 Loss_G: 4.5587\n",
      "[7/25][597/782] Loss_D: 0.4476 Loss_G: 3.7239\n",
      "[7/25][598/782] Loss_D: 0.4613 Loss_G: 2.1960\n",
      "[7/25][599/782] Loss_D: 0.6066 Loss_G: 4.6535\n",
      "[7/25][600/782] Loss_D: 0.4614 Loss_G: 3.3229\n",
      "[7/25][601/782] Loss_D: 0.3770 Loss_G: 4.0705\n",
      "[7/25][602/782] Loss_D: 0.4359 Loss_G: 3.4238\n",
      "[7/25][603/782] Loss_D: 0.4793 Loss_G: 5.1399\n",
      "[7/25][604/782] Loss_D: 1.0040 Loss_G: 0.9582\n",
      "[7/25][605/782] Loss_D: 1.2146 Loss_G: 7.9121\n",
      "[7/25][606/782] Loss_D: 1.3123 Loss_G: 4.6072\n",
      "[7/25][607/782] Loss_D: 0.1535 Loss_G: 2.5957\n",
      "[7/25][608/782] Loss_D: 0.4317 Loss_G: 4.1632\n",
      "[7/25][609/782] Loss_D: 0.1403 Loss_G: 4.5224\n",
      "[7/25][610/782] Loss_D: 0.3386 Loss_G: 2.9728\n",
      "[7/25][611/782] Loss_D: 0.2319 Loss_G: 3.6311\n",
      "[7/25][612/782] Loss_D: 0.3292 Loss_G: 4.7645\n",
      "[7/25][613/782] Loss_D: 0.2431 Loss_G: 4.1907\n",
      "[7/25][614/782] Loss_D: 0.4728 Loss_G: 1.8259\n",
      "[7/25][615/782] Loss_D: 0.6765 Loss_G: 7.7278\n",
      "[7/25][616/782] Loss_D: 0.7137 Loss_G: 4.3762\n",
      "[7/25][617/782] Loss_D: 0.3668 Loss_G: 3.5077\n",
      "[7/25][618/782] Loss_D: 0.3665 Loss_G: 4.9835\n",
      "[7/25][619/782] Loss_D: 0.5114 Loss_G: 2.6094\n",
      "[7/25][620/782] Loss_D: 0.5164 Loss_G: 6.7260\n",
      "[7/25][621/782] Loss_D: 0.3233 Loss_G: 4.9909\n",
      "[7/25][622/782] Loss_D: 0.1718 Loss_G: 3.0365\n",
      "[7/25][623/782] Loss_D: 0.3760 Loss_G: 4.9287\n",
      "[7/25][624/782] Loss_D: 0.1662 Loss_G: 4.6798\n",
      "[7/25][625/782] Loss_D: 0.1376 Loss_G: 3.7199\n",
      "[7/25][626/782] Loss_D: 0.0975 Loss_G: 3.9873\n",
      "[7/25][627/782] Loss_D: 0.1116 Loss_G: 4.6548\n",
      "[7/25][628/782] Loss_D: 0.0443 Loss_G: 4.9352\n",
      "[7/25][629/782] Loss_D: 0.1356 Loss_G: 4.4643\n",
      "[7/25][630/782] Loss_D: 0.1501 Loss_G: 3.9798\n",
      "[7/25][631/782] Loss_D: 0.1426 Loss_G: 3.4001\n",
      "[7/25][632/782] Loss_D: 0.2161 Loss_G: 4.7246\n",
      "[7/25][633/782] Loss_D: 0.1166 Loss_G: 4.6389\n",
      "[7/25][634/782] Loss_D: 0.3243 Loss_G: 2.9667\n",
      "[7/25][635/782] Loss_D: 0.1121 Loss_G: 3.8575\n",
      "[7/25][636/782] Loss_D: 0.0929 Loss_G: 4.7901\n",
      "[7/25][637/782] Loss_D: 0.1670 Loss_G: 5.2810\n",
      "[7/25][638/782] Loss_D: 0.2267 Loss_G: 3.5910\n",
      "[7/25][639/782] Loss_D: 0.1252 Loss_G: 4.3998\n",
      "[7/25][640/782] Loss_D: 0.0639 Loss_G: 4.6596\n",
      "[7/25][641/782] Loss_D: 0.1280 Loss_G: 3.6239\n",
      "[7/25][642/782] Loss_D: 0.0286 Loss_G: 4.8882\n",
      "[7/25][643/782] Loss_D: 0.1861 Loss_G: 5.6401\n",
      "[7/25][644/782] Loss_D: 0.3381 Loss_G: 3.4718\n",
      "[7/25][645/782] Loss_D: 0.2218 Loss_G: 7.4185\n",
      "[7/25][646/782] Loss_D: 1.0157 Loss_G: 3.4849\n",
      "[7/25][647/782] Loss_D: 0.9939 Loss_G: 9.9598\n",
      "[7/25][648/782] Loss_D: 6.6595 Loss_G: 4.4519\n",
      "[7/25][649/782] Loss_D: 1.6553 Loss_G: 0.0958\n",
      "[7/25][650/782] Loss_D: 4.0804 Loss_G: 1.8231\n",
      "[7/25][651/782] Loss_D: 0.7125 Loss_G: 5.9063\n",
      "[7/25][652/782] Loss_D: 1.8316 Loss_G: 2.4372\n",
      "[7/25][653/782] Loss_D: 0.3919 Loss_G: 1.4994\n",
      "[7/25][654/782] Loss_D: 1.2423 Loss_G: 3.6278\n",
      "[7/25][655/782] Loss_D: 0.6059 Loss_G: 3.5381\n",
      "[7/25][656/782] Loss_D: 0.5871 Loss_G: 2.1723\n",
      "[7/25][657/782] Loss_D: 0.7393 Loss_G: 2.0808\n",
      "[7/25][658/782] Loss_D: 0.8176 Loss_G: 2.7827\n",
      "[7/25][659/782] Loss_D: 0.6053 Loss_G: 2.6146\n",
      "[7/25][660/782] Loss_D: 0.7164 Loss_G: 2.6987\n",
      "[7/25][661/782] Loss_D: 0.5094 Loss_G: 2.5276\n",
      "[7/25][662/782] Loss_D: 0.6680 Loss_G: 3.4329\n",
      "[7/25][663/782] Loss_D: 0.5668 Loss_G: 2.0499\n",
      "[7/25][664/782] Loss_D: 0.6068 Loss_G: 4.5324\n",
      "[7/25][665/782] Loss_D: 0.8288 Loss_G: 1.9596\n",
      "[7/25][666/782] Loss_D: 0.5623 Loss_G: 3.7355\n",
      "[7/25][667/782] Loss_D: 0.3551 Loss_G: 3.3488\n",
      "[7/25][668/782] Loss_D: 0.2580 Loss_G: 3.4307\n",
      "[7/25][669/782] Loss_D: 0.2888 Loss_G: 2.8124\n",
      "[7/25][670/782] Loss_D: 0.4378 Loss_G: 4.7632\n",
      "[7/25][671/782] Loss_D: 0.6384 Loss_G: 1.5127\n",
      "[7/25][672/782] Loss_D: 0.9993 Loss_G: 6.0316\n",
      "[7/25][673/782] Loss_D: 0.8326 Loss_G: 3.3180\n",
      "[7/25][674/782] Loss_D: 0.1212 Loss_G: 2.7970\n",
      "[7/25][675/782] Loss_D: 0.1764 Loss_G: 3.7743\n",
      "[7/25][676/782] Loss_D: 0.1358 Loss_G: 4.0328\n",
      "[7/25][677/782] Loss_D: 0.2966 Loss_G: 3.2779\n",
      "[7/25][678/782] Loss_D: 0.2140 Loss_G: 3.8874\n",
      "[7/25][679/782] Loss_D: 0.1717 Loss_G: 4.2269\n",
      "[7/25][680/782] Loss_D: 0.3339 Loss_G: 2.2827\n",
      "[7/25][681/782] Loss_D: 0.5564 Loss_G: 6.8389\n",
      "[7/25][682/782] Loss_D: 0.9962 Loss_G: 3.0879\n",
      "[7/25][683/782] Loss_D: 0.2780 Loss_G: 3.2075\n",
      "[7/25][684/782] Loss_D: 0.9052 Loss_G: 0.8283\n",
      "[7/25][685/782] Loss_D: 1.3996 Loss_G: 7.1357\n",
      "[7/25][686/782] Loss_D: 2.9378 Loss_G: 2.3863\n",
      "[7/25][687/782] Loss_D: 0.4594 Loss_G: 1.5382\n",
      "[7/25][688/782] Loss_D: 0.5007 Loss_G: 3.4276\n",
      "[7/25][689/782] Loss_D: 0.3971 Loss_G: 4.0581\n",
      "[7/25][690/782] Loss_D: 0.9149 Loss_G: 1.2007\n",
      "[7/25][691/782] Loss_D: 0.7457 Loss_G: 3.4336\n",
      "[7/25][692/782] Loss_D: 0.3851 Loss_G: 3.7755\n",
      "[7/25][693/782] Loss_D: 0.6099 Loss_G: 2.3738\n",
      "[7/25][694/782] Loss_D: 0.3875 Loss_G: 2.7752\n",
      "[7/25][695/782] Loss_D: 0.4457 Loss_G: 3.7649\n",
      "[7/25][696/782] Loss_D: 0.6247 Loss_G: 1.9309\n",
      "[7/25][697/782] Loss_D: 0.8475 Loss_G: 4.2198\n",
      "[7/25][698/782] Loss_D: 0.4534 Loss_G: 3.4922\n",
      "[7/25][699/782] Loss_D: 0.5213 Loss_G: 1.6112\n",
      "[7/25][700/782] Loss_D: 0.5537 Loss_G: 3.6406\n",
      "[7/25][701/782] Loss_D: 0.3871 Loss_G: 3.2363\n",
      "[7/25][702/782] Loss_D: 0.2965 Loss_G: 2.4953\n",
      "[7/25][703/782] Loss_D: 0.3225 Loss_G: 3.3372\n",
      "[7/25][704/782] Loss_D: 0.4523 Loss_G: 3.3057\n",
      "[7/25][705/782] Loss_D: 0.3628 Loss_G: 2.0904\n",
      "[7/25][706/782] Loss_D: 0.3071 Loss_G: 4.6395\n",
      "[7/25][707/782] Loss_D: 0.1498 Loss_G: 4.4999\n",
      "[7/25][708/782] Loss_D: 0.3859 Loss_G: 1.9270\n",
      "[7/25][709/782] Loss_D: 0.7131 Loss_G: 6.9489\n",
      "[7/25][710/782] Loss_D: 1.2050 Loss_G: 3.7703\n",
      "[7/25][711/782] Loss_D: 0.1753 Loss_G: 2.6116\n",
      "[7/25][712/782] Loss_D: 0.8859 Loss_G: 2.3706\n",
      "[7/25][713/782] Loss_D: 0.9108 Loss_G: 3.0884\n",
      "[7/25][714/782] Loss_D: 0.4896 Loss_G: 3.1981\n",
      "[7/25][715/782] Loss_D: 0.5142 Loss_G: 1.3825\n",
      "[7/25][716/782] Loss_D: 1.4426 Loss_G: 9.3882\n",
      "[7/25][717/782] Loss_D: 2.8491 Loss_G: 3.4813\n",
      "[7/25][718/782] Loss_D: 0.4705 Loss_G: 0.7493\n",
      "[7/25][719/782] Loss_D: 1.4205 Loss_G: 5.2224\n",
      "[7/25][720/782] Loss_D: 0.8642 Loss_G: 1.9185\n",
      "[7/25][721/782] Loss_D: 0.5665 Loss_G: 3.3978\n",
      "[7/25][722/782] Loss_D: 0.3787 Loss_G: 3.1200\n",
      "[7/25][723/782] Loss_D: 0.5916 Loss_G: 2.7394\n",
      "[7/25][724/782] Loss_D: 0.3016 Loss_G: 3.7078\n",
      "[7/25][725/782] Loss_D: 0.2937 Loss_G: 3.1523\n",
      "[7/25][726/782] Loss_D: 0.2777 Loss_G: 2.1955\n",
      "[7/25][727/782] Loss_D: 0.8854 Loss_G: 6.5113\n",
      "[7/25][728/782] Loss_D: 0.9957 Loss_G: 2.7669\n",
      "[7/25][729/782] Loss_D: 0.1885 Loss_G: 3.2236\n",
      "[7/25][730/782] Loss_D: 0.1285 Loss_G: 4.2024\n",
      "[7/25][731/782] Loss_D: 0.1466 Loss_G: 3.8280\n",
      "[7/25][732/782] Loss_D: 0.1175 Loss_G: 3.7798\n",
      "[7/25][733/782] Loss_D: 0.1610 Loss_G: 3.9514\n",
      "[7/25][734/782] Loss_D: 0.0791 Loss_G: 4.3197\n",
      "[7/25][735/782] Loss_D: 0.1430 Loss_G: 3.4430\n",
      "[7/25][736/782] Loss_D: 0.1007 Loss_G: 3.7177\n",
      "[7/25][737/782] Loss_D: 0.1249 Loss_G: 3.3652\n",
      "[7/25][738/782] Loss_D: 0.2863 Loss_G: 5.9178\n",
      "[7/25][739/782] Loss_D: 0.5117 Loss_G: 1.5115\n",
      "[7/25][740/782] Loss_D: 0.8029 Loss_G: 8.0969\n",
      "[7/25][741/782] Loss_D: 3.6935 Loss_G: 1.5032\n",
      "[7/25][742/782] Loss_D: 0.3057 Loss_G: 1.7068\n",
      "[7/25][743/782] Loss_D: 1.2219 Loss_G: 6.0862\n",
      "[7/25][744/782] Loss_D: 2.0153 Loss_G: 1.8390\n",
      "[7/25][745/782] Loss_D: 0.5030 Loss_G: 3.6774\n",
      "[7/25][746/782] Loss_D: 0.4300 Loss_G: 4.8008\n",
      "[7/25][747/782] Loss_D: 1.1135 Loss_G: 1.7546\n",
      "[7/25][748/782] Loss_D: 0.7254 Loss_G: 5.3355\n",
      "[7/25][749/782] Loss_D: 0.2638 Loss_G: 4.3529\n",
      "[7/25][750/782] Loss_D: 0.5908 Loss_G: 2.0171\n",
      "[7/25][751/782] Loss_D: 0.7181 Loss_G: 5.0107\n",
      "[7/25][752/782] Loss_D: 0.2048 Loss_G: 4.5145\n",
      "[7/25][753/782] Loss_D: 0.5721 Loss_G: 2.1481\n",
      "[7/25][754/782] Loss_D: 0.6006 Loss_G: 4.9478\n",
      "[7/25][755/782] Loss_D: 0.3803 Loss_G: 2.9300\n",
      "[7/25][756/782] Loss_D: 0.2567 Loss_G: 3.1423\n",
      "[7/25][757/782] Loss_D: 0.4091 Loss_G: 4.8556\n",
      "[7/25][758/782] Loss_D: 0.0997 Loss_G: 4.9290\n",
      "[7/25][759/782] Loss_D: 0.1466 Loss_G: 3.7761\n",
      "[7/25][760/782] Loss_D: 0.1652 Loss_G: 3.0299\n",
      "[7/25][761/782] Loss_D: 0.2082 Loss_G: 3.9525\n",
      "[7/25][762/782] Loss_D: 0.0620 Loss_G: 4.6995\n",
      "[7/25][763/782] Loss_D: 0.1867 Loss_G: 4.3192\n",
      "[7/25][764/782] Loss_D: 0.3733 Loss_G: 2.5584\n",
      "[7/25][765/782] Loss_D: 0.0954 Loss_G: 3.6403\n",
      "[7/25][766/782] Loss_D: 0.0642 Loss_G: 4.3941\n",
      "[7/25][767/782] Loss_D: 0.1050 Loss_G: 4.6638\n",
      "[7/25][768/782] Loss_D: 0.0340 Loss_G: 5.5387\n",
      "[7/25][769/782] Loss_D: 0.1486 Loss_G: 3.3841\n",
      "[7/25][770/782] Loss_D: 0.0618 Loss_G: 4.1784\n",
      "[7/25][771/782] Loss_D: 0.0591 Loss_G: 4.3863\n",
      "[7/25][772/782] Loss_D: 0.1543 Loss_G: 4.9705\n",
      "[7/25][773/782] Loss_D: 0.0471 Loss_G: 5.1650\n",
      "[7/25][774/782] Loss_D: 0.0587 Loss_G: 5.0824\n",
      "[7/25][775/782] Loss_D: 0.0487 Loss_G: 4.1996\n",
      "[7/25][776/782] Loss_D: 0.1347 Loss_G: 4.2811\n",
      "[7/25][777/782] Loss_D: 0.0440 Loss_G: 5.0326\n",
      "[7/25][778/782] Loss_D: 0.0317 Loss_G: 4.7315\n",
      "[7/25][779/782] Loss_D: 0.0545 Loss_G: 4.3065\n",
      "[7/25][780/782] Loss_D: 0.0530 Loss_G: 4.3785\n",
      "[7/25][781/782] Loss_D: 0.1168 Loss_G: 3.9975\n",
      "[8/25][0/782] Loss_D: 0.1557 Loss_G: 4.2418\n",
      "[8/25][1/782] Loss_D: 0.0257 Loss_G: 5.1977\n",
      "[8/25][2/782] Loss_D: 0.0650 Loss_G: 4.4370\n",
      "[8/25][3/782] Loss_D: 0.0383 Loss_G: 4.9588\n",
      "[8/25][4/782] Loss_D: 0.0560 Loss_G: 4.3732\n",
      "[8/25][5/782] Loss_D: 0.0731 Loss_G: 4.4528\n",
      "[8/25][6/782] Loss_D: 0.1019 Loss_G: 4.1036\n",
      "[8/25][7/782] Loss_D: 0.0562 Loss_G: 4.5197\n",
      "[8/25][8/782] Loss_D: 0.0468 Loss_G: 4.7849\n",
      "[8/25][9/782] Loss_D: 0.0605 Loss_G: 4.6282\n",
      "[8/25][10/782] Loss_D: 0.1080 Loss_G: 3.7472\n",
      "[8/25][11/782] Loss_D: 0.0174 Loss_G: 5.1802\n",
      "[8/25][12/782] Loss_D: 0.0405 Loss_G: 4.3469\n",
      "[8/25][13/782] Loss_D: 0.0484 Loss_G: 4.4324\n",
      "[8/25][14/782] Loss_D: 0.0431 Loss_G: 4.4517\n",
      "[8/25][15/782] Loss_D: 0.0967 Loss_G: 4.5125\n",
      "[8/25][16/782] Loss_D: 0.0293 Loss_G: 5.8402\n",
      "[8/25][17/782] Loss_D: 0.1118 Loss_G: 4.5310\n",
      "[8/25][18/782] Loss_D: 0.1544 Loss_G: 5.2443\n",
      "[8/25][19/782] Loss_D: 0.1242 Loss_G: 4.8485\n",
      "[8/25][20/782] Loss_D: 0.0924 Loss_G: 4.9241\n",
      "[8/25][21/782] Loss_D: 0.0286 Loss_G: 4.3178\n",
      "[8/25][22/782] Loss_D: 0.0698 Loss_G: 5.4992\n",
      "[8/25][23/782] Loss_D: 0.0206 Loss_G: 5.8952\n",
      "[8/25][24/782] Loss_D: 0.0408 Loss_G: 4.9385\n",
      "[8/25][25/782] Loss_D: 0.0743 Loss_G: 5.4050\n",
      "[8/25][26/782] Loss_D: 0.0755 Loss_G: 4.5896\n",
      "[8/25][27/782] Loss_D: 0.0219 Loss_G: 5.0704\n",
      "[8/25][28/782] Loss_D: 0.0478 Loss_G: 4.6346\n",
      "[8/25][29/782] Loss_D: 0.0510 Loss_G: 4.5563\n",
      "[8/25][30/782] Loss_D: 0.0320 Loss_G: 5.1346\n",
      "[8/25][31/782] Loss_D: 0.0235 Loss_G: 5.9952\n",
      "[8/25][32/782] Loss_D: 0.1509 Loss_G: 5.0692\n",
      "[8/25][33/782] Loss_D: 0.0366 Loss_G: 6.9897\n",
      "[8/25][34/782] Loss_D: 0.0697 Loss_G: 4.4517\n",
      "[8/25][35/782] Loss_D: 0.0539 Loss_G: 3.9263\n",
      "[8/25][36/782] Loss_D: 0.0190 Loss_G: 4.9273\n",
      "[8/25][37/782] Loss_D: 0.0514 Loss_G: 4.3677\n",
      "[8/25][38/782] Loss_D: 0.0395 Loss_G: 4.7605\n",
      "[8/25][39/782] Loss_D: 0.0693 Loss_G: 4.3823\n",
      "[8/25][40/782] Loss_D: 0.0370 Loss_G: 5.3275\n",
      "[8/25][41/782] Loss_D: 0.3433 Loss_G: 8.0242\n",
      "[8/25][42/782] Loss_D: 1.9105 Loss_G: 5.3812\n",
      "[8/25][43/782] Loss_D: 3.1613 Loss_G: 0.0168\n",
      "[8/25][44/782] Loss_D: 5.3586 Loss_G: 4.6918\n",
      "[8/25][45/782] Loss_D: 1.1370 Loss_G: 2.3745\n",
      "[8/25][46/782] Loss_D: 0.5462 Loss_G: 1.9409\n",
      "[8/25][47/782] Loss_D: 0.7650 Loss_G: 3.4956\n",
      "[8/25][48/782] Loss_D: 0.7173 Loss_G: 2.4146\n",
      "[8/25][49/782] Loss_D: 0.5917 Loss_G: 1.9540\n",
      "[8/25][50/782] Loss_D: 0.7256 Loss_G: 3.4072\n",
      "[8/25][51/782] Loss_D: 0.6791 Loss_G: 2.1381\n",
      "[8/25][52/782] Loss_D: 0.6084 Loss_G: 3.0251\n",
      "[8/25][53/782] Loss_D: 0.6174 Loss_G: 2.1616\n",
      "[8/25][54/782] Loss_D: 0.6537 Loss_G: 2.8609\n",
      "[8/25][55/782] Loss_D: 0.5365 Loss_G: 2.5232\n",
      "[8/25][56/782] Loss_D: 0.8570 Loss_G: 2.0646\n",
      "[8/25][57/782] Loss_D: 0.4108 Loss_G: 3.5656\n",
      "[8/25][58/782] Loss_D: 0.3281 Loss_G: 3.3319\n",
      "[8/25][59/782] Loss_D: 0.8621 Loss_G: 1.1374\n",
      "[8/25][60/782] Loss_D: 0.8324 Loss_G: 3.8380\n",
      "[8/25][61/782] Loss_D: 0.5019 Loss_G: 2.9517\n",
      "[8/25][62/782] Loss_D: 0.5945 Loss_G: 1.7591\n",
      "[8/25][63/782] Loss_D: 0.5862 Loss_G: 4.1425\n",
      "[8/25][64/782] Loss_D: 0.3254 Loss_G: 3.4366\n",
      "[8/25][65/782] Loss_D: 0.3185 Loss_G: 2.6725\n",
      "[8/25][66/782] Loss_D: 0.4010 Loss_G: 3.2619\n",
      "[8/25][67/782] Loss_D: 0.5722 Loss_G: 2.4436\n",
      "[8/25][68/782] Loss_D: 0.3613 Loss_G: 3.1384\n",
      "[8/25][69/782] Loss_D: 0.4420 Loss_G: 2.8281\n",
      "[8/25][70/782] Loss_D: 0.5761 Loss_G: 2.4415\n",
      "[8/25][71/782] Loss_D: 0.8984 Loss_G: 3.4527\n",
      "[8/25][72/782] Loss_D: 0.6519 Loss_G: 1.7744\n",
      "[8/25][73/782] Loss_D: 0.7021 Loss_G: 3.9206\n",
      "[8/25][74/782] Loss_D: 0.7004 Loss_G: 1.8278\n",
      "[8/25][75/782] Loss_D: 0.6264 Loss_G: 4.2249\n",
      "[8/25][76/782] Loss_D: 1.0079 Loss_G: 0.7470\n",
      "[8/25][77/782] Loss_D: 1.4400 Loss_G: 6.1051\n",
      "[8/25][78/782] Loss_D: 1.3844 Loss_G: 2.4324\n",
      "[8/25][79/782] Loss_D: 0.4683 Loss_G: 2.3412\n",
      "[8/25][80/782] Loss_D: 0.3963 Loss_G: 3.5730\n",
      "[8/25][81/782] Loss_D: 0.5630 Loss_G: 1.8973\n",
      "[8/25][82/782] Loss_D: 0.7682 Loss_G: 4.2574\n",
      "[8/25][83/782] Loss_D: 0.7653 Loss_G: 2.2212\n",
      "[8/25][84/782] Loss_D: 0.5726 Loss_G: 2.6881\n",
      "[8/25][85/782] Loss_D: 0.4774 Loss_G: 2.9590\n",
      "[8/25][86/782] Loss_D: 0.3066 Loss_G: 2.8221\n",
      "[8/25][87/782] Loss_D: 0.3766 Loss_G: 2.9881\n",
      "[8/25][88/782] Loss_D: 0.4764 Loss_G: 3.2804\n",
      "[8/25][89/782] Loss_D: 0.4075 Loss_G: 2.6077\n",
      "[8/25][90/782] Loss_D: 0.3788 Loss_G: 2.6880\n",
      "[8/25][91/782] Loss_D: 0.4359 Loss_G: 2.8164\n",
      "[8/25][92/782] Loss_D: 0.2987 Loss_G: 3.0611\n",
      "[8/25][93/782] Loss_D: 0.4107 Loss_G: 2.5330\n",
      "[8/25][94/782] Loss_D: 0.4680 Loss_G: 2.5856\n",
      "[8/25][95/782] Loss_D: 0.3030 Loss_G: 3.2537\n",
      "[8/25][96/782] Loss_D: 0.4152 Loss_G: 2.4447\n",
      "[8/25][97/782] Loss_D: 0.3125 Loss_G: 2.7018\n",
      "[8/25][98/782] Loss_D: 0.3882 Loss_G: 4.3977\n",
      "[8/25][99/782] Loss_D: 0.4374 Loss_G: 2.1050\n",
      "[8/25][100/782] Loss_D: 0.3543 Loss_G: 4.4504\n",
      "[8/25][101/782] Loss_D: 0.2587 Loss_G: 3.0359\n",
      "[8/25][102/782] Loss_D: 0.2498 Loss_G: 3.2009\n",
      "[8/25][103/782] Loss_D: 0.2893 Loss_G: 2.8797\n",
      "[8/25][104/782] Loss_D: 0.3149 Loss_G: 3.7298\n",
      "[8/25][105/782] Loss_D: 0.2489 Loss_G: 2.7080\n",
      "[8/25][106/782] Loss_D: 0.3631 Loss_G: 2.5293\n",
      "[8/25][107/782] Loss_D: 0.4378 Loss_G: 6.4063\n",
      "[8/25][108/782] Loss_D: 1.1957 Loss_G: 0.7000\n",
      "[8/25][109/782] Loss_D: 1.2615 Loss_G: 7.2481\n",
      "[8/25][110/782] Loss_D: 2.5720 Loss_G: 1.1574\n",
      "[8/25][111/782] Loss_D: 1.0661 Loss_G: 3.9045\n",
      "[8/25][112/782] Loss_D: 0.7748 Loss_G: 2.1077\n",
      "[8/25][113/782] Loss_D: 0.6444 Loss_G: 4.8186\n",
      "[8/25][114/782] Loss_D: 0.4253 Loss_G: 3.1964\n",
      "[8/25][115/782] Loss_D: 0.3319 Loss_G: 2.3817\n",
      "[8/25][116/782] Loss_D: 0.8451 Loss_G: 8.0081\n",
      "[8/25][117/782] Loss_D: 2.6355 Loss_G: 1.3181\n",
      "[8/25][118/782] Loss_D: 0.7646 Loss_G: 3.1814\n",
      "[8/25][119/782] Loss_D: 0.3613 Loss_G: 3.8048\n",
      "[8/25][120/782] Loss_D: 0.4691 Loss_G: 1.8609\n",
      "[8/25][121/782] Loss_D: 0.7342 Loss_G: 4.9042\n",
      "[8/25][122/782] Loss_D: 0.2538 Loss_G: 4.0549\n",
      "[8/25][123/782] Loss_D: 0.0955 Loss_G: 3.8218\n",
      "[8/25][124/782] Loss_D: 0.1944 Loss_G: 3.5684\n",
      "[8/25][125/782] Loss_D: 0.1667 Loss_G: 3.9927\n",
      "[8/25][126/782] Loss_D: 0.0928 Loss_G: 4.3086\n",
      "[8/25][127/782] Loss_D: 0.1703 Loss_G: 3.3717\n",
      "[8/25][128/782] Loss_D: 0.1010 Loss_G: 4.1541\n",
      "[8/25][129/782] Loss_D: 0.1300 Loss_G: 3.9192\n",
      "[8/25][130/782] Loss_D: 0.1715 Loss_G: 3.8579\n",
      "[8/25][131/782] Loss_D: 0.1101 Loss_G: 4.1130\n",
      "[8/25][132/782] Loss_D: 0.0682 Loss_G: 4.3944\n",
      "[8/25][133/782] Loss_D: 0.1592 Loss_G: 3.4785\n",
      "[8/25][134/782] Loss_D: 0.3127 Loss_G: 6.5940\n",
      "[8/25][135/782] Loss_D: 0.3115 Loss_G: 4.6968\n",
      "[8/25][136/782] Loss_D: 0.0731 Loss_G: 3.4162\n",
      "[8/25][137/782] Loss_D: 0.3247 Loss_G: 5.6108\n",
      "[8/25][138/782] Loss_D: 0.6267 Loss_G: 3.4220\n",
      "[8/25][139/782] Loss_D: 0.0881 Loss_G: 3.8946\n",
      "[8/25][140/782] Loss_D: 0.6126 Loss_G: 0.2125\n",
      "[8/25][141/782] Loss_D: 2.8819 Loss_G: 12.1147\n",
      "[8/25][142/782] Loss_D: 6.7781 Loss_G: 6.6524\n",
      "[8/25][143/782] Loss_D: 2.6181 Loss_G: 0.3774\n",
      "[8/25][144/782] Loss_D: 1.6106 Loss_G: 2.6927\n",
      "[8/25][145/782] Loss_D: 0.9636 Loss_G: 5.1470\n",
      "[8/25][146/782] Loss_D: 1.9169 Loss_G: 1.5099\n",
      "[8/25][147/782] Loss_D: 0.9207 Loss_G: 1.7751\n",
      "[8/25][148/782] Loss_D: 0.5485 Loss_G: 3.2147\n",
      "[8/25][149/782] Loss_D: 0.7982 Loss_G: 3.0678\n",
      "[8/25][150/782] Loss_D: 0.6606 Loss_G: 1.9012\n",
      "[8/25][151/782] Loss_D: 1.2290 Loss_G: 5.4888\n",
      "[8/25][152/782] Loss_D: 2.4173 Loss_G: 1.0174\n",
      "[8/25][153/782] Loss_D: 1.6698 Loss_G: 4.1613\n",
      "[8/25][154/782] Loss_D: 0.7314 Loss_G: 2.9353\n",
      "[8/25][155/782] Loss_D: 0.4914 Loss_G: 1.9850\n",
      "[8/25][156/782] Loss_D: 0.5797 Loss_G: 3.1603\n",
      "[8/25][157/782] Loss_D: 0.6923 Loss_G: 2.8414\n",
      "[8/25][158/782] Loss_D: 0.5247 Loss_G: 3.6399\n",
      "[8/25][159/782] Loss_D: 0.3929 Loss_G: 2.5890\n",
      "[8/25][160/782] Loss_D: 0.3945 Loss_G: 4.7902\n",
      "[8/25][161/782] Loss_D: 0.3389 Loss_G: 3.2119\n",
      "[8/25][162/782] Loss_D: 0.3150 Loss_G: 3.9789\n",
      "[8/25][163/782] Loss_D: 0.2470 Loss_G: 3.7407\n",
      "[8/25][164/782] Loss_D: 0.3525 Loss_G: 2.3207\n",
      "[8/25][165/782] Loss_D: 0.1714 Loss_G: 3.9496\n",
      "[8/25][166/782] Loss_D: 0.2394 Loss_G: 4.8269\n",
      "[8/25][167/782] Loss_D: 0.1757 Loss_G: 3.9926\n",
      "[8/25][168/782] Loss_D: 0.0802 Loss_G: 3.8907\n",
      "[8/25][169/782] Loss_D: 0.1448 Loss_G: 4.0993\n",
      "[8/25][170/782] Loss_D: 0.1426 Loss_G: 3.9015\n",
      "[8/25][171/782] Loss_D: 0.0842 Loss_G: 3.6137\n",
      "[8/25][172/782] Loss_D: 0.1146 Loss_G: 4.4588\n",
      "[8/25][173/782] Loss_D: 0.2708 Loss_G: 4.1344\n",
      "[8/25][174/782] Loss_D: 0.0713 Loss_G: 4.6579\n",
      "[8/25][175/782] Loss_D: 0.2897 Loss_G: 2.1478\n",
      "[8/25][176/782] Loss_D: 0.3387 Loss_G: 6.6344\n",
      "[8/25][177/782] Loss_D: 0.9950 Loss_G: 2.7092\n",
      "[8/25][178/782] Loss_D: 0.3121 Loss_G: 2.8709\n",
      "[8/25][179/782] Loss_D: 0.6001 Loss_G: 0.4576\n",
      "[8/25][180/782] Loss_D: 4.2940 Loss_G: 9.0814\n",
      "[8/25][181/782] Loss_D: 4.9536 Loss_G: 4.4105\n",
      "[8/25][182/782] Loss_D: 0.6494 Loss_G: 0.8760\n",
      "[8/25][183/782] Loss_D: 1.4960 Loss_G: 2.7383\n",
      "[8/25][184/782] Loss_D: 0.4409 Loss_G: 3.7883\n",
      "[8/25][185/782] Loss_D: 0.9212 Loss_G: 1.9598\n",
      "[8/25][186/782] Loss_D: 0.6943 Loss_G: 2.5716\n",
      "[8/25][187/782] Loss_D: 0.6198 Loss_G: 2.5027\n",
      "[8/25][188/782] Loss_D: 0.4213 Loss_G: 2.7900\n",
      "[8/25][189/782] Loss_D: 0.6410 Loss_G: 2.1666\n",
      "[8/25][190/782] Loss_D: 0.7121 Loss_G: 1.8457\n",
      "[8/25][191/782] Loss_D: 0.5115 Loss_G: 2.8546\n",
      "[8/25][192/782] Loss_D: 0.7262 Loss_G: 2.1596\n",
      "[8/25][193/782] Loss_D: 0.5403 Loss_G: 2.5698\n",
      "[8/25][194/782] Loss_D: 0.5676 Loss_G: 1.8732\n",
      "[8/25][195/782] Loss_D: 0.7948 Loss_G: 4.0640\n",
      "[8/25][196/782] Loss_D: 0.9794 Loss_G: 1.6053\n",
      "[8/25][197/782] Loss_D: 0.9757 Loss_G: 3.5398\n",
      "[8/25][198/782] Loss_D: 0.5800 Loss_G: 2.6651\n",
      "[8/25][199/782] Loss_D: 0.4976 Loss_G: 2.2663\n",
      "[8/25][200/782] Loss_D: 0.5313 Loss_G: 3.3592\n",
      "[8/25][201/782] Loss_D: 0.6280 Loss_G: 1.8033\n",
      "[8/25][202/782] Loss_D: 0.8227 Loss_G: 4.3629\n",
      "[8/25][203/782] Loss_D: 0.6873 Loss_G: 1.9147\n",
      "[8/25][204/782] Loss_D: 0.5895 Loss_G: 2.9829\n",
      "[8/25][205/782] Loss_D: 0.3625 Loss_G: 2.6506\n",
      "[8/25][206/782] Loss_D: 0.3908 Loss_G: 2.9216\n",
      "[8/25][207/782] Loss_D: 0.4535 Loss_G: 4.6149\n",
      "[8/25][208/782] Loss_D: 0.9618 Loss_G: 0.8765\n",
      "[8/25][209/782] Loss_D: 1.4160 Loss_G: 6.9547\n",
      "[8/25][210/782] Loss_D: 2.7879 Loss_G: 2.2892\n",
      "[8/25][211/782] Loss_D: 0.4003 Loss_G: 3.0340\n",
      "[8/25][212/782] Loss_D: 0.4445 Loss_G: 3.7808\n",
      "[8/25][213/782] Loss_D: 0.5076 Loss_G: 2.0262\n",
      "[8/25][214/782] Loss_D: 0.7023 Loss_G: 4.8975\n",
      "[8/25][215/782] Loss_D: 0.2038 Loss_G: 4.5395\n",
      "[8/25][216/782] Loss_D: 0.6669 Loss_G: 1.7312\n",
      "[8/25][217/782] Loss_D: 0.8079 Loss_G: 5.1745\n",
      "[8/25][218/782] Loss_D: 0.3121 Loss_G: 3.6598\n",
      "[8/25][219/782] Loss_D: 0.1190 Loss_G: 4.0117\n",
      "[8/25][220/782] Loss_D: 0.2394 Loss_G: 3.6409\n",
      "[8/25][221/782] Loss_D: 0.1209 Loss_G: 4.4426\n",
      "[8/25][222/782] Loss_D: 0.1125 Loss_G: 4.2008\n",
      "[8/25][223/782] Loss_D: 0.2310 Loss_G: 4.0126\n",
      "[8/25][224/782] Loss_D: 0.1040 Loss_G: 4.1239\n",
      "[8/25][225/782] Loss_D: 0.1525 Loss_G: 4.1723\n",
      "[8/25][226/782] Loss_D: 0.1254 Loss_G: 4.0032\n",
      "[8/25][227/782] Loss_D: 0.2338 Loss_G: 3.1117\n",
      "[8/25][228/782] Loss_D: 0.2002 Loss_G: 4.0474\n",
      "[8/25][229/782] Loss_D: 0.0804 Loss_G: 4.4799\n",
      "[8/25][230/782] Loss_D: 0.0885 Loss_G: 4.3314\n",
      "[8/25][231/782] Loss_D: 0.0643 Loss_G: 4.1602\n",
      "[8/25][232/782] Loss_D: 0.1223 Loss_G: 3.6426\n",
      "[8/25][233/782] Loss_D: 0.0635 Loss_G: 4.1096\n",
      "[8/25][234/782] Loss_D: 0.0498 Loss_G: 4.5915\n",
      "[8/25][235/782] Loss_D: 0.0634 Loss_G: 4.3031\n",
      "[8/25][236/782] Loss_D: 0.0875 Loss_G: 4.2913\n",
      "[8/25][237/782] Loss_D: 0.0839 Loss_G: 4.2141\n",
      "[8/25][238/782] Loss_D: 0.0838 Loss_G: 4.2656\n",
      "[8/25][239/782] Loss_D: 0.0532 Loss_G: 5.1928\n",
      "[8/25][240/782] Loss_D: 0.1786 Loss_G: 4.1124\n",
      "[8/25][241/782] Loss_D: 0.0823 Loss_G: 4.8017\n",
      "[8/25][242/782] Loss_D: 0.1402 Loss_G: 4.3864\n",
      "[8/25][243/782] Loss_D: 0.0486 Loss_G: 5.5506\n",
      "[8/25][244/782] Loss_D: 0.1947 Loss_G: 2.5789\n",
      "[8/25][245/782] Loss_D: 0.0299 Loss_G: 3.9348\n",
      "[8/25][246/782] Loss_D: 0.0598 Loss_G: 4.4458\n",
      "[8/25][247/782] Loss_D: 0.1772 Loss_G: 6.1195\n",
      "[8/25][248/782] Loss_D: 0.1551 Loss_G: 4.6035\n",
      "[8/25][249/782] Loss_D: 0.0345 Loss_G: 4.6910\n",
      "[8/25][250/782] Loss_D: 0.0458 Loss_G: 4.4140\n",
      "[8/25][251/782] Loss_D: 0.0552 Loss_G: 4.5294\n",
      "[8/25][252/782] Loss_D: 0.0460 Loss_G: 4.4270\n",
      "[8/25][253/782] Loss_D: 0.0857 Loss_G: 4.4519\n",
      "[8/25][254/782] Loss_D: 0.0617 Loss_G: 4.5852\n",
      "[8/25][255/782] Loss_D: 0.2416 Loss_G: 5.4098\n",
      "[8/25][256/782] Loss_D: 0.1643 Loss_G: 4.6166\n",
      "[8/25][257/782] Loss_D: 0.1022 Loss_G: 3.5095\n",
      "[8/25][258/782] Loss_D: 0.0675 Loss_G: 4.0185\n",
      "[8/25][259/782] Loss_D: 0.0118 Loss_G: 5.4033\n",
      "[8/25][260/782] Loss_D: 0.1611 Loss_G: 6.1752\n",
      "[8/25][261/782] Loss_D: 0.1898 Loss_G: 6.2126\n",
      "[8/25][262/782] Loss_D: 0.0413 Loss_G: 4.5721\n",
      "[8/25][263/782] Loss_D: 0.0453 Loss_G: 4.6797\n",
      "[8/25][264/782] Loss_D: 0.0486 Loss_G: 4.4368\n",
      "[8/25][265/782] Loss_D: 0.0182 Loss_G: 4.9112\n",
      "[8/25][266/782] Loss_D: 0.0804 Loss_G: 4.9827\n",
      "[8/25][267/782] Loss_D: 0.0400 Loss_G: 5.3207\n",
      "[8/25][268/782] Loss_D: 0.0179 Loss_G: 5.3818\n",
      "[8/25][269/782] Loss_D: 0.0548 Loss_G: 4.7127\n",
      "[8/25][270/782] Loss_D: 0.0709 Loss_G: 4.5974\n",
      "[8/25][271/782] Loss_D: 0.0226 Loss_G: 5.6370\n",
      "[8/25][272/782] Loss_D: 0.0625 Loss_G: 4.4460\n",
      "[8/25][273/782] Loss_D: 0.0603 Loss_G: 5.1134\n",
      "[8/25][274/782] Loss_D: 0.0075 Loss_G: 6.6862\n",
      "[8/25][275/782] Loss_D: 0.0241 Loss_G: 4.7654\n",
      "[8/25][276/782] Loss_D: 0.0191 Loss_G: 5.2025\n",
      "[8/25][277/782] Loss_D: 0.1410 Loss_G: 5.7192\n",
      "[8/25][278/782] Loss_D: 0.1129 Loss_G: 5.1098\n",
      "[8/25][279/782] Loss_D: 0.0333 Loss_G: 4.9981\n",
      "[8/25][280/782] Loss_D: 0.1006 Loss_G: 4.3819\n",
      "[8/25][281/782] Loss_D: 0.0388 Loss_G: 4.9893\n",
      "[8/25][282/782] Loss_D: 0.1169 Loss_G: 5.5380\n",
      "[8/25][283/782] Loss_D: 0.0519 Loss_G: 6.2111\n",
      "[8/25][284/782] Loss_D: 0.0521 Loss_G: 4.5949\n",
      "[8/25][285/782] Loss_D: 0.0318 Loss_G: 4.6446\n",
      "[8/25][286/782] Loss_D: 0.0223 Loss_G: 5.1629\n",
      "[8/25][287/782] Loss_D: 0.0246 Loss_G: 4.8669\n",
      "[8/25][288/782] Loss_D: 0.0374 Loss_G: 4.8201\n",
      "[8/25][289/782] Loss_D: 0.0167 Loss_G: 5.3436\n",
      "[8/25][290/782] Loss_D: 0.0869 Loss_G: 4.6224\n",
      "[8/25][291/782] Loss_D: 0.0406 Loss_G: 5.2953\n",
      "[8/25][292/782] Loss_D: 0.1073 Loss_G: 3.6699\n",
      "[8/25][293/782] Loss_D: 0.0397 Loss_G: 4.2652\n",
      "[8/25][294/782] Loss_D: 0.0228 Loss_G: 4.9078\n",
      "[8/25][295/782] Loss_D: 0.0595 Loss_G: 4.9344\n",
      "[8/25][296/782] Loss_D: 0.0301 Loss_G: 5.3474\n",
      "[8/25][297/782] Loss_D: 0.0195 Loss_G: 5.5343\n",
      "[8/25][298/782] Loss_D: 0.0677 Loss_G: 4.8451\n",
      "[8/25][299/782] Loss_D: 0.0620 Loss_G: 4.6395\n",
      "[8/25][300/782] Loss_D: 0.0252 Loss_G: 5.8796\n",
      "[8/25][301/782] Loss_D: 0.0482 Loss_G: 4.5369\n",
      "[8/25][302/782] Loss_D: 0.0526 Loss_G: 4.6323\n",
      "[8/25][303/782] Loss_D: 0.0397 Loss_G: 5.0786\n",
      "[8/25][304/782] Loss_D: 0.0563 Loss_G: 4.7144\n",
      "[8/25][305/782] Loss_D: 0.0285 Loss_G: 5.4396\n",
      "[8/25][306/782] Loss_D: 0.0508 Loss_G: 4.6787\n",
      "[8/25][307/782] Loss_D: 0.0387 Loss_G: 5.4651\n",
      "[8/25][308/782] Loss_D: 0.0239 Loss_G: 4.9965\n",
      "[8/25][309/782] Loss_D: 0.1536 Loss_G: 7.3415\n",
      "[8/25][310/782] Loss_D: 0.1029 Loss_G: 5.7112\n",
      "[8/25][311/782] Loss_D: 0.1209 Loss_G: 4.0378\n",
      "[8/25][312/782] Loss_D: 0.0224 Loss_G: 4.1780\n",
      "[8/25][313/782] Loss_D: 0.0041 Loss_G: 5.8688\n",
      "[8/25][314/782] Loss_D: 0.3499 Loss_G: 9.9106\n",
      "[8/25][315/782] Loss_D: 1.7983 Loss_G: 8.0785\n",
      "[8/25][316/782] Loss_D: 4.3742 Loss_G: 0.2056\n",
      "[8/25][317/782] Loss_D: 2.7607 Loss_G: 3.8502\n",
      "[8/25][318/782] Loss_D: 0.4394 Loss_G: 4.0247\n",
      "[8/25][319/782] Loss_D: 0.7231 Loss_G: 1.2056\n",
      "[8/25][320/782] Loss_D: 0.8466 Loss_G: 3.9500\n",
      "[8/25][321/782] Loss_D: 0.4763 Loss_G: 3.5795\n",
      "[8/25][322/782] Loss_D: 0.8529 Loss_G: 1.0717\n",
      "[8/25][323/782] Loss_D: 1.1591 Loss_G: 4.2836\n",
      "[8/25][324/782] Loss_D: 0.9376 Loss_G: 2.0007\n",
      "[8/25][325/782] Loss_D: 0.8773 Loss_G: 2.0348\n",
      "[8/25][326/782] Loss_D: 0.5972 Loss_G: 2.8583\n",
      "[8/25][327/782] Loss_D: 0.4992 Loss_G: 2.1856\n",
      "[8/25][328/782] Loss_D: 0.6990 Loss_G: 2.6548\n",
      "[8/25][329/782] Loss_D: 0.7783 Loss_G: 2.3786\n",
      "[8/25][330/782] Loss_D: 0.6284 Loss_G: 2.1364\n",
      "[8/25][331/782] Loss_D: 0.4314 Loss_G: 2.8252\n",
      "[8/25][332/782] Loss_D: 0.6787 Loss_G: 1.2869\n",
      "[8/25][333/782] Loss_D: 1.1670 Loss_G: 4.6550\n",
      "[8/25][334/782] Loss_D: 0.9995 Loss_G: 2.3583\n",
      "[8/25][335/782] Loss_D: 0.5900 Loss_G: 1.3706\n",
      "[8/25][336/782] Loss_D: 0.7289 Loss_G: 3.9013\n",
      "[8/25][337/782] Loss_D: 0.7316 Loss_G: 2.0838\n",
      "[8/25][338/782] Loss_D: 0.3950 Loss_G: 2.3142\n",
      "[8/25][339/782] Loss_D: 0.5675 Loss_G: 2.8970\n",
      "[8/25][340/782] Loss_D: 0.5476 Loss_G: 2.4778\n",
      "[8/25][341/782] Loss_D: 0.5742 Loss_G: 2.1047\n",
      "[8/25][342/782] Loss_D: 0.6495 Loss_G: 2.9241\n",
      "[8/25][343/782] Loss_D: 0.5075 Loss_G: 3.2168\n",
      "[8/25][344/782] Loss_D: 0.4512 Loss_G: 2.5855\n",
      "[8/25][345/782] Loss_D: 0.4574 Loss_G: 2.2742\n",
      "[8/25][346/782] Loss_D: 0.3432 Loss_G: 3.0045\n",
      "[8/25][347/782] Loss_D: 0.4413 Loss_G: 2.9159\n",
      "[8/25][348/782] Loss_D: 0.7375 Loss_G: 1.4026\n",
      "[8/25][349/782] Loss_D: 0.9997 Loss_G: 4.7194\n",
      "[8/25][350/782] Loss_D: 1.2970 Loss_G: 1.1620\n",
      "[8/25][351/782] Loss_D: 0.8307 Loss_G: 3.9428\n",
      "[8/25][352/782] Loss_D: 0.5452 Loss_G: 2.4165\n",
      "[8/25][353/782] Loss_D: 0.4040 Loss_G: 3.0469\n",
      "[8/25][354/782] Loss_D: 0.7718 Loss_G: 1.4430\n",
      "[8/25][355/782] Loss_D: 0.7985 Loss_G: 4.3901\n",
      "[8/25][356/782] Loss_D: 0.5361 Loss_G: 3.0321\n",
      "[8/25][357/782] Loss_D: 0.4839 Loss_G: 2.0101\n",
      "[8/25][358/782] Loss_D: 0.6263 Loss_G: 4.1374\n",
      "[8/25][359/782] Loss_D: 0.2441 Loss_G: 4.1288\n",
      "[8/25][360/782] Loss_D: 0.3552 Loss_G: 2.3398\n",
      "[8/25][361/782] Loss_D: 0.4753 Loss_G: 2.6931\n",
      "[8/25][362/782] Loss_D: 0.6256 Loss_G: 3.1195\n",
      "[8/25][363/782] Loss_D: 0.5246 Loss_G: 2.5787\n",
      "[8/25][364/782] Loss_D: 0.4564 Loss_G: 4.0840\n",
      "[8/25][365/782] Loss_D: 0.4989 Loss_G: 2.2574\n",
      "[8/25][366/782] Loss_D: 0.4544 Loss_G: 4.0255\n",
      "[8/25][367/782] Loss_D: 0.5158 Loss_G: 2.2666\n",
      "[8/25][368/782] Loss_D: 0.3805 Loss_G: 3.5320\n",
      "[8/25][369/782] Loss_D: 0.2969 Loss_G: 3.2729\n",
      "[8/25][370/782] Loss_D: 0.4653 Loss_G: 2.5683\n",
      "[8/25][371/782] Loss_D: 0.3573 Loss_G: 3.5535\n",
      "[8/25][372/782] Loss_D: 0.7236 Loss_G: 1.1865\n",
      "[8/25][373/782] Loss_D: 0.6666 Loss_G: 4.7300\n",
      "[8/25][374/782] Loss_D: 0.3262 Loss_G: 3.8135\n",
      "[8/25][375/782] Loss_D: 0.3974 Loss_G: 2.2004\n",
      "[8/25][376/782] Loss_D: 0.3590 Loss_G: 2.9940\n",
      "[8/25][377/782] Loss_D: 0.3209 Loss_G: 3.5344\n",
      "[8/25][378/782] Loss_D: 0.2579 Loss_G: 3.2592\n",
      "[8/25][379/782] Loss_D: 0.4244 Loss_G: 1.7951\n",
      "[8/25][380/782] Loss_D: 0.6864 Loss_G: 5.1939\n",
      "[8/25][381/782] Loss_D: 0.7143 Loss_G: 1.7498\n",
      "[8/25][382/782] Loss_D: 0.3278 Loss_G: 2.8445\n",
      "[8/25][383/782] Loss_D: 0.4010 Loss_G: 4.1051\n",
      "[8/25][384/782] Loss_D: 0.2527 Loss_G: 3.3675\n",
      "[8/25][385/782] Loss_D: 0.3558 Loss_G: 2.7981\n",
      "[8/25][386/782] Loss_D: 0.3037 Loss_G: 3.7564\n",
      "[8/25][387/782] Loss_D: 0.2091 Loss_G: 3.0203\n",
      "[8/25][388/782] Loss_D: 0.2916 Loss_G: 5.0445\n",
      "[8/25][389/782] Loss_D: 0.3945 Loss_G: 2.2656\n",
      "[8/25][390/782] Loss_D: 1.0120 Loss_G: 7.9402\n",
      "[8/25][391/782] Loss_D: 2.1517 Loss_G: 1.6937\n",
      "[8/25][392/782] Loss_D: 0.6546 Loss_G: 3.9386\n",
      "[8/25][393/782] Loss_D: 0.8293 Loss_G: 1.2517\n",
      "[8/25][394/782] Loss_D: 0.7637 Loss_G: 3.2815\n",
      "[8/25][395/782] Loss_D: 0.9395 Loss_G: 1.7248\n",
      "[8/25][396/782] Loss_D: 0.7165 Loss_G: 3.9298\n",
      "[8/25][397/782] Loss_D: 0.8263 Loss_G: 1.7068\n",
      "[8/25][398/782] Loss_D: 0.9029 Loss_G: 5.6351\n",
      "[8/25][399/782] Loss_D: 0.8269 Loss_G: 2.4461\n",
      "[8/25][400/782] Loss_D: 0.2990 Loss_G: 3.0146\n",
      "[8/25][401/782] Loss_D: 0.3253 Loss_G: 4.0826\n",
      "[8/25][402/782] Loss_D: 0.5646 Loss_G: 2.0496\n",
      "[8/25][403/782] Loss_D: 0.4430 Loss_G: 4.3471\n",
      "[8/25][404/782] Loss_D: 0.2857 Loss_G: 4.0122\n",
      "[8/25][405/782] Loss_D: 0.4070 Loss_G: 2.4951\n",
      "[8/25][406/782] Loss_D: 0.7012 Loss_G: 7.1328\n",
      "[8/25][407/782] Loss_D: 2.0570 Loss_G: 0.9897\n",
      "[8/25][408/782] Loss_D: 0.6560 Loss_G: 3.7205\n",
      "[8/25][409/782] Loss_D: 0.3215 Loss_G: 4.7562\n",
      "[8/25][410/782] Loss_D: 0.5102 Loss_G: 1.9919\n",
      "[8/25][411/782] Loss_D: 0.2970 Loss_G: 3.7020\n",
      "[8/25][412/782] Loss_D: 0.3254 Loss_G: 4.6425\n",
      "[8/25][413/782] Loss_D: 0.3838 Loss_G: 2.9297\n",
      "[8/25][414/782] Loss_D: 0.2434 Loss_G: 4.6884\n",
      "[8/25][415/782] Loss_D: 0.3121 Loss_G: 2.9883\n",
      "[8/25][416/782] Loss_D: 0.3770 Loss_G: 6.1075\n",
      "[8/25][417/782] Loss_D: 0.2470 Loss_G: 3.6333\n",
      "[8/25][418/782] Loss_D: 0.0279 Loss_G: 4.2134\n",
      "[8/25][419/782] Loss_D: 0.1695 Loss_G: 4.3801\n",
      "[8/25][420/782] Loss_D: 0.0658 Loss_G: 4.7800\n",
      "[8/25][421/782] Loss_D: 0.2239 Loss_G: 2.8443\n",
      "[8/25][422/782] Loss_D: 0.2444 Loss_G: 6.0889\n",
      "[8/25][423/782] Loss_D: 0.1511 Loss_G: 4.3911\n",
      "[8/25][424/782] Loss_D: 0.1972 Loss_G: 4.2459\n",
      "[8/25][425/782] Loss_D: 0.0584 Loss_G: 4.7281\n",
      "[8/25][426/782] Loss_D: 0.1152 Loss_G: 3.9759\n",
      "[8/25][427/782] Loss_D: 0.0389 Loss_G: 5.0041\n",
      "[8/25][428/782] Loss_D: 1.0045 Loss_G: 10.5677\n",
      "[8/25][429/782] Loss_D: 5.1221 Loss_G: 3.3773\n",
      "[8/25][430/782] Loss_D: 0.3607 Loss_G: 0.5865\n",
      "[8/25][431/782] Loss_D: 1.5589 Loss_G: 6.1424\n",
      "[8/25][432/782] Loss_D: 1.8259 Loss_G: 0.8644\n",
      "[8/25][433/782] Loss_D: 1.3864 Loss_G: 6.1898\n",
      "[8/25][434/782] Loss_D: 0.7806 Loss_G: 2.5256\n",
      "[8/25][435/782] Loss_D: 0.6365 Loss_G: 4.3928\n",
      "[8/25][436/782] Loss_D: 0.3684 Loss_G: 3.7262\n",
      "[8/25][437/782] Loss_D: 1.0073 Loss_G: 1.5064\n",
      "[8/25][438/782] Loss_D: 1.3641 Loss_G: 7.3818\n",
      "[8/25][439/782] Loss_D: 2.4730 Loss_G: 1.7805\n",
      "[8/25][440/782] Loss_D: 0.4209 Loss_G: 1.7070\n",
      "[8/25][441/782] Loss_D: 0.7264 Loss_G: 4.5113\n",
      "[8/25][442/782] Loss_D: 0.5845 Loss_G: 3.3881\n",
      "[8/25][443/782] Loss_D: 0.3144 Loss_G: 2.2595\n",
      "[8/25][444/782] Loss_D: 0.3661 Loss_G: 2.9453\n",
      "[8/25][445/782] Loss_D: 0.5734 Loss_G: 3.1660\n",
      "[8/25][446/782] Loss_D: 0.4236 Loss_G: 2.6623\n",
      "[8/25][447/782] Loss_D: 0.4377 Loss_G: 3.0242\n",
      "[8/25][448/782] Loss_D: 0.4549 Loss_G: 2.2560\n",
      "[8/25][449/782] Loss_D: 0.8811 Loss_G: 3.0420\n",
      "[8/25][450/782] Loss_D: 0.5352 Loss_G: 3.1068\n",
      "[8/25][451/782] Loss_D: 0.3635 Loss_G: 2.6150\n",
      "[8/25][452/782] Loss_D: 0.4628 Loss_G: 3.6921\n",
      "[8/25][453/782] Loss_D: 0.2984 Loss_G: 3.2803\n",
      "[8/25][454/782] Loss_D: 0.1792 Loss_G: 3.6904\n",
      "[8/25][455/782] Loss_D: 0.2815 Loss_G: 3.0026\n",
      "[8/25][456/782] Loss_D: 0.1888 Loss_G: 3.4268\n",
      "[8/25][457/782] Loss_D: 0.1649 Loss_G: 3.8417\n",
      "[8/25][458/782] Loss_D: 0.1813 Loss_G: 4.2152\n",
      "[8/25][459/782] Loss_D: 0.2701 Loss_G: 3.2421\n",
      "[8/25][460/782] Loss_D: 0.1299 Loss_G: 3.3614\n",
      "[8/25][461/782] Loss_D: 0.1857 Loss_G: 4.1770\n",
      "[8/25][462/782] Loss_D: 0.2078 Loss_G: 3.2516\n",
      "[8/25][463/782] Loss_D: 0.1329 Loss_G: 3.6939\n",
      "[8/25][464/782] Loss_D: 0.1628 Loss_G: 3.3173\n",
      "[8/25][465/782] Loss_D: 0.1250 Loss_G: 3.8676\n",
      "[8/25][466/782] Loss_D: 0.1342 Loss_G: 4.1208\n",
      "[8/25][467/782] Loss_D: 0.0937 Loss_G: 3.9498\n",
      "[8/25][468/782] Loss_D: 0.1437 Loss_G: 4.0603\n",
      "[8/25][469/782] Loss_D: 0.1031 Loss_G: 4.0458\n",
      "[8/25][470/782] Loss_D: 0.1857 Loss_G: 3.1582\n",
      "[8/25][471/782] Loss_D: 0.1065 Loss_G: 3.9442\n",
      "[8/25][472/782] Loss_D: 0.2559 Loss_G: 6.1470\n",
      "[8/25][473/782] Loss_D: 0.3370 Loss_G: 3.7168\n",
      "[8/25][474/782] Loss_D: 0.0889 Loss_G: 3.7990\n",
      "[8/25][475/782] Loss_D: 0.1770 Loss_G: 3.0513\n",
      "[8/25][476/782] Loss_D: 0.0858 Loss_G: 3.6755\n",
      "[8/25][477/782] Loss_D: 0.0344 Loss_G: 4.7664\n",
      "[8/25][478/782] Loss_D: 0.0674 Loss_G: 4.6667\n",
      "[8/25][479/782] Loss_D: 0.0538 Loss_G: 4.4831\n",
      "[8/25][480/782] Loss_D: 0.1106 Loss_G: 4.1506\n",
      "[8/25][481/782] Loss_D: 0.0630 Loss_G: 4.3812\n",
      "[8/25][482/782] Loss_D: 0.0888 Loss_G: 4.3686\n",
      "[8/25][483/782] Loss_D: 0.0679 Loss_G: 4.5135\n",
      "[8/25][484/782] Loss_D: 0.0606 Loss_G: 4.5377\n",
      "[8/25][485/782] Loss_D: 0.0561 Loss_G: 4.7734\n",
      "[8/25][486/782] Loss_D: 0.0511 Loss_G: 4.4799\n",
      "[8/25][487/782] Loss_D: 0.0710 Loss_G: 4.0777\n",
      "[8/25][488/782] Loss_D: 0.0425 Loss_G: 4.4523\n",
      "[8/25][489/782] Loss_D: 0.1056 Loss_G: 4.6055\n",
      "[8/25][490/782] Loss_D: 0.0281 Loss_G: 5.5662\n",
      "[8/25][491/782] Loss_D: 0.0615 Loss_G: 4.5168\n",
      "[8/25][492/782] Loss_D: 0.1073 Loss_G: 3.7930\n",
      "[8/25][493/782] Loss_D: 0.0495 Loss_G: 4.4995\n",
      "[8/25][494/782] Loss_D: 0.0584 Loss_G: 4.4535\n",
      "[8/25][495/782] Loss_D: 0.0525 Loss_G: 4.7834\n",
      "[8/25][496/782] Loss_D: 0.0788 Loss_G: 4.5131\n",
      "[8/25][497/782] Loss_D: 0.1018 Loss_G: 4.6520\n",
      "[8/25][498/782] Loss_D: 0.0729 Loss_G: 4.1882\n",
      "[8/25][499/782] Loss_D: 0.0180 Loss_G: 5.7916\n",
      "[8/25][500/782] Loss_D: 0.1373 Loss_G: 5.5964\n",
      "[8/25][501/782] Loss_D: 0.1975 Loss_G: 5.1178\n",
      "[8/25][502/782] Loss_D: 0.0115 Loss_G: 4.9297\n",
      "[8/25][503/782] Loss_D: 0.0391 Loss_G: 4.4545\n",
      "[8/25][504/782] Loss_D: 0.0302 Loss_G: 4.8310\n",
      "[8/25][505/782] Loss_D: 0.0114 Loss_G: 5.6081\n",
      "[8/25][506/782] Loss_D: 0.3120 Loss_G: 7.9646\n",
      "[8/25][507/782] Loss_D: 1.7174 Loss_G: 4.8486\n",
      "[8/25][508/782] Loss_D: 2.0719 Loss_G: 0.0111\n",
      "[8/25][509/782] Loss_D: 4.9950 Loss_G: 6.6250\n",
      "[8/25][510/782] Loss_D: 1.7898 Loss_G: 1.5690\n",
      "[8/25][511/782] Loss_D: 1.3174 Loss_G: 3.9110\n",
      "[8/25][512/782] Loss_D: 1.0105 Loss_G: 2.2539\n",
      "[8/25][513/782] Loss_D: 0.5488 Loss_G: 3.2002\n",
      "[8/25][514/782] Loss_D: 0.5082 Loss_G: 3.7314\n",
      "[8/25][515/782] Loss_D: 0.5354 Loss_G: 2.6682\n",
      "[8/25][516/782] Loss_D: 0.6905 Loss_G: 4.2031\n",
      "[8/25][517/782] Loss_D: 1.4224 Loss_G: 1.4145\n",
      "[8/25][518/782] Loss_D: 1.1106 Loss_G: 3.2101\n",
      "[8/25][519/782] Loss_D: 0.8535 Loss_G: 3.3535\n",
      "[8/25][520/782] Loss_D: 0.9481 Loss_G: 1.8040\n",
      "[8/25][521/782] Loss_D: 0.9056 Loss_G: 3.4623\n",
      "[8/25][522/782] Loss_D: 0.8982 Loss_G: 1.4842\n",
      "[8/25][523/782] Loss_D: 1.0269 Loss_G: 3.9393\n",
      "[8/25][524/782] Loss_D: 0.7042 Loss_G: 2.0690\n",
      "[8/25][525/782] Loss_D: 0.7196 Loss_G: 3.5232\n",
      "[8/25][526/782] Loss_D: 0.3935 Loss_G: 3.5480\n",
      "[8/25][527/782] Loss_D: 0.5113 Loss_G: 2.2698\n",
      "[8/25][528/782] Loss_D: 0.9667 Loss_G: 1.3771\n",
      "[8/25][529/782] Loss_D: 1.0441 Loss_G: 5.5834\n",
      "[8/25][530/782] Loss_D: 1.3606 Loss_G: 1.6541\n",
      "[8/25][531/782] Loss_D: 0.4651 Loss_G: 3.0809\n",
      "[8/25][532/782] Loss_D: 0.4274 Loss_G: 4.2781\n",
      "[8/25][533/782] Loss_D: 0.3512 Loss_G: 2.8945\n",
      "[8/25][534/782] Loss_D: 0.2702 Loss_G: 2.7756\n",
      "[8/25][535/782] Loss_D: 0.6940 Loss_G: 7.0311\n",
      "[8/25][536/782] Loss_D: 2.0415 Loss_G: 0.8121\n",
      "[8/25][537/782] Loss_D: 1.2662 Loss_G: 4.6936\n",
      "[8/25][538/782] Loss_D: 0.2401 Loss_G: 4.8675\n",
      "[8/25][539/782] Loss_D: 0.2117 Loss_G: 2.9934\n",
      "[8/25][540/782] Loss_D: 0.2114 Loss_G: 3.0638\n",
      "[8/25][541/782] Loss_D: 0.1369 Loss_G: 3.3823\n",
      "[8/25][542/782] Loss_D: 0.4339 Loss_G: 4.5161\n",
      "[8/25][543/782] Loss_D: 0.6652 Loss_G: 2.8786\n",
      "[8/25][544/782] Loss_D: 0.3098 Loss_G: 3.1277\n",
      "[8/25][545/782] Loss_D: 1.4937 Loss_G: 7.8544\n",
      "[8/25][546/782] Loss_D: 2.3865 Loss_G: 2.1375\n",
      "[8/25][547/782] Loss_D: 0.1360 Loss_G: 2.2601\n",
      "[8/25][548/782] Loss_D: 1.8002 Loss_G: 8.0320\n",
      "[8/25][549/782] Loss_D: 2.7959 Loss_G: 2.8088\n",
      "[8/25][550/782] Loss_D: 0.5777 Loss_G: 1.3063\n",
      "[8/25][551/782] Loss_D: 0.8130 Loss_G: 4.0737\n",
      "[8/25][552/782] Loss_D: 1.0159 Loss_G: 2.1173\n",
      "[8/25][553/782] Loss_D: 0.4143 Loss_G: 2.3670\n",
      "[8/25][554/782] Loss_D: 0.4181 Loss_G: 2.9314\n",
      "[8/25][555/782] Loss_D: 0.3993 Loss_G: 3.6214\n",
      "[8/25][556/782] Loss_D: 0.3082 Loss_G: 3.2962\n",
      "[8/25][557/782] Loss_D: 0.5270 Loss_G: 2.4060\n",
      "[8/25][558/782] Loss_D: 0.5164 Loss_G: 2.5436\n",
      "[8/25][559/782] Loss_D: 0.1806 Loss_G: 3.4512\n",
      "[8/25][560/782] Loss_D: 0.2761 Loss_G: 3.8821\n",
      "[8/25][561/782] Loss_D: 0.4182 Loss_G: 2.2336\n",
      "[8/25][562/782] Loss_D: 0.1835 Loss_G: 3.7004\n",
      "[8/25][563/782] Loss_D: 0.2507 Loss_G: 5.0483\n",
      "[8/25][564/782] Loss_D: 0.8946 Loss_G: 0.1507\n",
      "[8/25][565/782] Loss_D: 2.3367 Loss_G: 9.6760\n",
      "[8/25][566/782] Loss_D: 4.0135 Loss_G: 3.0172\n",
      "[8/25][567/782] Loss_D: 0.6704 Loss_G: 0.5508\n",
      "[8/25][568/782] Loss_D: 1.3446 Loss_G: 4.5162\n",
      "[8/25][569/782] Loss_D: 1.0360 Loss_G: 2.0270\n",
      "[8/25][570/782] Loss_D: 0.7301 Loss_G: 4.0172\n",
      "[8/25][571/782] Loss_D: 0.9659 Loss_G: 1.3640\n",
      "[8/25][572/782] Loss_D: 0.8883 Loss_G: 3.8573\n",
      "[8/25][573/782] Loss_D: 1.1001 Loss_G: 1.9511\n",
      "[8/25][574/782] Loss_D: 0.6092 Loss_G: 3.5902\n",
      "[8/25][575/782] Loss_D: 0.5990 Loss_G: 5.3495\n",
      "[8/25][576/782] Loss_D: 1.1706 Loss_G: 1.3610\n",
      "[8/25][577/782] Loss_D: 1.0258 Loss_G: 5.8252\n",
      "[8/25][578/782] Loss_D: 0.9741 Loss_G: 2.4887\n",
      "[8/25][579/782] Loss_D: 0.3822 Loss_G: 2.9481\n",
      "[8/25][580/782] Loss_D: 0.4780 Loss_G: 3.1645\n",
      "[8/25][581/782] Loss_D: 0.2920 Loss_G: 3.4743\n",
      "[8/25][582/782] Loss_D: 0.2728 Loss_G: 3.3385\n",
      "[8/25][583/782] Loss_D: 0.3770 Loss_G: 4.0116\n",
      "[8/25][584/782] Loss_D: 0.4151 Loss_G: 2.1926\n",
      "[8/25][585/782] Loss_D: 0.3980 Loss_G: 4.6642\n",
      "[8/25][586/782] Loss_D: 0.1996 Loss_G: 4.4405\n",
      "[8/25][587/782] Loss_D: 0.2001 Loss_G: 2.8335\n",
      "[8/25][588/782] Loss_D: 0.2165 Loss_G: 3.8955\n",
      "[8/25][589/782] Loss_D: 0.1235 Loss_G: 4.2894\n",
      "[8/25][590/782] Loss_D: 0.1209 Loss_G: 4.0249\n",
      "[8/25][591/782] Loss_D: 0.0721 Loss_G: 3.9632\n",
      "[8/25][592/782] Loss_D: 0.1120 Loss_G: 4.2357\n",
      "[8/25][593/782] Loss_D: 0.1222 Loss_G: 4.0971\n",
      "[8/25][594/782] Loss_D: 0.1111 Loss_G: 4.0705\n",
      "[8/25][595/782] Loss_D: 0.1204 Loss_G: 4.3222\n",
      "[8/25][596/782] Loss_D: 0.0501 Loss_G: 4.9797\n",
      "[8/25][597/782] Loss_D: 0.0644 Loss_G: 4.3724\n",
      "[8/25][598/782] Loss_D: 0.0833 Loss_G: 4.2168\n",
      "[8/25][599/782] Loss_D: 0.0648 Loss_G: 3.9822\n",
      "[8/25][600/782] Loss_D: 0.0948 Loss_G: 4.3296\n",
      "[8/25][601/782] Loss_D: 0.0971 Loss_G: 4.4143\n",
      "[8/25][602/782] Loss_D: 0.1237 Loss_G: 4.2860\n",
      "[8/25][603/782] Loss_D: 0.0918 Loss_G: 4.3217\n",
      "[8/25][604/782] Loss_D: 0.0290 Loss_G: 4.7635\n",
      "[8/25][605/782] Loss_D: 0.2695 Loss_G: 5.5803\n",
      "[8/25][606/782] Loss_D: 0.1384 Loss_G: 5.3528\n",
      "[8/25][607/782] Loss_D: 0.2705 Loss_G: 2.8810\n",
      "[8/25][608/782] Loss_D: 0.0937 Loss_G: 3.7220\n",
      "[8/25][609/782] Loss_D: 0.0646 Loss_G: 4.6912\n",
      "[8/25][610/782] Loss_D: 0.2748 Loss_G: 7.4980\n",
      "[8/25][611/782] Loss_D: 0.8769 Loss_G: 4.8417\n",
      "[8/25][612/782] Loss_D: 0.6157 Loss_G: 0.1525\n",
      "[8/25][613/782] Loss_D: 3.0607 Loss_G: 10.1094\n",
      "[8/25][614/782] Loss_D: 5.8027 Loss_G: 3.8717\n",
      "[8/25][615/782] Loss_D: 1.1593 Loss_G: 0.2486\n",
      "[8/25][616/782] Loss_D: 2.0331 Loss_G: 2.4905\n",
      "[8/25][617/782] Loss_D: 0.5785 Loss_G: 3.7908\n",
      "[8/25][618/782] Loss_D: 0.6853 Loss_G: 2.4267\n",
      "[8/25][619/782] Loss_D: 0.5207 Loss_G: 2.0348\n",
      "[8/25][620/782] Loss_D: 0.4549 Loss_G: 3.0291\n",
      "[8/25][621/782] Loss_D: 0.6590 Loss_G: 2.3089\n",
      "[8/25][622/782] Loss_D: 0.8289 Loss_G: 1.4491\n",
      "[8/25][623/782] Loss_D: 0.9778 Loss_G: 3.1511\n",
      "[8/25][624/782] Loss_D: 0.9731 Loss_G: 1.6958\n",
      "[8/25][625/782] Loss_D: 0.7390 Loss_G: 2.0702\n",
      "[8/25][626/782] Loss_D: 0.6382 Loss_G: 3.3988\n",
      "[8/25][627/782] Loss_D: 1.0312 Loss_G: 1.4424\n",
      "[8/25][628/782] Loss_D: 0.9725 Loss_G: 3.3066\n",
      "[8/25][629/782] Loss_D: 0.6571 Loss_G: 2.4574\n",
      "[8/25][630/782] Loss_D: 0.3997 Loss_G: 2.5249\n",
      "[8/25][631/782] Loss_D: 0.6606 Loss_G: 2.8025\n",
      "[8/25][632/782] Loss_D: 0.5638 Loss_G: 3.0889\n",
      "[8/25][633/782] Loss_D: 0.6337 Loss_G: 2.0226\n",
      "[8/25][634/782] Loss_D: 0.7402 Loss_G: 3.0656\n",
      "[8/25][635/782] Loss_D: 0.4576 Loss_G: 3.4701\n",
      "[8/25][636/782] Loss_D: 0.5159 Loss_G: 1.4859\n",
      "[8/25][637/782] Loss_D: 0.9649 Loss_G: 4.5324\n",
      "[8/25][638/782] Loss_D: 0.7713 Loss_G: 1.8949\n",
      "[8/25][639/782] Loss_D: 0.8962 Loss_G: 4.5383\n",
      "[8/25][640/782] Loss_D: 1.0477 Loss_G: 1.1171\n",
      "[8/25][641/782] Loss_D: 0.8752 Loss_G: 4.5488\n",
      "[8/25][642/782] Loss_D: 0.8877 Loss_G: 1.6623\n",
      "[8/25][643/782] Loss_D: 0.5929 Loss_G: 2.8084\n",
      "[8/25][644/782] Loss_D: 0.4180 Loss_G: 4.4671\n",
      "[8/25][645/782] Loss_D: 0.6758 Loss_G: 1.9526\n",
      "[8/25][646/782] Loss_D: 0.7426 Loss_G: 5.7802\n",
      "[8/25][647/782] Loss_D: 0.7113 Loss_G: 2.6990\n",
      "[8/25][648/782] Loss_D: 0.3328 Loss_G: 4.8265\n",
      "[8/25][649/782] Loss_D: 0.2151 Loss_G: 4.1334\n",
      "[8/25][650/782] Loss_D: 0.2756 Loss_G: 3.2536\n",
      "[8/25][651/782] Loss_D: 0.3505 Loss_G: 5.8729\n",
      "[8/25][652/782] Loss_D: 0.4460 Loss_G: 2.7376\n",
      "[8/25][653/782] Loss_D: 0.7306 Loss_G: 6.7038\n",
      "[8/25][654/782] Loss_D: 2.0881 Loss_G: 2.1920\n",
      "[8/25][655/782] Loss_D: 0.7055 Loss_G: 5.2922\n",
      "[8/25][656/782] Loss_D: 1.4111 Loss_G: 0.7787\n",
      "[8/25][657/782] Loss_D: 1.3222 Loss_G: 4.8626\n",
      "[8/25][658/782] Loss_D: 0.6486 Loss_G: 2.6402\n",
      "[8/25][659/782] Loss_D: 0.6105 Loss_G: 2.2111\n",
      "[8/25][660/782] Loss_D: 0.8343 Loss_G: 5.1168\n",
      "[8/25][661/782] Loss_D: 0.9878 Loss_G: 2.0024\n",
      "[8/25][662/782] Loss_D: 0.3557 Loss_G: 3.3732\n",
      "[8/25][663/782] Loss_D: 0.3250 Loss_G: 4.0631\n",
      "[8/25][664/782] Loss_D: 0.3701 Loss_G: 2.5337\n",
      "[8/25][665/782] Loss_D: 0.4404 Loss_G: 5.0373\n",
      "[8/25][666/782] Loss_D: 0.3103 Loss_G: 3.1949\n",
      "[8/25][667/782] Loss_D: 0.2159 Loss_G: 3.9618\n",
      "[8/25][668/782] Loss_D: 0.1203 Loss_G: 4.1047\n",
      "[8/25][669/782] Loss_D: 0.1657 Loss_G: 5.1366\n",
      "[8/25][670/782] Loss_D: 0.1241 Loss_G: 4.8963\n",
      "[8/25][671/782] Loss_D: 0.1161 Loss_G: 4.0112\n",
      "[8/25][672/782] Loss_D: 0.0879 Loss_G: 4.4361\n",
      "[8/25][673/782] Loss_D: 0.0705 Loss_G: 4.6188\n",
      "[8/25][674/782] Loss_D: 0.1550 Loss_G: 4.4146\n",
      "[8/25][675/782] Loss_D: 0.0598 Loss_G: 4.6751\n",
      "[8/25][676/782] Loss_D: 0.1203 Loss_G: 3.9819\n",
      "[8/25][677/782] Loss_D: 0.0969 Loss_G: 4.0416\n",
      "[8/25][678/782] Loss_D: 0.0378 Loss_G: 4.7604\n",
      "[8/25][679/782] Loss_D: 0.1633 Loss_G: 3.7320\n",
      "[8/25][680/782] Loss_D: 0.0658 Loss_G: 4.3545\n",
      "[8/25][681/782] Loss_D: 0.0547 Loss_G: 4.4650\n",
      "[8/25][682/782] Loss_D: 0.1201 Loss_G: 4.0362\n",
      "[8/25][683/782] Loss_D: 0.0352 Loss_G: 5.4543\n",
      "[8/25][684/782] Loss_D: 0.1925 Loss_G: 4.7217\n",
      "[8/25][685/782] Loss_D: 0.2888 Loss_G: 2.8903\n",
      "[8/25][686/782] Loss_D: 0.0502 Loss_G: 3.7547\n",
      "[8/25][687/782] Loss_D: 0.0876 Loss_G: 4.5083\n",
      "[8/25][688/782] Loss_D: 0.0803 Loss_G: 4.7075\n",
      "[8/25][689/782] Loss_D: 0.0986 Loss_G: 4.6523\n",
      "[8/25][690/782] Loss_D: 0.0487 Loss_G: 5.7553\n",
      "[8/25][691/782] Loss_D: 0.0827 Loss_G: 4.3040\n",
      "[8/25][692/782] Loss_D: 0.0251 Loss_G: 5.0912\n",
      "[8/25][693/782] Loss_D: 0.0410 Loss_G: 4.6843\n",
      "[8/25][694/782] Loss_D: 0.0523 Loss_G: 4.8056\n",
      "[8/25][695/782] Loss_D: 0.0467 Loss_G: 4.3976\n",
      "[8/25][696/782] Loss_D: 0.4317 Loss_G: 7.8408\n",
      "[8/25][697/782] Loss_D: 1.4116 Loss_G: 7.2937\n",
      "[8/25][698/782] Loss_D: 4.4588 Loss_G: 0.0504\n",
      "[8/25][699/782] Loss_D: 2.9888 Loss_G: 6.1378\n",
      "[8/25][700/782] Loss_D: 2.3722 Loss_G: 1.3019\n",
      "[8/25][701/782] Loss_D: 0.9979 Loss_G: 2.0414\n",
      "[8/25][702/782] Loss_D: 0.8046 Loss_G: 3.3067\n",
      "[8/25][703/782] Loss_D: 0.4705 Loss_G: 3.8027\n",
      "[8/25][704/782] Loss_D: 0.2930 Loss_G: 3.0253\n",
      "[8/25][705/782] Loss_D: 0.3627 Loss_G: 2.6071\n",
      "[8/25][706/782] Loss_D: 0.6221 Loss_G: 2.4118\n",
      "[8/25][707/782] Loss_D: 0.3743 Loss_G: 2.8059\n",
      "[8/25][708/782] Loss_D: 0.7257 Loss_G: 2.6752\n",
      "[8/25][709/782] Loss_D: 0.5162 Loss_G: 1.9380\n",
      "[8/25][710/782] Loss_D: 0.4793 Loss_G: 3.2515\n",
      "[8/25][711/782] Loss_D: 0.9802 Loss_G: 1.7878\n",
      "[8/25][712/782] Loss_D: 0.6799 Loss_G: 4.9218\n",
      "[8/25][713/782] Loss_D: 0.9538 Loss_G: 1.4862\n",
      "[8/25][714/782] Loss_D: 0.5590 Loss_G: 3.5300\n",
      "[8/25][715/782] Loss_D: 0.5946 Loss_G: 5.5693\n",
      "[8/25][716/782] Loss_D: 0.5262 Loss_G: 4.2324\n",
      "[8/25][717/782] Loss_D: 0.6483 Loss_G: 1.1879\n",
      "[8/25][718/782] Loss_D: 1.5365 Loss_G: 5.4143\n",
      "[8/25][719/782] Loss_D: 0.7448 Loss_G: 4.8017\n",
      "[8/25][720/782] Loss_D: 0.3283 Loss_G: 2.1660\n",
      "[8/25][721/782] Loss_D: 0.4996 Loss_G: 3.4100\n",
      "[8/25][722/782] Loss_D: 0.4077 Loss_G: 4.1273\n",
      "[8/25][723/782] Loss_D: 0.4637 Loss_G: 2.6946\n",
      "[8/25][724/782] Loss_D: 0.5468 Loss_G: 1.9212\n",
      "[8/25][725/782] Loss_D: 0.3939 Loss_G: 3.3135\n",
      "[8/25][726/782] Loss_D: 0.4439 Loss_G: 2.4149\n",
      "[8/25][727/782] Loss_D: 0.0919 Loss_G: 3.6083\n",
      "[8/25][728/782] Loss_D: 0.7890 Loss_G: 4.9569\n",
      "[8/25][729/782] Loss_D: 0.6526 Loss_G: 2.7305\n",
      "[8/25][730/782] Loss_D: 0.1985 Loss_G: 2.5141\n",
      "[8/25][731/782] Loss_D: 0.2150 Loss_G: 3.6886\n",
      "[8/25][732/782] Loss_D: 0.4925 Loss_G: 6.2063\n",
      "[8/25][733/782] Loss_D: 0.9738 Loss_G: 2.1080\n",
      "[8/25][734/782] Loss_D: 0.3089 Loss_G: 4.3951\n",
      "[8/25][735/782] Loss_D: 0.2270 Loss_G: 5.0634\n",
      "[8/25][736/782] Loss_D: 0.2505 Loss_G: 3.5047\n",
      "[8/25][737/782] Loss_D: 0.1406 Loss_G: 3.4734\n",
      "[8/25][738/782] Loss_D: 0.0195 Loss_G: 5.2291\n",
      "[8/25][739/782] Loss_D: 0.0951 Loss_G: 4.1854\n",
      "[8/25][740/782] Loss_D: 0.2796 Loss_G: 6.7693\n",
      "[8/25][741/782] Loss_D: 0.6258 Loss_G: 2.5774\n",
      "[8/25][742/782] Loss_D: 0.4677 Loss_G: 8.1361\n",
      "[8/25][743/782] Loss_D: 1.2027 Loss_G: 0.8845\n",
      "[8/25][744/782] Loss_D: 1.2158 Loss_G: 8.3249\n",
      "[8/25][745/782] Loss_D: 3.4283 Loss_G: 1.2410\n",
      "[8/25][746/782] Loss_D: 1.0575 Loss_G: 4.5261\n",
      "[8/25][747/782] Loss_D: 0.6369 Loss_G: 2.7700\n",
      "[8/25][748/782] Loss_D: 0.8394 Loss_G: 1.6247\n",
      "[8/25][749/782] Loss_D: 1.1415 Loss_G: 5.0014\n",
      "[8/25][750/782] Loss_D: 1.1056 Loss_G: 2.3849\n",
      "[8/25][751/782] Loss_D: 0.6590 Loss_G: 3.3945\n",
      "[8/25][752/782] Loss_D: 0.2968 Loss_G: 3.9341\n",
      "[8/25][753/782] Loss_D: 0.1831 Loss_G: 3.1228\n",
      "[8/25][754/782] Loss_D: 0.4853 Loss_G: 5.3372\n",
      "[8/25][755/782] Loss_D: 0.4551 Loss_G: 2.5838\n",
      "[8/25][756/782] Loss_D: 0.3442 Loss_G: 4.1211\n",
      "[8/25][757/782] Loss_D: 0.0818 Loss_G: 4.3898\n",
      "[8/25][758/782] Loss_D: 0.2069 Loss_G: 3.7702\n",
      "[8/25][759/782] Loss_D: 0.0754 Loss_G: 4.2469\n",
      "[8/25][760/782] Loss_D: 0.1150 Loss_G: 4.3717\n",
      "[8/25][761/782] Loss_D: 0.0906 Loss_G: 4.4204\n",
      "[8/25][762/782] Loss_D: 0.0803 Loss_G: 4.6964\n",
      "[8/25][763/782] Loss_D: 0.3113 Loss_G: 4.6120\n",
      "[8/25][764/782] Loss_D: 0.0861 Loss_G: 5.6900\n",
      "[8/25][765/782] Loss_D: 0.0479 Loss_G: 4.8654\n",
      "[8/25][766/782] Loss_D: 0.0660 Loss_G: 3.9983\n",
      "[8/25][767/782] Loss_D: 0.1231 Loss_G: 4.1393\n",
      "[8/25][768/782] Loss_D: 0.0539 Loss_G: 4.9796\n",
      "[8/25][769/782] Loss_D: 0.0733 Loss_G: 4.2508\n",
      "[8/25][770/782] Loss_D: 0.0752 Loss_G: 4.3263\n",
      "[8/25][771/782] Loss_D: 0.0739 Loss_G: 4.2677\n",
      "[8/25][772/782] Loss_D: 0.1181 Loss_G: 4.1445\n",
      "[8/25][773/782] Loss_D: 0.0697 Loss_G: 4.5410\n",
      "[8/25][774/782] Loss_D: 0.0952 Loss_G: 4.2614\n",
      "[8/25][775/782] Loss_D: 0.0551 Loss_G: 4.8094\n",
      "[8/25][776/782] Loss_D: 0.0826 Loss_G: 4.4971\n",
      "[8/25][777/782] Loss_D: 0.0244 Loss_G: 5.4773\n",
      "[8/25][778/782] Loss_D: 0.1055 Loss_G: 3.9768\n",
      "[8/25][779/782] Loss_D: 0.1004 Loss_G: 4.2349\n",
      "[8/25][780/782] Loss_D: 0.0471 Loss_G: 4.7140\n",
      "[8/25][781/782] Loss_D: 0.1267 Loss_G: 3.5151\n",
      "[9/25][0/782] Loss_D: 0.0131 Loss_G: 5.4343\n",
      "[9/25][1/782] Loss_D: 0.2581 Loss_G: 6.5070\n",
      "[9/25][2/782] Loss_D: 0.0911 Loss_G: 6.3131\n",
      "[9/25][3/782] Loss_D: 0.0947 Loss_G: 4.6373\n",
      "[9/25][4/782] Loss_D: 0.0704 Loss_G: 4.0049\n",
      "[9/25][5/782] Loss_D: 0.0226 Loss_G: 4.5593\n",
      "[9/25][6/782] Loss_D: 0.0452 Loss_G: 4.7800\n",
      "[9/25][7/782] Loss_D: 0.0357 Loss_G: 4.9581\n",
      "[9/25][8/782] Loss_D: 0.0692 Loss_G: 4.6543\n",
      "[9/25][9/782] Loss_D: 0.0437 Loss_G: 5.4176\n",
      "[9/25][10/782] Loss_D: 0.0692 Loss_G: 4.0820\n",
      "[9/25][11/782] Loss_D: 0.0387 Loss_G: 4.7798\n",
      "[9/25][12/782] Loss_D: 0.0254 Loss_G: 4.9857\n",
      "[9/25][13/782] Loss_D: 0.0284 Loss_G: 4.9415\n",
      "[9/25][14/782] Loss_D: 0.0198 Loss_G: 5.2360\n",
      "[9/25][15/782] Loss_D: 0.1625 Loss_G: 5.8377\n",
      "[9/25][16/782] Loss_D: 0.3246 Loss_G: 6.3350\n",
      "[9/25][17/782] Loss_D: 0.0872 Loss_G: 3.0470\n",
      "[9/25][18/782] Loss_D: 0.2463 Loss_G: 7.8680\n",
      "[9/25][19/782] Loss_D: 1.1635 Loss_G: 5.6343\n",
      "[9/25][20/782] Loss_D: 1.0721 Loss_G: 0.0300\n",
      "[9/25][21/782] Loss_D: 3.1156 Loss_G: 8.5877\n",
      "[9/25][22/782] Loss_D: 2.2045 Loss_G: 4.0708\n",
      "[9/25][23/782] Loss_D: 0.2829 Loss_G: 1.5162\n",
      "[9/25][24/782] Loss_D: 0.9363 Loss_G: 3.9904\n",
      "[9/25][25/782] Loss_D: 0.4295 Loss_G: 3.7057\n",
      "[9/25][26/782] Loss_D: 0.9375 Loss_G: 1.6451\n",
      "[9/25][27/782] Loss_D: 0.7282 Loss_G: 3.3458\n",
      "[9/25][28/782] Loss_D: 0.3316 Loss_G: 3.3979\n",
      "[9/25][29/782] Loss_D: 0.5348 Loss_G: 2.3880\n",
      "[9/25][30/782] Loss_D: 0.3405 Loss_G: 3.0939\n",
      "[9/25][31/782] Loss_D: 0.6389 Loss_G: 2.1551\n",
      "[9/25][32/782] Loss_D: 0.7295 Loss_G: 2.8514\n",
      "[9/25][33/782] Loss_D: 0.5557 Loss_G: 4.3312\n",
      "[9/25][34/782] Loss_D: 0.6890 Loss_G: 2.5964\n",
      "[9/25][35/782] Loss_D: 1.0286 Loss_G: 5.4182\n",
      "[9/25][36/782] Loss_D: 0.7426 Loss_G: 3.9173\n",
      "[9/25][37/782] Loss_D: 0.4089 Loss_G: 2.6249\n",
      "[9/25][38/782] Loss_D: 0.3218 Loss_G: 2.7007\n",
      "[9/25][39/782] Loss_D: 0.2057 Loss_G: 2.9925\n",
      "[9/25][40/782] Loss_D: 0.7078 Loss_G: 5.1638\n",
      "[9/25][41/782] Loss_D: 0.8887 Loss_G: 3.5514\n",
      "[9/25][42/782] Loss_D: 0.1155 Loss_G: 2.7919\n",
      "[9/25][43/782] Loss_D: 1.5491 Loss_G: 6.5783\n",
      "[9/25][44/782] Loss_D: 1.2902 Loss_G: 3.8291\n",
      "[9/25][45/782] Loss_D: 0.1340 Loss_G: 2.2973\n",
      "[9/25][46/782] Loss_D: 1.3839 Loss_G: 7.1726\n",
      "[9/25][47/782] Loss_D: 2.2472 Loss_G: 2.0879\n",
      "[9/25][48/782] Loss_D: 0.4606 Loss_G: 1.6549\n",
      "[9/25][49/782] Loss_D: 0.4629 Loss_G: 3.7658\n",
      "[9/25][50/782] Loss_D: 0.2290 Loss_G: 3.9526\n",
      "[9/25][51/782] Loss_D: 0.4658 Loss_G: 2.5847\n",
      "[9/25][52/782] Loss_D: 0.1406 Loss_G: 4.1284\n",
      "[9/25][53/782] Loss_D: 0.0883 Loss_G: 5.2259\n",
      "[9/25][54/782] Loss_D: 0.3045 Loss_G: 4.3416\n",
      "[9/25][55/782] Loss_D: 0.2063 Loss_G: 4.1800\n",
      "[9/25][56/782] Loss_D: 0.6269 Loss_G: 7.0236\n",
      "[9/25][57/782] Loss_D: 1.1382 Loss_G: 3.5905\n",
      "[9/25][58/782] Loss_D: 0.5483 Loss_G: 4.7901\n",
      "[9/25][59/782] Loss_D: 0.1019 Loss_G: 5.6771\n",
      "[9/25][60/782] Loss_D: 0.2999 Loss_G: 3.2839\n",
      "[9/25][61/782] Loss_D: 0.0540 Loss_G: 3.7252\n",
      "[9/25][62/782] Loss_D: 0.4279 Loss_G: 6.2829\n",
      "[9/25][63/782] Loss_D: 0.5906 Loss_G: 1.3473\n",
      "[9/25][64/782] Loss_D: 1.7446 Loss_G: 9.3078\n",
      "[9/25][65/782] Loss_D: 3.4438 Loss_G: 5.0878\n",
      "[9/25][66/782] Loss_D: 0.1788 Loss_G: 2.8469\n",
      "[9/25][67/782] Loss_D: 0.5355 Loss_G: 3.7180\n",
      "[9/25][68/782] Loss_D: 0.4994 Loss_G: 4.1681\n",
      "[9/25][69/782] Loss_D: 0.9240 Loss_G: 0.8073\n",
      "[9/25][70/782] Loss_D: 1.9756 Loss_G: 6.3122\n",
      "[9/25][71/782] Loss_D: 2.1082 Loss_G: 2.2658\n",
      "[9/25][72/782] Loss_D: 0.4594 Loss_G: 1.9868\n",
      "[9/25][73/782] Loss_D: 0.5434 Loss_G: 3.8634\n",
      "[9/25][74/782] Loss_D: 0.3806 Loss_G: 3.4337\n",
      "[9/25][75/782] Loss_D: 0.5869 Loss_G: 1.9291\n",
      "[9/25][76/782] Loss_D: 0.5051 Loss_G: 3.7286\n",
      "[9/25][77/782] Loss_D: 0.1829 Loss_G: 3.9339\n",
      "[9/25][78/782] Loss_D: 0.2929 Loss_G: 3.1088\n",
      "[9/25][79/782] Loss_D: 0.2938 Loss_G: 3.7364\n",
      "[9/25][80/782] Loss_D: 0.1282 Loss_G: 4.2934\n",
      "[9/25][81/782] Loss_D: 0.3171 Loss_G: 2.8269\n",
      "[9/25][82/782] Loss_D: 0.3022 Loss_G: 4.4479\n",
      "[9/25][83/782] Loss_D: 0.0914 Loss_G: 4.7653\n",
      "[9/25][84/782] Loss_D: 0.3158 Loss_G: 2.7490\n",
      "[9/25][85/782] Loss_D: 0.4909 Loss_G: 5.4923\n",
      "[9/25][86/782] Loss_D: 0.3107 Loss_G: 3.1895\n",
      "[9/25][87/782] Loss_D: 0.0834 Loss_G: 3.9172\n",
      "[9/25][88/782] Loss_D: 0.2085 Loss_G: 4.6089\n",
      "[9/25][89/782] Loss_D: 0.1566 Loss_G: 4.0529\n",
      "[9/25][90/782] Loss_D: 0.1133 Loss_G: 4.2507\n",
      "[9/25][91/782] Loss_D: 0.1267 Loss_G: 4.3656\n",
      "[9/25][92/782] Loss_D: 0.1974 Loss_G: 3.0044\n",
      "[9/25][93/782] Loss_D: 0.4132 Loss_G: 6.3419\n",
      "[9/25][94/782] Loss_D: 0.4386 Loss_G: 4.5455\n",
      "[9/25][95/782] Loss_D: 0.0763 Loss_G: 4.0862\n",
      "[9/25][96/782] Loss_D: 0.6625 Loss_G: 3.7746\n",
      "[9/25][97/782] Loss_D: 0.1773 Loss_G: 5.1596\n",
      "[9/25][98/782] Loss_D: 1.0800 Loss_G: 0.1214\n",
      "[9/25][99/782] Loss_D: 3.5617 Loss_G: 9.0883\n",
      "[9/25][100/782] Loss_D: 4.7970 Loss_G: 3.3034\n",
      "[9/25][101/782] Loss_D: 1.0066 Loss_G: 0.2145\n",
      "[9/25][102/782] Loss_D: 2.5355 Loss_G: 2.8737\n",
      "[9/25][103/782] Loss_D: 0.6769 Loss_G: 3.2665\n",
      "[9/25][104/782] Loss_D: 1.1259 Loss_G: 1.2718\n",
      "[9/25][105/782] Loss_D: 0.9734 Loss_G: 2.6918\n",
      "[9/25][106/782] Loss_D: 0.8978 Loss_G: 3.4469\n",
      "[9/25][107/782] Loss_D: 0.8899 Loss_G: 2.1861\n",
      "[9/25][108/782] Loss_D: 0.8811 Loss_G: 2.8859\n",
      "[9/25][109/782] Loss_D: 0.4818 Loss_G: 3.4067\n",
      "[9/25][110/782] Loss_D: 0.5642 Loss_G: 2.8218\n",
      "[9/25][111/782] Loss_D: 0.3871 Loss_G: 3.2709\n",
      "[9/25][112/782] Loss_D: 0.3008 Loss_G: 3.5437\n",
      "[9/25][113/782] Loss_D: 0.5695 Loss_G: 3.9877\n",
      "[9/25][114/782] Loss_D: 0.4191 Loss_G: 3.3360\n",
      "[9/25][115/782] Loss_D: 0.1562 Loss_G: 3.3293\n",
      "[9/25][116/782] Loss_D: 0.2405 Loss_G: 4.3549\n",
      "[9/25][117/782] Loss_D: 0.1457 Loss_G: 4.3295\n",
      "[9/25][118/782] Loss_D: 0.1865 Loss_G: 3.5282\n",
      "[9/25][119/782] Loss_D: 0.1288 Loss_G: 3.5021\n",
      "[9/25][120/782] Loss_D: 0.1330 Loss_G: 3.7662\n",
      "[9/25][121/782] Loss_D: 0.0995 Loss_G: 3.9693\n",
      "[9/25][122/782] Loss_D: 0.1182 Loss_G: 3.9853\n",
      "[9/25][123/782] Loss_D: 0.0684 Loss_G: 4.4808\n",
      "[9/25][124/782] Loss_D: 0.0658 Loss_G: 4.2031\n",
      "[9/25][125/782] Loss_D: 0.1488 Loss_G: 3.2641\n",
      "[9/25][126/782] Loss_D: 0.1408 Loss_G: 3.9480\n",
      "[9/25][127/782] Loss_D: 0.0553 Loss_G: 4.7632\n",
      "[9/25][128/782] Loss_D: 0.1319 Loss_G: 4.0817\n",
      "[9/25][129/782] Loss_D: 0.0682 Loss_G: 4.7122\n",
      "[9/25][130/782] Loss_D: 0.0843 Loss_G: 3.8874\n",
      "[9/25][131/782] Loss_D: 0.1347 Loss_G: 4.3448\n",
      "[9/25][132/782] Loss_D: 0.0597 Loss_G: 5.0746\n",
      "[9/25][133/782] Loss_D: 0.1134 Loss_G: 4.4206\n",
      "[9/25][134/782] Loss_D: 0.0619 Loss_G: 3.9167\n",
      "[9/25][135/782] Loss_D: 0.0638 Loss_G: 4.1364\n",
      "[9/25][136/782] Loss_D: 0.0480 Loss_G: 4.4899\n",
      "[9/25][137/782] Loss_D: 0.0560 Loss_G: 4.5187\n",
      "[9/25][138/782] Loss_D: 0.0734 Loss_G: 4.6296\n",
      "[9/25][139/782] Loss_D: 0.0548 Loss_G: 5.7599\n",
      "[9/25][140/782] Loss_D: 0.0706 Loss_G: 3.9947\n",
      "[9/25][141/782] Loss_D: 0.0656 Loss_G: 5.3659\n",
      "[9/25][142/782] Loss_D: 0.0560 Loss_G: 4.1161\n",
      "[9/25][143/782] Loss_D: 0.0237 Loss_G: 4.9407\n",
      "[9/25][144/782] Loss_D: 0.2404 Loss_G: 5.3464\n",
      "[9/25][145/782] Loss_D: 0.1408 Loss_G: 6.7870\n",
      "[9/25][146/782] Loss_D: 0.0451 Loss_G: 4.7871\n",
      "[9/25][147/782] Loss_D: 0.0901 Loss_G: 5.5895\n",
      "[9/25][148/782] Loss_D: 0.0892 Loss_G: 3.4711\n",
      "[9/25][149/782] Loss_D: 0.0193 Loss_G: 5.2632\n",
      "[9/25][150/782] Loss_D: 0.0550 Loss_G: 4.1690\n",
      "[9/25][151/782] Loss_D: 0.0308 Loss_G: 5.2442\n",
      "[9/25][152/782] Loss_D: 0.0526 Loss_G: 4.1088\n",
      "[9/25][153/782] Loss_D: 0.0429 Loss_G: 4.3237\n",
      "[9/25][154/782] Loss_D: 0.0834 Loss_G: 4.0865\n",
      "[9/25][155/782] Loss_D: 0.0434 Loss_G: 4.9117\n",
      "[9/25][156/782] Loss_D: 0.0597 Loss_G: 5.4643\n",
      "[9/25][157/782] Loss_D: 0.0608 Loss_G: 3.8447\n",
      "[9/25][158/782] Loss_D: 0.0459 Loss_G: 4.6427\n",
      "[9/25][159/782] Loss_D: 0.0178 Loss_G: 5.2243\n",
      "[9/25][160/782] Loss_D: 0.0778 Loss_G: 4.0462\n",
      "[9/25][161/782] Loss_D: 0.0388 Loss_G: 4.7405\n",
      "[9/25][162/782] Loss_D: 0.0890 Loss_G: 4.3780\n",
      "[9/25][163/782] Loss_D: 0.0332 Loss_G: 5.6061\n",
      "[9/25][164/782] Loss_D: 0.0628 Loss_G: 4.1194\n",
      "[9/25][165/782] Loss_D: 0.0506 Loss_G: 4.3117\n",
      "[9/25][166/782] Loss_D: 0.0655 Loss_G: 5.2513\n",
      "[9/25][167/782] Loss_D: 0.2173 Loss_G: 5.0549\n",
      "[9/25][168/782] Loss_D: 0.0592 Loss_G: 6.3089\n",
      "[9/25][169/782] Loss_D: 0.0786 Loss_G: 5.5158\n",
      "[9/25][170/782] Loss_D: 0.0405 Loss_G: 4.1249\n",
      "[9/25][171/782] Loss_D: 0.0171 Loss_G: 5.6106\n",
      "[9/25][172/782] Loss_D: 0.0490 Loss_G: 4.2760\n",
      "[9/25][173/782] Loss_D: 0.0203 Loss_G: 4.7883\n",
      "[9/25][174/782] Loss_D: 0.0405 Loss_G: 4.4516\n",
      "[9/25][175/782] Loss_D: 0.0145 Loss_G: 5.5653\n",
      "[9/25][176/782] Loss_D: 0.0642 Loss_G: 4.1647\n",
      "[9/25][177/782] Loss_D: 0.0318 Loss_G: 5.3145\n",
      "[9/25][178/782] Loss_D: 0.0417 Loss_G: 4.8307\n",
      "[9/25][179/782] Loss_D: 0.0305 Loss_G: 5.1389\n",
      "[9/25][180/782] Loss_D: 0.0157 Loss_G: 5.1684\n",
      "[9/25][181/782] Loss_D: 0.0778 Loss_G: 4.2716\n",
      "[9/25][182/782] Loss_D: 0.0231 Loss_G: 5.4611\n",
      "[9/25][183/782] Loss_D: 0.0425 Loss_G: 5.7273\n",
      "[9/25][184/782] Loss_D: 0.0375 Loss_G: 4.2616\n",
      "[9/25][185/782] Loss_D: 0.0377 Loss_G: 4.7576\n",
      "[9/25][186/782] Loss_D: 0.0378 Loss_G: 4.6612\n",
      "[9/25][187/782] Loss_D: 0.0542 Loss_G: 4.3461\n",
      "[9/25][188/782] Loss_D: 0.0276 Loss_G: 5.5120\n",
      "[9/25][189/782] Loss_D: 0.0378 Loss_G: 4.6824\n",
      "[9/25][190/782] Loss_D: 0.0152 Loss_G: 5.6280\n",
      "[9/25][191/782] Loss_D: 0.1628 Loss_G: 6.0230\n",
      "[9/25][192/782] Loss_D: 0.0820 Loss_G: 7.1486\n",
      "[9/25][193/782] Loss_D: 0.1071 Loss_G: 4.0246\n",
      "[9/25][194/782] Loss_D: 0.0243 Loss_G: 4.4184\n",
      "[9/25][195/782] Loss_D: 0.0123 Loss_G: 5.9096\n",
      "[9/25][196/782] Loss_D: 0.0373 Loss_G: 4.2884\n",
      "[9/25][197/782] Loss_D: 0.0090 Loss_G: 5.7212\n",
      "[9/25][198/782] Loss_D: 0.0429 Loss_G: 4.4193\n",
      "[9/25][199/782] Loss_D: 0.0397 Loss_G: 4.7008\n",
      "[9/25][200/782] Loss_D: 0.0371 Loss_G: 4.8219\n",
      "[9/25][201/782] Loss_D: 0.0452 Loss_G: 5.7040\n",
      "[9/25][202/782] Loss_D: 0.0086 Loss_G: 5.6925\n",
      "[9/25][203/782] Loss_D: 0.0256 Loss_G: 4.8063\n",
      "[9/25][204/782] Loss_D: 0.0265 Loss_G: 6.1792\n",
      "[9/25][205/782] Loss_D: 0.0279 Loss_G: 4.6426\n",
      "[9/25][206/782] Loss_D: 0.0178 Loss_G: 5.1383\n",
      "[9/25][207/782] Loss_D: 0.0104 Loss_G: 7.2994\n",
      "[9/25][208/782] Loss_D: 0.0741 Loss_G: 4.4059\n",
      "[9/25][209/782] Loss_D: 0.0075 Loss_G: 7.4011\n",
      "[9/25][210/782] Loss_D: 0.0436 Loss_G: 4.9561\n",
      "[9/25][211/782] Loss_D: 0.0276 Loss_G: 4.6733\n",
      "[9/25][212/782] Loss_D: 0.0097 Loss_G: 5.4823\n",
      "[9/25][213/782] Loss_D: 0.0690 Loss_G: 4.8276\n",
      "[9/25][214/782] Loss_D: 0.0193 Loss_G: 6.8875\n",
      "[9/25][215/782] Loss_D: 0.1093 Loss_G: 4.2283\n",
      "[9/25][216/782] Loss_D: 0.0458 Loss_G: 5.6839\n",
      "[9/25][217/782] Loss_D: 0.0453 Loss_G: 4.7222\n",
      "[9/25][218/782] Loss_D: 0.0113 Loss_G: 5.8675\n",
      "[9/25][219/782] Loss_D: 0.1080 Loss_G: 5.3844\n",
      "[9/25][220/782] Loss_D: 0.0125 Loss_G: 8.0243\n",
      "[9/25][221/782] Loss_D: 0.1055 Loss_G: 4.9306\n",
      "[9/25][222/782] Loss_D: 0.0150 Loss_G: 7.9440\n",
      "[9/25][223/782] Loss_D: 0.0173 Loss_G: 4.4863\n",
      "[9/25][224/782] Loss_D: 0.0067 Loss_G: 6.4220\n",
      "[9/25][225/782] Loss_D: 0.0180 Loss_G: 5.2483\n",
      "[9/25][226/782] Loss_D: 0.0775 Loss_G: 4.8404\n",
      "[9/25][227/782] Loss_D: 0.0283 Loss_G: 6.2797\n",
      "[9/25][228/782] Loss_D: 0.0260 Loss_G: 6.1977\n",
      "[9/25][229/782] Loss_D: 0.0139 Loss_G: 5.8608\n",
      "[9/25][230/782] Loss_D: 0.0335 Loss_G: 4.6675\n",
      "[9/25][231/782] Loss_D: 0.0186 Loss_G: 5.3696\n",
      "[9/25][232/782] Loss_D: 0.0207 Loss_G: 5.8302\n",
      "[9/25][233/782] Loss_D: 0.0095 Loss_G: 6.8169\n",
      "[9/25][234/782] Loss_D: 0.1274 Loss_G: 6.5881\n",
      "[9/25][235/782] Loss_D: 0.0321 Loss_G: 8.3215\n",
      "[9/25][236/782] Loss_D: 0.1652 Loss_G: 4.5453\n",
      "[9/25][237/782] Loss_D: 0.0080 Loss_G: 6.7866\n",
      "[9/25][238/782] Loss_D: 0.0541 Loss_G: 5.1327\n",
      "[9/25][239/782] Loss_D: 0.0395 Loss_G: 7.6100\n",
      "[9/25][240/782] Loss_D: 0.2972 Loss_G: 9.2504\n",
      "[9/25][241/782] Loss_D: 0.1492 Loss_G: 9.7545\n",
      "[9/25][242/782] Loss_D: 0.1043 Loss_G: 7.2701\n",
      "[9/25][243/782] Loss_D: 0.0273 Loss_G: 5.6112\n",
      "[9/25][244/782] Loss_D: 0.0067 Loss_G: 7.0253\n",
      "[9/25][245/782] Loss_D: 0.1912 Loss_G: 7.8680\n",
      "[9/25][246/782] Loss_D: 0.0315 Loss_G: 10.0448\n",
      "[9/25][247/782] Loss_D: 0.0557 Loss_G: 6.9489\n",
      "[9/25][248/782] Loss_D: 0.0199 Loss_G: 9.0468\n",
      "[9/25][249/782] Loss_D: 0.0044 Loss_G: 6.2572\n",
      "[9/25][250/782] Loss_D: 0.0088 Loss_G: 7.0302\n",
      "[9/25][251/782] Loss_D: 0.0151 Loss_G: 5.9354\n",
      "[9/25][252/782] Loss_D: 0.0078 Loss_G: 6.2844\n",
      "[9/25][253/782] Loss_D: 0.0087 Loss_G: 5.6615\n",
      "[9/25][254/782] Loss_D: 0.0031 Loss_G: 7.6007\n",
      "[9/25][255/782] Loss_D: 0.0275 Loss_G: 5.4634\n",
      "[9/25][256/782] Loss_D: 0.0333 Loss_G: 6.7283\n",
      "[9/25][257/782] Loss_D: 0.0149 Loss_G: 5.3366\n",
      "[9/25][258/782] Loss_D: 0.0139 Loss_G: 5.5913\n",
      "[9/25][259/782] Loss_D: 0.0090 Loss_G: 8.2751\n",
      "[9/25][260/782] Loss_D: 0.0259 Loss_G: 5.4928\n",
      "[9/25][261/782] Loss_D: 0.0015 Loss_G: 10.4063\n",
      "[9/25][262/782] Loss_D: 0.0060 Loss_G: 10.8306\n",
      "[9/25][263/782] Loss_D: 0.0053 Loss_G: 8.6889\n",
      "[9/25][264/782] Loss_D: 0.0328 Loss_G: 5.0278\n",
      "[9/25][265/782] Loss_D: 0.0127 Loss_G: 5.7543\n",
      "[9/25][266/782] Loss_D: 0.0383 Loss_G: 5.3957\n",
      "[9/25][267/782] Loss_D: 0.0245 Loss_G: 4.7525\n",
      "[9/25][268/782] Loss_D: 0.0161 Loss_G: 5.5563\n",
      "[9/25][269/782] Loss_D: 0.0146 Loss_G: 5.8048\n",
      "[9/25][270/782] Loss_D: 0.0777 Loss_G: 5.4949\n",
      "[9/25][271/782] Loss_D: 0.0221 Loss_G: 7.1457\n",
      "[9/25][272/782] Loss_D: 0.0949 Loss_G: 3.6524\n",
      "[9/25][273/782] Loss_D: 0.0064 Loss_G: 6.6792\n",
      "[9/25][274/782] Loss_D: 0.1227 Loss_G: 6.5584\n",
      "[9/25][275/782] Loss_D: 0.0678 Loss_G: 7.7270\n",
      "[9/25][276/782] Loss_D: 0.0160 Loss_G: 6.1415\n",
      "[9/25][277/782] Loss_D: 0.0331 Loss_G: 5.5192\n",
      "[9/25][278/782] Loss_D: 0.0100 Loss_G: 6.2161\n",
      "[9/25][279/782] Loss_D: 0.0314 Loss_G: 4.8104\n",
      "[9/25][280/782] Loss_D: 0.0116 Loss_G: 6.6134\n",
      "[9/25][281/782] Loss_D: 0.0907 Loss_G: 5.7035\n",
      "[9/25][282/782] Loss_D: 0.1202 Loss_G: 6.9128\n",
      "[9/25][283/782] Loss_D: 0.0226 Loss_G: 5.2589\n",
      "[9/25][284/782] Loss_D: 0.0076 Loss_G: 9.2685\n",
      "[9/25][285/782] Loss_D: 0.0121 Loss_G: 7.1431\n",
      "[9/25][286/782] Loss_D: 0.0075 Loss_G: 6.2949\n",
      "[9/25][287/782] Loss_D: 0.0569 Loss_G: 5.3076\n",
      "[9/25][288/782] Loss_D: 0.0140 Loss_G: 6.0528\n",
      "[9/25][289/782] Loss_D: 0.0144 Loss_G: 7.1331\n",
      "[9/25][290/782] Loss_D: 0.0651 Loss_G: 5.1943\n",
      "[9/25][291/782] Loss_D: 0.0128 Loss_G: 8.1440\n",
      "[9/25][292/782] Loss_D: 0.0335 Loss_G: 4.7006\n",
      "[9/25][293/782] Loss_D: 0.0215 Loss_G: 5.9937\n",
      "[9/25][294/782] Loss_D: 0.0476 Loss_G: 4.9707\n",
      "[9/25][295/782] Loss_D: 0.0148 Loss_G: 6.5070\n",
      "[9/25][296/782] Loss_D: 0.0113 Loss_G: 7.4651\n",
      "[9/25][297/782] Loss_D: 0.0750 Loss_G: 4.4453\n",
      "[9/25][298/782] Loss_D: 0.0234 Loss_G: 5.4051\n",
      "[9/25][299/782] Loss_D: 0.0143 Loss_G: 5.7015\n",
      "[9/25][300/782] Loss_D: 0.0118 Loss_G: 8.3099\n",
      "[9/25][301/782] Loss_D: 0.0247 Loss_G: 5.2035\n",
      "[9/25][302/782] Loss_D: 0.0038 Loss_G: 8.8648\n",
      "[9/25][303/782] Loss_D: 0.0055 Loss_G: 7.2496\n",
      "[9/25][304/782] Loss_D: 0.0084 Loss_G: 5.6057\n",
      "[9/25][305/782] Loss_D: 0.0278 Loss_G: 4.9024\n",
      "[9/25][306/782] Loss_D: 0.0131 Loss_G: 6.0954\n",
      "[9/25][307/782] Loss_D: 0.0724 Loss_G: 5.0285\n",
      "[9/25][308/782] Loss_D: 0.0287 Loss_G: 6.6083\n",
      "[9/25][309/782] Loss_D: 0.0317 Loss_G: 4.9230\n",
      "[9/25][310/782] Loss_D: 0.0190 Loss_G: 6.4444\n",
      "[9/25][311/782] Loss_D: 0.0396 Loss_G: 4.9116\n",
      "[9/25][312/782] Loss_D: 0.0201 Loss_G: 5.1139\n",
      "[9/25][313/782] Loss_D: 0.0253 Loss_G: 5.7164\n",
      "[9/25][314/782] Loss_D: 0.0567 Loss_G: 4.8334\n",
      "[9/25][315/782] Loss_D: 0.0273 Loss_G: 6.0027\n",
      "[9/25][316/782] Loss_D: 0.0158 Loss_G: 5.3581\n",
      "[9/25][317/782] Loss_D: 0.0128 Loss_G: 6.8313\n",
      "[9/25][318/782] Loss_D: 0.0808 Loss_G: 5.5758\n",
      "[9/25][319/782] Loss_D: 0.0663 Loss_G: 6.2955\n",
      "[9/25][320/782] Loss_D: 0.0172 Loss_G: 5.2713\n",
      "[9/25][321/782] Loss_D: 0.0094 Loss_G: 6.6895\n",
      "[9/25][322/782] Loss_D: 0.0355 Loss_G: 4.9827\n",
      "[9/25][323/782] Loss_D: 0.0112 Loss_G: 5.6916\n",
      "[9/25][324/782] Loss_D: 0.0209 Loss_G: 5.5691\n",
      "[9/25][325/782] Loss_D: 0.0076 Loss_G: 7.0788\n",
      "[9/25][326/782] Loss_D: 0.0505 Loss_G: 5.5734\n",
      "[9/25][327/782] Loss_D: 0.0066 Loss_G: 9.8488\n",
      "[9/25][328/782] Loss_D: 0.0427 Loss_G: 6.7920\n",
      "[9/25][329/782] Loss_D: 0.0115 Loss_G: 7.2172\n",
      "[9/25][330/782] Loss_D: 0.0246 Loss_G: 4.7427\n",
      "[9/25][331/782] Loss_D: 0.0072 Loss_G: 6.1040\n",
      "[9/25][332/782] Loss_D: 0.0325 Loss_G: 5.1328\n",
      "[9/25][333/782] Loss_D: 0.0168 Loss_G: 5.4306\n",
      "[9/25][334/782] Loss_D: 0.0171 Loss_G: 5.9421\n",
      "[9/25][335/782] Loss_D: 0.0577 Loss_G: 5.4992\n",
      "[9/25][336/782] Loss_D: 0.0366 Loss_G: 6.4914\n",
      "[9/25][337/782] Loss_D: 0.0215 Loss_G: 4.9585\n",
      "[9/25][338/782] Loss_D: 0.0046 Loss_G: 6.6038\n",
      "[9/25][339/782] Loss_D: 0.0509 Loss_G: 5.3623\n",
      "[9/25][340/782] Loss_D: 0.0256 Loss_G: 6.2844\n",
      "[9/25][341/782] Loss_D: 0.0537 Loss_G: 4.2578\n",
      "[9/25][342/782] Loss_D: 0.0126 Loss_G: 5.6604\n",
      "[9/25][343/782] Loss_D: 0.0117 Loss_G: 5.6802\n",
      "[9/25][344/782] Loss_D: 0.0238 Loss_G: 4.8478\n",
      "[9/25][345/782] Loss_D: 0.0091 Loss_G: 5.8045\n",
      "[9/25][346/782] Loss_D: 0.0274 Loss_G: 5.2003\n",
      "[9/25][347/782] Loss_D: 0.0101 Loss_G: 6.4111\n",
      "[9/25][348/782] Loss_D: 0.0200 Loss_G: 5.5839\n",
      "[9/25][349/782] Loss_D: 0.0241 Loss_G: 5.4072\n",
      "[9/25][350/782] Loss_D: 0.0179 Loss_G: 7.0159\n",
      "[9/25][351/782] Loss_D: 0.1061 Loss_G: 6.5278\n",
      "[9/25][352/782] Loss_D: 0.0251 Loss_G: 8.0992\n",
      "[9/25][353/782] Loss_D: 0.1509 Loss_G: 3.8849\n",
      "[9/25][354/782] Loss_D: 0.0028 Loss_G: 7.1498\n",
      "[9/25][355/782] Loss_D: 0.3079 Loss_G: 11.7799\n",
      "[9/25][356/782] Loss_D: 5.1855 Loss_G: 7.4212\n",
      "[9/25][357/782] Loss_D: 5.0476 Loss_G: 0.0386\n",
      "[9/25][358/782] Loss_D: 4.8241 Loss_G: 5.0843\n",
      "[9/25][359/782] Loss_D: 1.8393 Loss_G: 1.5875\n",
      "[9/25][360/782] Loss_D: 0.7375 Loss_G: 2.6830\n",
      "[9/25][361/782] Loss_D: 0.6248 Loss_G: 3.1772\n",
      "[9/25][362/782] Loss_D: 0.7838 Loss_G: 2.4488\n",
      "[9/25][363/782] Loss_D: 0.3779 Loss_G: 2.9715\n",
      "[9/25][364/782] Loss_D: 0.4193 Loss_G: 2.4319\n",
      "[9/25][365/782] Loss_D: 0.6150 Loss_G: 3.1158\n",
      "[9/25][366/782] Loss_D: 0.5685 Loss_G: 2.0567\n",
      "[9/25][367/782] Loss_D: 0.6893 Loss_G: 3.2657\n",
      "[9/25][368/782] Loss_D: 0.4742 Loss_G: 3.1781\n",
      "[9/25][369/782] Loss_D: 0.5231 Loss_G: 1.5140\n",
      "[9/25][370/782] Loss_D: 0.7221 Loss_G: 4.1432\n",
      "[9/25][371/782] Loss_D: 0.4426 Loss_G: 3.4113\n",
      "[9/25][372/782] Loss_D: 0.6261 Loss_G: 1.0374\n",
      "[9/25][373/782] Loss_D: 0.8738 Loss_G: 4.4404\n",
      "[9/25][374/782] Loss_D: 0.6778 Loss_G: 2.8549\n",
      "[9/25][375/782] Loss_D: 0.3116 Loss_G: 2.7343\n",
      "[9/25][376/782] Loss_D: 0.5550 Loss_G: 2.6606\n",
      "[9/25][377/782] Loss_D: 0.3141 Loss_G: 3.2568\n",
      "[9/25][378/782] Loss_D: 0.6878 Loss_G: 2.1150\n",
      "[9/25][379/782] Loss_D: 0.5573 Loss_G: 2.9398\n",
      "[9/25][380/782] Loss_D: 0.5302 Loss_G: 3.0746\n",
      "[9/25][381/782] Loss_D: 0.7722 Loss_G: 1.0216\n",
      "[9/25][382/782] Loss_D: 1.0678 Loss_G: 4.3696\n",
      "[9/25][383/782] Loss_D: 0.7566 Loss_G: 2.7706\n",
      "[9/25][384/782] Loss_D: 0.3940 Loss_G: 2.4971\n",
      "[9/25][385/782] Loss_D: 0.4793 Loss_G: 3.8008\n",
      "[9/25][386/782] Loss_D: 0.5275 Loss_G: 2.6775\n",
      "[9/25][387/782] Loss_D: 0.3029 Loss_G: 2.9268\n",
      "[9/25][388/782] Loss_D: 0.3902 Loss_G: 2.4048\n",
      "[9/25][389/782] Loss_D: 0.6593 Loss_G: 2.9982\n",
      "[9/25][390/782] Loss_D: 0.5873 Loss_G: 2.8994\n",
      "[9/25][391/782] Loss_D: 0.7580 Loss_G: 1.7403\n",
      "[9/25][392/782] Loss_D: 0.7163 Loss_G: 4.6671\n",
      "[9/25][393/782] Loss_D: 0.4332 Loss_G: 3.2460\n",
      "[9/25][394/782] Loss_D: 0.4466 Loss_G: 1.9657\n",
      "[9/25][395/782] Loss_D: 0.3850 Loss_G: 3.2425\n",
      "[9/25][396/782] Loss_D: 0.2332 Loss_G: 3.9633\n",
      "[9/25][397/782] Loss_D: 0.3040 Loss_G: 2.8984\n",
      "[9/25][398/782] Loss_D: 0.2989 Loss_G: 2.3978\n",
      "[9/25][399/782] Loss_D: 0.4866 Loss_G: 4.4432\n",
      "[9/25][400/782] Loss_D: 0.2245 Loss_G: 4.2486\n",
      "[9/25][401/782] Loss_D: 0.4486 Loss_G: 2.4037\n",
      "[9/25][402/782] Loss_D: 0.4808 Loss_G: 3.3489\n",
      "[9/25][403/782] Loss_D: 0.4716 Loss_G: 2.9275\n",
      "[9/25][404/782] Loss_D: 0.5040 Loss_G: 4.3030\n",
      "[9/25][405/782] Loss_D: 0.7394 Loss_G: 1.6657\n",
      "[9/25][406/782] Loss_D: 0.6356 Loss_G: 3.6650\n",
      "[9/25][407/782] Loss_D: 0.2697 Loss_G: 3.8661\n",
      "[9/25][408/782] Loss_D: 0.2606 Loss_G: 3.2479\n",
      "[9/25][409/782] Loss_D: 0.4807 Loss_G: 2.7224\n",
      "[9/25][410/782] Loss_D: 0.3390 Loss_G: 2.9684\n",
      "[9/25][411/782] Loss_D: 0.3677 Loss_G: 3.3984\n",
      "[9/25][412/782] Loss_D: 0.4140 Loss_G: 2.9086\n",
      "[9/25][413/782] Loss_D: 0.4545 Loss_G: 3.2218\n",
      "[9/25][414/782] Loss_D: 0.4314 Loss_G: 3.3666\n",
      "[9/25][415/782] Loss_D: 0.4134 Loss_G: 2.7567\n",
      "[9/25][416/782] Loss_D: 0.4646 Loss_G: 3.8531\n",
      "[9/25][417/782] Loss_D: 0.3991 Loss_G: 3.1888\n",
      "[9/25][418/782] Loss_D: 0.3395 Loss_G: 4.0761\n",
      "[9/25][419/782] Loss_D: 0.5498 Loss_G: 1.4259\n",
      "[9/25][420/782] Loss_D: 0.6861 Loss_G: 5.4500\n",
      "[9/25][421/782] Loss_D: 0.2661 Loss_G: 4.5902\n",
      "[9/25][422/782] Loss_D: 0.4806 Loss_G: 2.0432\n",
      "[9/25][423/782] Loss_D: 0.6225 Loss_G: 4.5701\n",
      "[9/25][424/782] Loss_D: 0.4044 Loss_G: 3.1104\n",
      "[9/25][425/782] Loss_D: 0.3658 Loss_G: 4.6038\n",
      "[9/25][426/782] Loss_D: 0.8064 Loss_G: 1.0212\n",
      "[9/25][427/782] Loss_D: 1.3243 Loss_G: 7.1818\n",
      "[9/25][428/782] Loss_D: 0.9492 Loss_G: 3.5849\n",
      "[9/25][429/782] Loss_D: 0.3711 Loss_G: 1.5892\n",
      "[9/25][430/782] Loss_D: 0.7399 Loss_G: 5.0828\n",
      "[9/25][431/782] Loss_D: 0.4813 Loss_G: 3.5241\n",
      "[9/25][432/782] Loss_D: 0.3004 Loss_G: 3.2355\n",
      "[9/25][433/782] Loss_D: 0.5868 Loss_G: 3.0050\n",
      "[9/25][434/782] Loss_D: 0.5242 Loss_G: 4.4237\n",
      "[9/25][435/782] Loss_D: 0.8728 Loss_G: 1.2676\n",
      "[9/25][436/782] Loss_D: 1.3613 Loss_G: 5.8846\n",
      "[9/25][437/782] Loss_D: 0.8168 Loss_G: 2.3147\n",
      "[9/25][438/782] Loss_D: 0.4188 Loss_G: 3.2257\n",
      "[9/25][439/782] Loss_D: 0.3313 Loss_G: 3.6014\n",
      "[9/25][440/782] Loss_D: 0.7395 Loss_G: 1.9992\n",
      "[9/25][441/782] Loss_D: 0.5199 Loss_G: 4.1945\n",
      "[9/25][442/782] Loss_D: 0.2817 Loss_G: 3.6086\n",
      "[9/25][443/782] Loss_D: 0.4028 Loss_G: 2.0228\n",
      "[9/25][444/782] Loss_D: 0.5256 Loss_G: 4.9938\n",
      "[9/25][445/782] Loss_D: 0.3114 Loss_G: 3.4968\n",
      "[9/25][446/782] Loss_D: 0.4609 Loss_G: 2.2269\n",
      "[9/25][447/782] Loss_D: 0.4508 Loss_G: 4.8311\n",
      "[9/25][448/782] Loss_D: 0.5773 Loss_G: 1.9848\n",
      "[9/25][449/782] Loss_D: 0.4969 Loss_G: 5.0054\n",
      "[9/25][450/782] Loss_D: 0.5358 Loss_G: 2.3049\n",
      "[9/25][451/782] Loss_D: 0.5112 Loss_G: 4.7001\n",
      "[9/25][452/782] Loss_D: 0.6059 Loss_G: 2.0845\n",
      "[9/25][453/782] Loss_D: 0.6647 Loss_G: 5.1876\n",
      "[9/25][454/782] Loss_D: 0.3750 Loss_G: 3.6609\n",
      "[9/25][455/782] Loss_D: 0.3915 Loss_G: 1.9443\n",
      "[9/25][456/782] Loss_D: 0.5440 Loss_G: 5.3812\n",
      "[9/25][457/782] Loss_D: 0.4982 Loss_G: 2.5499\n",
      "[9/25][458/782] Loss_D: 0.3398 Loss_G: 3.3048\n",
      "[9/25][459/782] Loss_D: 0.1753 Loss_G: 4.0411\n",
      "[9/25][460/782] Loss_D: 0.3506 Loss_G: 3.6413\n",
      "[9/25][461/782] Loss_D: 0.2570 Loss_G: 5.5510\n",
      "[9/25][462/782] Loss_D: 0.6471 Loss_G: 0.5332\n",
      "[9/25][463/782] Loss_D: 3.5285 Loss_G: 9.7373\n",
      "[9/25][464/782] Loss_D: 4.9559 Loss_G: 3.6629\n",
      "[9/25][465/782] Loss_D: 0.6257 Loss_G: 0.3361\n",
      "[9/25][466/782] Loss_D: 1.7646 Loss_G: 4.3645\n",
      "[9/25][467/782] Loss_D: 0.7367 Loss_G: 3.3467\n",
      "[9/25][468/782] Loss_D: 0.5243 Loss_G: 2.4186\n",
      "[9/25][469/782] Loss_D: 0.4840 Loss_G: 2.4206\n",
      "[9/25][470/782] Loss_D: 0.5342 Loss_G: 2.6169\n",
      "[9/25][471/782] Loss_D: 0.6594 Loss_G: 3.6380\n",
      "[9/25][472/782] Loss_D: 0.9029 Loss_G: 2.0416\n",
      "[9/25][473/782] Loss_D: 0.8612 Loss_G: 2.8495\n",
      "[9/25][474/782] Loss_D: 0.5837 Loss_G: 3.1399\n",
      "[9/25][475/782] Loss_D: 1.0395 Loss_G: 1.5004\n",
      "[9/25][476/782] Loss_D: 1.5657 Loss_G: 5.5891\n",
      "[9/25][477/782] Loss_D: 2.0510 Loss_G: 1.8943\n",
      "[9/25][478/782] Loss_D: 0.9873 Loss_G: 4.2061\n",
      "[9/25][479/782] Loss_D: 0.7587 Loss_G: 2.5601\n",
      "[9/25][480/782] Loss_D: 0.8979 Loss_G: 3.1700\n",
      "[9/25][481/782] Loss_D: 0.3327 Loss_G: 3.7654\n",
      "[9/25][482/782] Loss_D: 0.3011 Loss_G: 3.4964\n",
      "[9/25][483/782] Loss_D: 0.3609 Loss_G: 3.6332\n",
      "[9/25][484/782] Loss_D: 0.2876 Loss_G: 3.4423\n",
      "[9/25][485/782] Loss_D: 0.4784 Loss_G: 2.9430\n",
      "[9/25][486/782] Loss_D: 0.2647 Loss_G: 3.7804\n",
      "[9/25][487/782] Loss_D: 0.3257 Loss_G: 3.5514\n",
      "[9/25][488/782] Loss_D: 0.2736 Loss_G: 3.5403\n",
      "[9/25][489/782] Loss_D: 0.4556 Loss_G: 2.5614\n",
      "[9/25][490/782] Loss_D: 0.4546 Loss_G: 3.7130\n",
      "[9/25][491/782] Loss_D: 0.4104 Loss_G: 2.8963\n",
      "[9/25][492/782] Loss_D: 0.3295 Loss_G: 2.8495\n",
      "[9/25][493/782] Loss_D: 0.3789 Loss_G: 3.5106\n",
      "[9/25][494/782] Loss_D: 0.3420 Loss_G: 3.3042\n",
      "[9/25][495/782] Loss_D: 0.3294 Loss_G: 2.9212\n",
      "[9/25][496/782] Loss_D: 0.3290 Loss_G: 3.4766\n",
      "[9/25][497/782] Loss_D: 0.2776 Loss_G: 3.5464\n",
      "[9/25][498/782] Loss_D: 0.2024 Loss_G: 3.1347\n",
      "[9/25][499/782] Loss_D: 0.1616 Loss_G: 3.5928\n",
      "[9/25][500/782] Loss_D: 0.1856 Loss_G: 3.4732\n",
      "[9/25][501/782] Loss_D: 0.2000 Loss_G: 3.1415\n",
      "[9/25][502/782] Loss_D: 0.2413 Loss_G: 3.3014\n",
      "[9/25][503/782] Loss_D: 0.2118 Loss_G: 4.2405\n",
      "[9/25][504/782] Loss_D: 0.1715 Loss_G: 3.9437\n",
      "[9/25][505/782] Loss_D: 0.5176 Loss_G: 1.3270\n",
      "[9/25][506/782] Loss_D: 0.5965 Loss_G: 4.6357\n",
      "[9/25][507/782] Loss_D: 0.1609 Loss_G: 4.6240\n",
      "[9/25][508/782] Loss_D: 0.3077 Loss_G: 3.2159\n",
      "[9/25][509/782] Loss_D: 0.1476 Loss_G: 2.7175\n",
      "[9/25][510/782] Loss_D: 0.5283 Loss_G: 6.1196\n",
      "[9/25][511/782] Loss_D: 1.1670 Loss_G: 2.8029\n",
      "[9/25][512/782] Loss_D: 0.5787 Loss_G: 2.6628\n",
      "[9/25][513/782] Loss_D: 0.8202 Loss_G: 2.7911\n",
      "[9/25][514/782] Loss_D: 0.8186 Loss_G: 1.6217\n",
      "[9/25][515/782] Loss_D: 1.5235 Loss_G: 6.5596\n",
      "[9/25][516/782] Loss_D: 1.9994 Loss_G: 2.0690\n",
      "[9/25][517/782] Loss_D: 0.6598 Loss_G: 4.4009\n",
      "[9/25][518/782] Loss_D: 0.7108 Loss_G: 1.5095\n",
      "[9/25][519/782] Loss_D: 1.5527 Loss_G: 6.8317\n",
      "[9/25][520/782] Loss_D: 1.6092 Loss_G: 1.0896\n",
      "[9/25][521/782] Loss_D: 1.1907 Loss_G: 6.1031\n",
      "[9/25][522/782] Loss_D: 0.6540 Loss_G: 3.0163\n",
      "[9/25][523/782] Loss_D: 0.3960 Loss_G: 2.3842\n",
      "[9/25][524/782] Loss_D: 0.7372 Loss_G: 4.2080\n",
      "[9/25][525/782] Loss_D: 0.3229 Loss_G: 3.6857\n",
      "[9/25][526/782] Loss_D: 0.3512 Loss_G: 2.2845\n",
      "[9/25][527/782] Loss_D: 0.3966 Loss_G: 3.8283\n",
      "[9/25][528/782] Loss_D: 0.3868 Loss_G: 3.9692\n",
      "[9/25][529/782] Loss_D: 0.1920 Loss_G: 4.4013\n",
      "[9/25][530/782] Loss_D: 0.1911 Loss_G: 3.5915\n",
      "[9/25][531/782] Loss_D: 0.2455 Loss_G: 2.9631\n",
      "[9/25][532/782] Loss_D: 0.2866 Loss_G: 4.2325\n",
      "[9/25][533/782] Loss_D: 0.1816 Loss_G: 3.9346\n",
      "[9/25][534/782] Loss_D: 0.2045 Loss_G: 3.8465\n",
      "[9/25][535/782] Loss_D: 0.2549 Loss_G: 2.8927\n",
      "[9/25][536/782] Loss_D: 0.4175 Loss_G: 6.2586\n",
      "[9/25][537/782] Loss_D: 1.1825 Loss_G: 3.3810\n",
      "[9/25][538/782] Loss_D: 1.1077 Loss_G: 0.0769\n",
      "[9/25][539/782] Loss_D: 3.9863 Loss_G: 6.0836\n",
      "[9/25][540/782] Loss_D: 2.0617 Loss_G: 0.8176\n",
      "[9/25][541/782] Loss_D: 1.3201 Loss_G: 4.7061\n",
      "[9/25][542/782] Loss_D: 1.0926 Loss_G: 1.6695\n",
      "[9/25][543/782] Loss_D: 0.5000 Loss_G: 2.6216\n",
      "[9/25][544/782] Loss_D: 0.4684 Loss_G: 3.0579\n",
      "[9/25][545/782] Loss_D: 0.5495 Loss_G: 2.2377\n",
      "[9/25][546/782] Loss_D: 0.5930 Loss_G: 2.4509\n",
      "[9/25][547/782] Loss_D: 0.3785 Loss_G: 3.0408\n",
      "[9/25][548/782] Loss_D: 0.8427 Loss_G: 2.2077\n",
      "[9/25][549/782] Loss_D: 0.4808 Loss_G: 3.6066\n",
      "[9/25][550/782] Loss_D: 0.6727 Loss_G: 1.8491\n",
      "[9/25][551/782] Loss_D: 0.7675 Loss_G: 3.6881\n",
      "[9/25][552/782] Loss_D: 0.7459 Loss_G: 1.9518\n",
      "[9/25][553/782] Loss_D: 0.6004 Loss_G: 3.1312\n",
      "[9/25][554/782] Loss_D: 0.8993 Loss_G: 1.6618\n",
      "[9/25][555/782] Loss_D: 0.8537 Loss_G: 3.4906\n",
      "[9/25][556/782] Loss_D: 0.6878 Loss_G: 2.6918\n",
      "[9/25][557/782] Loss_D: 0.6315 Loss_G: 2.7078\n",
      "[9/25][558/782] Loss_D: 0.4226 Loss_G: 2.7883\n",
      "[9/25][559/782] Loss_D: 0.4710 Loss_G: 3.7414\n",
      "[9/25][560/782] Loss_D: 0.5988 Loss_G: 1.9137\n",
      "[9/25][561/782] Loss_D: 0.6959 Loss_G: 2.8775\n",
      "[9/25][562/782] Loss_D: 0.6355 Loss_G: 3.2015\n",
      "[9/25][563/782] Loss_D: 0.4974 Loss_G: 1.7954\n",
      "[9/25][564/782] Loss_D: 0.9675 Loss_G: 5.2019\n",
      "[9/25][565/782] Loss_D: 1.4686 Loss_G: 0.8782\n",
      "[9/25][566/782] Loss_D: 1.2001 Loss_G: 5.0287\n",
      "[9/25][567/782] Loss_D: 0.3938 Loss_G: 3.0538\n",
      "[9/25][568/782] Loss_D: 0.4056 Loss_G: 2.7109\n",
      "[9/25][569/782] Loss_D: 0.4529 Loss_G: 2.5282\n",
      "[9/25][570/782] Loss_D: 0.5329 Loss_G: 5.4689\n",
      "[9/25][571/782] Loss_D: 1.4566 Loss_G: 0.4976\n",
      "[9/25][572/782] Loss_D: 1.4438 Loss_G: 5.5260\n",
      "[9/25][573/782] Loss_D: 1.0531 Loss_G: 1.4094\n",
      "[9/25][574/782] Loss_D: 0.7186 Loss_G: 4.5919\n",
      "[9/25][575/782] Loss_D: 0.4056 Loss_G: 3.4876\n",
      "[9/25][576/782] Loss_D: 0.3043 Loss_G: 2.8115\n",
      "[9/25][577/782] Loss_D: 0.2404 Loss_G: 3.8552\n",
      "[9/25][578/782] Loss_D: 0.1264 Loss_G: 4.0479\n",
      "[9/25][579/782] Loss_D: 0.1667 Loss_G: 3.9686\n",
      "[9/25][580/782] Loss_D: 0.1680 Loss_G: 3.1367\n",
      "[9/25][581/782] Loss_D: 0.1373 Loss_G: 4.3910\n",
      "[9/25][582/782] Loss_D: 0.2397 Loss_G: 5.4969\n",
      "[9/25][583/782] Loss_D: 0.1704 Loss_G: 3.7762\n",
      "[9/25][584/782] Loss_D: 0.1173 Loss_G: 3.5437\n",
      "[9/25][585/782] Loss_D: 0.1172 Loss_G: 5.0863\n",
      "[9/25][586/782] Loss_D: 0.1096 Loss_G: 4.3114\n",
      "[9/25][587/782] Loss_D: 0.0953 Loss_G: 4.7442\n",
      "[9/25][588/782] Loss_D: 0.0714 Loss_G: 5.1356\n",
      "[9/25][589/782] Loss_D: 0.1508 Loss_G: 4.8782\n",
      "[9/25][590/782] Loss_D: 0.1803 Loss_G: 3.8327\n",
      "[9/25][591/782] Loss_D: 0.0222 Loss_G: 5.1154\n",
      "[9/25][592/782] Loss_D: 0.3719 Loss_G: 7.3636\n",
      "[9/25][593/782] Loss_D: 1.7831 Loss_G: 4.0451\n",
      "[9/25][594/782] Loss_D: 0.8681 Loss_G: 0.0501\n",
      "[9/25][595/782] Loss_D: 2.1962 Loss_G: 8.3757\n",
      "[9/25][596/782] Loss_D: 2.4816 Loss_G: 1.9624\n",
      "[9/25][597/782] Loss_D: 1.5225 Loss_G: 2.8400\n",
      "[9/25][598/782] Loss_D: 0.7638 Loss_G: 2.4075\n",
      "[9/25][599/782] Loss_D: 0.5704 Loss_G: 2.3540\n",
      "[9/25][600/782] Loss_D: 0.5923 Loss_G: 2.5705\n",
      "[9/25][601/782] Loss_D: 0.5733 Loss_G: 3.2141\n",
      "[9/25][602/782] Loss_D: 0.9679 Loss_G: 1.1621\n",
      "[9/25][603/782] Loss_D: 0.9858 Loss_G: 4.0556\n",
      "[9/25][604/782] Loss_D: 0.4523 Loss_G: 3.5671\n",
      "[9/25][605/782] Loss_D: 0.3996 Loss_G: 2.4195\n",
      "[9/25][606/782] Loss_D: 0.4001 Loss_G: 4.0238\n",
      "[9/25][607/782] Loss_D: 0.6876 Loss_G: 2.7945\n",
      "[9/25][608/782] Loss_D: 0.2736 Loss_G: 3.5688\n",
      "[9/25][609/782] Loss_D: 0.4702 Loss_G: 4.3030\n",
      "[9/25][610/782] Loss_D: 0.9086 Loss_G: 1.4533\n",
      "[9/25][611/782] Loss_D: 1.9145 Loss_G: 6.4151\n",
      "[9/25][612/782] Loss_D: 1.7347 Loss_G: 1.6785\n",
      "[9/25][613/782] Loss_D: 0.4117 Loss_G: 2.7434\n",
      "[9/25][614/782] Loss_D: 0.8573 Loss_G: 4.8140\n",
      "[9/25][615/782] Loss_D: 1.0373 Loss_G: 1.8393\n",
      "[9/25][616/782] Loss_D: 0.5314 Loss_G: 3.4203\n",
      "[9/25][617/782] Loss_D: 0.1800 Loss_G: 4.3054\n",
      "[9/25][618/782] Loss_D: 0.5243 Loss_G: 3.2484\n",
      "[9/25][619/782] Loss_D: 0.1583 Loss_G: 3.9952\n",
      "[9/25][620/782] Loss_D: 0.0503 Loss_G: 4.0583\n",
      "[9/25][621/782] Loss_D: 0.9011 Loss_G: 6.1359\n",
      "[9/25][622/782] Loss_D: 0.9974 Loss_G: 3.8944\n",
      "[9/25][623/782] Loss_D: 0.7187 Loss_G: 4.0464\n",
      "[9/25][624/782] Loss_D: 0.2823 Loss_G: 5.2683\n",
      "[9/25][625/782] Loss_D: 0.0816 Loss_G: 3.5772\n",
      "[9/25][626/782] Loss_D: 1.2517 Loss_G: 7.0573\n",
      "[9/25][627/782] Loss_D: 2.5711 Loss_G: 2.8346\n",
      "[9/25][628/782] Loss_D: 0.1734 Loss_G: 1.4765\n",
      "[9/25][629/782] Loss_D: 2.5296 Loss_G: 7.2200\n",
      "[9/25][630/782] Loss_D: 2.2528 Loss_G: 4.1456\n",
      "[9/25][631/782] Loss_D: 0.4167 Loss_G: 1.2282\n",
      "[9/25][632/782] Loss_D: 0.7151 Loss_G: 3.5491\n",
      "[9/25][633/782] Loss_D: 0.5822 Loss_G: 4.4548\n",
      "[9/25][634/782] Loss_D: 0.7517 Loss_G: 2.4106\n",
      "[9/25][635/782] Loss_D: 0.5311 Loss_G: 2.6650\n",
      "[9/25][636/782] Loss_D: 0.4961 Loss_G: 2.4579\n",
      "[9/25][637/782] Loss_D: 0.3110 Loss_G: 2.4429\n",
      "[9/25][638/782] Loss_D: 0.4632 Loss_G: 3.9943\n",
      "[9/25][639/782] Loss_D: 0.3822 Loss_G: 4.1236\n",
      "[9/25][640/782] Loss_D: 0.6768 Loss_G: 2.3029\n",
      "[9/25][641/782] Loss_D: 0.5752 Loss_G: 4.7677\n",
      "[9/25][642/782] Loss_D: 0.4833 Loss_G: 2.9449\n",
      "[9/25][643/782] Loss_D: 0.3094 Loss_G: 3.1543\n",
      "[9/25][644/782] Loss_D: 0.2693 Loss_G: 3.5397\n",
      "[9/25][645/782] Loss_D: 0.3019 Loss_G: 2.7524\n",
      "[9/25][646/782] Loss_D: 0.8645 Loss_G: 6.9232\n",
      "[9/25][647/782] Loss_D: 1.3085 Loss_G: 2.5282\n",
      "[9/25][648/782] Loss_D: 0.4824 Loss_G: 4.8058\n",
      "[9/25][649/782] Loss_D: 0.2863 Loss_G: 4.5814\n",
      "[9/25][650/782] Loss_D: 0.4386 Loss_G: 3.8078\n",
      "[9/25][651/782] Loss_D: 0.2062 Loss_G: 3.8179\n",
      "[9/25][652/782] Loss_D: 0.3416 Loss_G: 3.3360\n",
      "[9/25][653/782] Loss_D: 0.4033 Loss_G: 3.4647\n",
      "[9/25][654/782] Loss_D: 0.2973 Loss_G: 3.9390\n",
      "[9/25][655/782] Loss_D: 0.2426 Loss_G: 5.5341\n",
      "[9/25][656/782] Loss_D: 0.5393 Loss_G: 3.4114\n",
      "[9/25][657/782] Loss_D: 0.3315 Loss_G: 7.5405\n",
      "[9/25][658/782] Loss_D: 2.8574 Loss_G: 0.3887\n",
      "[9/25][659/782] Loss_D: 1.4938 Loss_G: 5.8518\n",
      "[9/25][660/782] Loss_D: 1.7219 Loss_G: 1.1498\n",
      "[9/25][661/782] Loss_D: 1.0218 Loss_G: 3.9226\n",
      "[9/25][662/782] Loss_D: 0.3941 Loss_G: 3.3331\n",
      "[9/25][663/782] Loss_D: 0.5750 Loss_G: 2.4196\n",
      "[9/25][664/782] Loss_D: 0.2181 Loss_G: 2.9586\n",
      "[9/25][665/782] Loss_D: 0.6624 Loss_G: 4.4691\n",
      "[9/25][666/782] Loss_D: 0.6173 Loss_G: 2.7621\n",
      "[9/25][667/782] Loss_D: 0.2926 Loss_G: 2.3487\n",
      "[9/25][668/782] Loss_D: 0.7547 Loss_G: 4.5567\n",
      "[9/25][669/782] Loss_D: 0.2301 Loss_G: 4.8988\n",
      "[9/25][670/782] Loss_D: 0.5247 Loss_G: 1.9659\n",
      "[9/25][671/782] Loss_D: 0.8514 Loss_G: 5.3174\n",
      "[9/25][672/782] Loss_D: 1.5703 Loss_G: 1.1385\n",
      "[9/25][673/782] Loss_D: 1.1960 Loss_G: 6.3191\n",
      "[9/25][674/782] Loss_D: 1.8009 Loss_G: 2.5954\n",
      "[9/25][675/782] Loss_D: 0.9598 Loss_G: 3.3017\n",
      "[9/25][676/782] Loss_D: 0.3138 Loss_G: 3.5235\n",
      "[9/25][677/782] Loss_D: 0.2406 Loss_G: 3.9769\n",
      "[9/25][678/782] Loss_D: 0.3640 Loss_G: 3.2322\n",
      "[9/25][679/782] Loss_D: 0.0688 Loss_G: 4.9117\n",
      "[9/25][680/782] Loss_D: 0.2137 Loss_G: 3.5521\n",
      "[9/25][681/782] Loss_D: 0.2455 Loss_G: 3.3911\n",
      "[9/25][682/782] Loss_D: 0.5617 Loss_G: 5.1813\n",
      "[9/25][683/782] Loss_D: 0.3341 Loss_G: 4.4728\n",
      "[9/25][684/782] Loss_D: 0.2272 Loss_G: 2.4594\n",
      "[9/25][685/782] Loss_D: 0.2111 Loss_G: 4.1365\n",
      "[9/25][686/782] Loss_D: 0.1431 Loss_G: 5.0064\n",
      "[9/25][687/782] Loss_D: 0.2239 Loss_G: 3.3430\n",
      "[9/25][688/782] Loss_D: 0.2584 Loss_G: 4.6951\n",
      "[9/25][689/782] Loss_D: 0.0539 Loss_G: 5.2499\n",
      "[9/25][690/782] Loss_D: 0.1562 Loss_G: 3.2964\n",
      "[9/25][691/782] Loss_D: 0.1022 Loss_G: 4.3334\n",
      "[9/25][692/782] Loss_D: 0.0523 Loss_G: 4.4561\n",
      "[9/25][693/782] Loss_D: 0.0772 Loss_G: 4.5017\n",
      "[9/25][694/782] Loss_D: 0.0612 Loss_G: 4.8466\n",
      "[9/25][695/782] Loss_D: 0.0424 Loss_G: 4.5380\n",
      "[9/25][696/782] Loss_D: 0.1168 Loss_G: 3.8871\n",
      "[9/25][697/782] Loss_D: 0.0788 Loss_G: 4.4795\n",
      "[9/25][698/782] Loss_D: 0.0887 Loss_G: 5.7643\n",
      "[9/25][699/782] Loss_D: 0.1119 Loss_G: 4.2790\n",
      "[9/25][700/782] Loss_D: 0.0224 Loss_G: 5.5677\n",
      "[9/25][701/782] Loss_D: 0.2749 Loss_G: 6.0163\n",
      "[9/25][702/782] Loss_D: 0.3883 Loss_G: 5.4951\n",
      "[9/25][703/782] Loss_D: 0.1606 Loss_G: 3.4415\n",
      "[9/25][704/782] Loss_D: 0.2232 Loss_G: 4.2120\n",
      "[9/25][705/782] Loss_D: 0.4555 Loss_G: 3.0135\n",
      "[9/25][706/782] Loss_D: 0.4530 Loss_G: 9.4408\n",
      "[9/25][707/782] Loss_D: 3.5723 Loss_G: 3.8562\n",
      "[9/25][708/782] Loss_D: 0.3950 Loss_G: 4.7816\n",
      "[9/25][709/782] Loss_D: 1.2783 Loss_G: 0.8713\n",
      "[9/25][710/782] Loss_D: 1.9385 Loss_G: 6.5308\n",
      "[9/25][711/782] Loss_D: 2.4556 Loss_G: 1.5641\n",
      "[9/25][712/782] Loss_D: 0.7269 Loss_G: 1.9368\n",
      "[9/25][713/782] Loss_D: 0.6424 Loss_G: 4.1569\n",
      "[9/25][714/782] Loss_D: 0.5181 Loss_G: 3.4783\n",
      "[9/25][715/782] Loss_D: 0.6635 Loss_G: 1.6108\n",
      "[9/25][716/782] Loss_D: 0.7670 Loss_G: 2.6933\n",
      "[9/25][717/782] Loss_D: 1.0110 Loss_G: 1.8441\n",
      "[9/25][718/782] Loss_D: 0.8366 Loss_G: 2.4434\n",
      "[9/25][719/782] Loss_D: 0.6114 Loss_G: 2.9238\n",
      "[9/25][720/782] Loss_D: 0.9652 Loss_G: 1.1699\n",
      "[9/25][721/782] Loss_D: 1.4367 Loss_G: 4.4338\n",
      "[9/25][722/782] Loss_D: 0.8170 Loss_G: 3.0117\n",
      "[9/25][723/782] Loss_D: 0.5973 Loss_G: 1.4244\n",
      "[9/25][724/782] Loss_D: 0.8973 Loss_G: 2.4052\n",
      "[9/25][725/782] Loss_D: 0.4245 Loss_G: 3.8517\n",
      "[9/25][726/782] Loss_D: 0.6460 Loss_G: 1.8701\n",
      "[9/25][727/782] Loss_D: 0.8478 Loss_G: 3.6665\n",
      "[9/25][728/782] Loss_D: 1.0210 Loss_G: 1.4737\n",
      "[9/25][729/782] Loss_D: 0.5564 Loss_G: 3.0030\n",
      "[9/25][730/782] Loss_D: 0.3590 Loss_G: 2.5216\n",
      "[9/25][731/782] Loss_D: 0.5250 Loss_G: 3.6340\n",
      "[9/25][732/782] Loss_D: 0.3542 Loss_G: 2.9220\n",
      "[9/25][733/782] Loss_D: 0.2692 Loss_G: 3.5179\n",
      "[9/25][734/782] Loss_D: 0.2949 Loss_G: 4.1633\n",
      "[9/25][735/782] Loss_D: 0.1612 Loss_G: 3.6626\n",
      "[9/25][736/782] Loss_D: 0.1366 Loss_G: 4.3558\n",
      "[9/25][737/782] Loss_D: 0.2472 Loss_G: 2.2922\n",
      "[9/25][738/782] Loss_D: 0.8949 Loss_G: 8.6676\n",
      "[9/25][739/782] Loss_D: 4.9464 Loss_G: 1.4910\n",
      "[9/25][740/782] Loss_D: 0.8855 Loss_G: 3.3563\n",
      "[9/25][741/782] Loss_D: 0.6304 Loss_G: 1.6208\n",
      "[9/25][742/782] Loss_D: 0.8489 Loss_G: 4.6910\n",
      "[9/25][743/782] Loss_D: 0.4837 Loss_G: 2.7393\n",
      "[9/25][744/782] Loss_D: 0.3437 Loss_G: 5.8098\n",
      "[9/25][745/782] Loss_D: 0.2286 Loss_G: 3.6521\n",
      "[9/25][746/782] Loss_D: 0.1085 Loss_G: 3.9168\n",
      "[9/25][747/782] Loss_D: 0.2722 Loss_G: 5.7724\n",
      "[9/25][748/782] Loss_D: 0.4557 Loss_G: 2.4092\n",
      "[9/25][749/782] Loss_D: 0.5404 Loss_G: 6.3262\n",
      "[9/25][750/782] Loss_D: 0.6458 Loss_G: 2.1133\n",
      "[9/25][751/782] Loss_D: 0.4540 Loss_G: 5.7490\n",
      "[9/25][752/782] Loss_D: 0.3311 Loss_G: 2.5919\n",
      "[9/25][753/782] Loss_D: 0.4795 Loss_G: 6.4470\n",
      "[9/25][754/782] Loss_D: 0.4994 Loss_G: 3.2973\n",
      "[9/25][755/782] Loss_D: 0.2898 Loss_G: 6.0887\n",
      "[9/25][756/782] Loss_D: 0.8878 Loss_G: 1.1572\n",
      "[9/25][757/782] Loss_D: 2.0242 Loss_G: 9.6320\n",
      "[9/25][758/782] Loss_D: 6.3838 Loss_G: 3.8337\n",
      "[9/25][759/782] Loss_D: 1.5935 Loss_G: 0.1306\n",
      "[9/25][760/782] Loss_D: 2.7538 Loss_G: 2.4053\n",
      "[9/25][761/782] Loss_D: 0.7910 Loss_G: 3.0971\n",
      "[9/25][762/782] Loss_D: 0.9540 Loss_G: 1.0888\n",
      "[9/25][763/782] Loss_D: 0.8876 Loss_G: 1.5317\n",
      "[9/25][764/782] Loss_D: 0.9378 Loss_G: 2.8241\n",
      "[9/25][765/782] Loss_D: 1.2564 Loss_G: 1.2702\n",
      "[9/25][766/782] Loss_D: 0.8174 Loss_G: 2.1913\n",
      "[9/25][767/782] Loss_D: 0.4721 Loss_G: 2.9295\n",
      "[9/25][768/782] Loss_D: 0.6946 Loss_G: 1.9828\n",
      "[9/25][769/782] Loss_D: 0.5578 Loss_G: 1.8443\n",
      "[9/25][770/782] Loss_D: 1.0049 Loss_G: 1.7611\n",
      "[9/25][771/782] Loss_D: 0.5550 Loss_G: 2.9288\n",
      "[9/25][772/782] Loss_D: 0.8751 Loss_G: 1.7095\n",
      "[9/25][773/782] Loss_D: 0.8463 Loss_G: 1.6717\n",
      "[9/25][774/782] Loss_D: 0.7059 Loss_G: 1.8149\n",
      "[9/25][775/782] Loss_D: 0.6917 Loss_G: 2.2378\n",
      "[9/25][776/782] Loss_D: 0.6385 Loss_G: 2.6552\n",
      "[9/25][777/782] Loss_D: 1.0844 Loss_G: 1.1400\n",
      "[9/25][778/782] Loss_D: 0.7492 Loss_G: 1.7128\n",
      "[9/25][779/782] Loss_D: 0.7034 Loss_G: 2.8820\n",
      "[9/25][780/782] Loss_D: 0.7623 Loss_G: 2.0067\n",
      "[9/25][781/782] Loss_D: 0.5368 Loss_G: 2.5865\n",
      "[10/25][0/782] Loss_D: 0.4934 Loss_G: 2.5607\n",
      "[10/25][1/782] Loss_D: 0.7145 Loss_G: 2.2145\n",
      "[10/25][2/782] Loss_D: 0.4698 Loss_G: 2.4934\n",
      "[10/25][3/782] Loss_D: 0.4717 Loss_G: 2.4515\n",
      "[10/25][4/782] Loss_D: 0.5223 Loss_G: 2.2924\n",
      "[10/25][5/782] Loss_D: 0.9769 Loss_G: 2.3688\n",
      "[10/25][6/782] Loss_D: 1.1318 Loss_G: 1.2800\n",
      "[10/25][7/782] Loss_D: 0.7754 Loss_G: 2.9716\n",
      "[10/25][8/782] Loss_D: 1.0536 Loss_G: 1.6848\n",
      "[10/25][9/782] Loss_D: 0.7488 Loss_G: 2.1356\n",
      "[10/25][10/782] Loss_D: 0.6325 Loss_G: 2.3696\n",
      "[10/25][11/782] Loss_D: 0.6534 Loss_G: 2.0126\n",
      "[10/25][12/782] Loss_D: 0.6102 Loss_G: 2.5705\n",
      "[10/25][13/782] Loss_D: 0.5752 Loss_G: 2.6728\n",
      "[10/25][14/782] Loss_D: 0.6379 Loss_G: 1.8655\n",
      "[10/25][15/782] Loss_D: 0.7074 Loss_G: 3.1024\n",
      "[10/25][16/782] Loss_D: 0.7875 Loss_G: 1.6938\n",
      "[10/25][17/782] Loss_D: 0.5682 Loss_G: 2.6038\n",
      "[10/25][18/782] Loss_D: 0.5279 Loss_G: 2.3420\n",
      "[10/25][19/782] Loss_D: 0.4472 Loss_G: 2.4473\n",
      "[10/25][20/782] Loss_D: 0.3738 Loss_G: 2.4314\n",
      "[10/25][21/782] Loss_D: 0.6851 Loss_G: 3.2528\n",
      "[10/25][22/782] Loss_D: 0.5728 Loss_G: 2.4369\n",
      "[10/25][23/782] Loss_D: 0.3420 Loss_G: 2.6516\n",
      "[10/25][24/782] Loss_D: 0.3576 Loss_G: 2.7380\n",
      "[10/25][25/782] Loss_D: 0.4314 Loss_G: 2.4186\n",
      "[10/25][26/782] Loss_D: 0.3196 Loss_G: 2.9312\n",
      "[10/25][27/782] Loss_D: 0.2736 Loss_G: 3.3547\n",
      "[10/25][28/782] Loss_D: 0.4736 Loss_G: 2.0361\n",
      "[10/25][29/782] Loss_D: 0.3107 Loss_G: 3.6504\n",
      "[10/25][30/782] Loss_D: 0.4010 Loss_G: 2.3571\n",
      "[10/25][31/782] Loss_D: 0.5275 Loss_G: 5.1512\n",
      "[10/25][32/782] Loss_D: 0.1125 Loss_G: 5.4567\n",
      "[10/25][33/782] Loss_D: 0.2783 Loss_G: 3.4423\n",
      "[10/25][34/782] Loss_D: 0.1165 Loss_G: 3.2304\n",
      "[10/25][35/782] Loss_D: 0.1043 Loss_G: 3.9036\n",
      "[10/25][36/782] Loss_D: 0.0674 Loss_G: 4.4828\n",
      "[10/25][37/782] Loss_D: 0.0424 Loss_G: 4.4874\n",
      "[10/25][38/782] Loss_D: 0.0832 Loss_G: 4.2112\n",
      "[10/25][39/782] Loss_D: 0.0722 Loss_G: 4.2593\n",
      "[10/25][40/782] Loss_D: 0.0912 Loss_G: 3.8508\n",
      "[10/25][41/782] Loss_D: 0.0980 Loss_G: 3.9762\n",
      "[10/25][42/782] Loss_D: 0.0943 Loss_G: 3.8250\n",
      "[10/25][43/782] Loss_D: 0.1428 Loss_G: 4.1225\n",
      "[10/25][44/782] Loss_D: 0.0852 Loss_G: 4.3527\n",
      "[10/25][45/782] Loss_D: 0.0544 Loss_G: 4.2904\n",
      "[10/25][46/782] Loss_D: 0.0426 Loss_G: 4.3233\n",
      "[10/25][47/782] Loss_D: 0.1182 Loss_G: 3.7535\n",
      "[10/25][48/782] Loss_D: 0.0437 Loss_G: 4.0003\n",
      "[10/25][49/782] Loss_D: 0.0686 Loss_G: 4.0687\n",
      "[10/25][50/782] Loss_D: 0.0949 Loss_G: 4.4432\n",
      "[10/25][51/782] Loss_D: 0.0495 Loss_G: 4.9263\n",
      "[10/25][52/782] Loss_D: 0.0689 Loss_G: 4.7552\n",
      "[10/25][53/782] Loss_D: 0.0597 Loss_G: 3.9176\n",
      "[10/25][54/782] Loss_D: 0.0878 Loss_G: 4.0387\n",
      "[10/25][55/782] Loss_D: 0.0434 Loss_G: 5.7368\n",
      "[10/25][56/782] Loss_D: 0.1443 Loss_G: 4.8487\n",
      "[10/25][57/782] Loss_D: 0.0597 Loss_G: 6.0369\n",
      "[10/25][58/782] Loss_D: 0.0458 Loss_G: 5.0003\n",
      "[10/25][59/782] Loss_D: 0.0845 Loss_G: 4.1118\n",
      "[10/25][60/782] Loss_D: 0.0275 Loss_G: 4.3906\n",
      "[10/25][61/782] Loss_D: 0.0534 Loss_G: 4.2962\n",
      "[10/25][62/782] Loss_D: 0.1082 Loss_G: 5.2232\n",
      "[10/25][63/782] Loss_D: 0.0645 Loss_G: 5.0379\n",
      "[10/25][64/782] Loss_D: 0.0372 Loss_G: 5.9615\n",
      "[10/25][65/782] Loss_D: 0.0886 Loss_G: 4.6914\n",
      "[10/25][66/782] Loss_D: 0.0533 Loss_G: 3.8624\n",
      "[10/25][67/782] Loss_D: 0.0230 Loss_G: 4.7103\n",
      "[10/25][68/782] Loss_D: 0.0585 Loss_G: 4.3771\n",
      "[10/25][69/782] Loss_D: 0.0339 Loss_G: 4.6813\n",
      "[10/25][70/782] Loss_D: 0.0821 Loss_G: 5.0966\n",
      "[10/25][71/782] Loss_D: 0.0464 Loss_G: 5.2348\n",
      "[10/25][72/782] Loss_D: 0.0604 Loss_G: 4.6027\n",
      "[10/25][73/782] Loss_D: 0.0256 Loss_G: 5.2018\n",
      "[10/25][74/782] Loss_D: 0.0394 Loss_G: 4.6345\n",
      "[10/25][75/782] Loss_D: 0.0397 Loss_G: 4.4971\n",
      "[10/25][76/782] Loss_D: 0.0787 Loss_G: 4.9028\n",
      "[10/25][77/782] Loss_D: 0.0171 Loss_G: 6.2735\n",
      "[10/25][78/782] Loss_D: 0.0474 Loss_G: 4.4880\n",
      "[10/25][79/782] Loss_D: 0.0228 Loss_G: 6.8341\n",
      "[10/25][80/782] Loss_D: 0.0453 Loss_G: 4.3993\n",
      "[10/25][81/782] Loss_D: 0.0215 Loss_G: 6.3927\n",
      "[10/25][82/782] Loss_D: 0.0272 Loss_G: 4.6660\n",
      "[10/25][83/782] Loss_D: 0.0204 Loss_G: 5.1985\n",
      "[10/25][84/782] Loss_D: 0.1008 Loss_G: 4.1540\n",
      "[10/25][85/782] Loss_D: 0.0106 Loss_G: 5.8010\n",
      "[10/25][86/782] Loss_D: 0.0245 Loss_G: 5.2486\n",
      "[10/25][87/782] Loss_D: 0.0543 Loss_G: 4.2383\n",
      "[10/25][88/782] Loss_D: 0.0439 Loss_G: 4.5001\n",
      "[10/25][89/782] Loss_D: 0.0328 Loss_G: 4.6984\n",
      "[10/25][90/782] Loss_D: 0.0295 Loss_G: 4.9872\n",
      "[10/25][91/782] Loss_D: 0.0440 Loss_G: 5.0631\n",
      "[10/25][92/782] Loss_D: 0.0285 Loss_G: 4.7117\n",
      "[10/25][93/782] Loss_D: 0.0231 Loss_G: 4.7535\n",
      "[10/25][94/782] Loss_D: 0.0169 Loss_G: 5.5356\n",
      "[10/25][95/782] Loss_D: 0.1351 Loss_G: 5.2232\n",
      "[10/25][96/782] Loss_D: 0.0465 Loss_G: 5.7058\n",
      "[10/25][97/782] Loss_D: 0.1070 Loss_G: 4.0627\n",
      "[10/25][98/782] Loss_D: 0.0192 Loss_G: 4.5652\n",
      "[10/25][99/782] Loss_D: 0.0255 Loss_G: 4.4590\n",
      "[10/25][100/782] Loss_D: 0.0621 Loss_G: 4.7519\n",
      "[10/25][101/782] Loss_D: 0.0204 Loss_G: 5.5267\n",
      "[10/25][102/782] Loss_D: 0.0417 Loss_G: 5.0997\n",
      "[10/25][103/782] Loss_D: 0.0433 Loss_G: 6.2745\n",
      "[10/25][104/782] Loss_D: 0.0545 Loss_G: 4.7562\n",
      "[10/25][105/782] Loss_D: 0.0442 Loss_G: 4.1783\n",
      "[10/25][106/782] Loss_D: 0.0300 Loss_G: 4.7911\n",
      "[10/25][107/782] Loss_D: 0.0173 Loss_G: 5.5121\n",
      "[10/25][108/782] Loss_D: 0.0252 Loss_G: 4.9693\n",
      "[10/25][109/782] Loss_D: 0.0239 Loss_G: 5.1054\n",
      "[10/25][110/782] Loss_D: 0.0073 Loss_G: 6.3399\n",
      "[10/25][111/782] Loss_D: 0.1100 Loss_G: 5.0645\n",
      "[10/25][112/782] Loss_D: 0.0364 Loss_G: 6.7684\n",
      "[10/25][113/782] Loss_D: 0.1922 Loss_G: 2.4508\n",
      "[10/25][114/782] Loss_D: 0.0229 Loss_G: 4.2863\n",
      "[10/25][115/782] Loss_D: 0.0153 Loss_G: 4.7347\n",
      "[10/25][116/782] Loss_D: 0.4912 Loss_G: 12.0602\n",
      "[10/25][117/782] Loss_D: 7.8117 Loss_G: 5.0173\n",
      "[10/25][118/782] Loss_D: 1.1669 Loss_G: 0.0725\n",
      "[10/25][119/782] Loss_D: 3.9293 Loss_G: 7.2590\n",
      "[10/25][120/782] Loss_D: 2.5245 Loss_G: 1.5325\n",
      "[10/25][121/782] Loss_D: 0.6795 Loss_G: 1.4000\n",
      "[10/25][122/782] Loss_D: 0.8605 Loss_G: 4.4008\n",
      "[10/25][123/782] Loss_D: 0.5714 Loss_G: 3.6543\n",
      "[10/25][124/782] Loss_D: 0.4236 Loss_G: 2.1152\n",
      "[10/25][125/782] Loss_D: 0.4170 Loss_G: 2.5996\n",
      "[10/25][126/782] Loss_D: 0.2857 Loss_G: 3.2056\n",
      "[10/25][127/782] Loss_D: 0.6653 Loss_G: 2.5121\n",
      "[10/25][128/782] Loss_D: 0.4511 Loss_G: 2.6203\n",
      "[10/25][129/782] Loss_D: 0.4355 Loss_G: 2.5185\n",
      "[10/25][130/782] Loss_D: 0.3426 Loss_G: 2.7121\n",
      "[10/25][131/782] Loss_D: 0.4252 Loss_G: 3.2190\n",
      "[10/25][132/782] Loss_D: 0.5193 Loss_G: 2.7910\n",
      "[10/25][133/782] Loss_D: 0.5883 Loss_G: 2.6762\n",
      "[10/25][134/782] Loss_D: 0.3580 Loss_G: 3.2241\n",
      "[10/25][135/782] Loss_D: 0.6097 Loss_G: 1.6954\n",
      "[10/25][136/782] Loss_D: 0.8470 Loss_G: 4.1072\n",
      "[10/25][137/782] Loss_D: 0.4981 Loss_G: 3.3811\n",
      "[10/25][138/782] Loss_D: 0.6963 Loss_G: 2.0089\n",
      "[10/25][139/782] Loss_D: 0.4789 Loss_G: 3.0345\n",
      "[10/25][140/782] Loss_D: 0.7338 Loss_G: 2.4538\n",
      "[10/25][141/782] Loss_D: 0.6835 Loss_G: 3.4134\n",
      "[10/25][142/782] Loss_D: 0.5187 Loss_G: 3.3302\n",
      "[10/25][143/782] Loss_D: 0.7654 Loss_G: 1.1204\n",
      "[10/25][144/782] Loss_D: 0.8503 Loss_G: 4.9172\n",
      "[10/25][145/782] Loss_D: 0.6686 Loss_G: 3.0931\n",
      "[10/25][146/782] Loss_D: 0.2315 Loss_G: 2.6097\n",
      "[10/25][147/782] Loss_D: 0.5187 Loss_G: 3.8297\n",
      "[10/25][148/782] Loss_D: 0.3655 Loss_G: 3.2173\n",
      "[10/25][149/782] Loss_D: 0.3138 Loss_G: 2.8584\n",
      "[10/25][150/782] Loss_D: 0.5230 Loss_G: 3.5116\n",
      "[10/25][151/782] Loss_D: 0.1866 Loss_G: 4.0664\n",
      "[10/25][152/782] Loss_D: 0.1905 Loss_G: 3.1175\n",
      "[10/25][153/782] Loss_D: 0.4015 Loss_G: 2.6588\n",
      "[10/25][154/782] Loss_D: 0.4106 Loss_G: 3.2235\n",
      "[10/25][155/782] Loss_D: 0.3107 Loss_G: 3.3597\n",
      "[10/25][156/782] Loss_D: 0.4759 Loss_G: 2.1062\n",
      "[10/25][157/782] Loss_D: 0.6555 Loss_G: 3.7937\n",
      "[10/25][158/782] Loss_D: 0.4413 Loss_G: 2.8819\n",
      "[10/25][159/782] Loss_D: 0.2626 Loss_G: 2.6689\n",
      "[10/25][160/782] Loss_D: 0.4335 Loss_G: 3.0376\n",
      "[10/25][161/782] Loss_D: 0.2392 Loss_G: 3.5592\n",
      "[10/25][162/782] Loss_D: 0.1988 Loss_G: 3.1828\n",
      "[10/25][163/782] Loss_D: 0.4237 Loss_G: 4.2375\n",
      "[10/25][164/782] Loss_D: 0.1968 Loss_G: 4.5638\n",
      "[10/25][165/782] Loss_D: 0.1626 Loss_G: 3.1186\n",
      "[10/25][166/782] Loss_D: 0.2362 Loss_G: 3.1584\n",
      "[10/25][167/782] Loss_D: 0.1752 Loss_G: 4.0305\n",
      "[10/25][168/782] Loss_D: 0.2456 Loss_G: 3.4667\n",
      "[10/25][169/782] Loss_D: 0.0510 Loss_G: 4.0497\n",
      "[10/25][170/782] Loss_D: 0.5838 Loss_G: 6.3383\n",
      "[10/25][171/782] Loss_D: 0.9767 Loss_G: 1.5519\n",
      "[10/25][172/782] Loss_D: 0.2978 Loss_G: 3.7523\n",
      "[10/25][173/782] Loss_D: 0.1871 Loss_G: 5.1652\n",
      "[10/25][174/782] Loss_D: 0.2557 Loss_G: 4.1775\n",
      "[10/25][175/782] Loss_D: 0.2706 Loss_G: 3.0650\n",
      "[10/25][176/782] Loss_D: 0.0889 Loss_G: 3.9044\n",
      "[10/25][177/782] Loss_D: 0.6838 Loss_G: 8.9312\n",
      "[10/25][178/782] Loss_D: 3.9245 Loss_G: 3.2514\n",
      "[10/25][179/782] Loss_D: 0.4971 Loss_G: 2.5901\n",
      "[10/25][180/782] Loss_D: 0.4077 Loss_G: 3.8031\n",
      "[10/25][181/782] Loss_D: 0.2292 Loss_G: 3.8670\n",
      "[10/25][182/782] Loss_D: 0.2024 Loss_G: 4.2234\n",
      "[10/25][183/782] Loss_D: 0.3718 Loss_G: 2.3809\n",
      "[10/25][184/782] Loss_D: 0.5387 Loss_G: 5.4415\n",
      "[10/25][185/782] Loss_D: 0.5167 Loss_G: 2.4799\n",
      "[10/25][186/782] Loss_D: 0.3995 Loss_G: 5.1978\n",
      "[10/25][187/782] Loss_D: 0.4817 Loss_G: 3.0704\n",
      "[10/25][188/782] Loss_D: 0.4375 Loss_G: 5.4717\n",
      "[10/25][189/782] Loss_D: 0.5020 Loss_G: 2.2770\n",
      "[10/25][190/782] Loss_D: 0.2860 Loss_G: 4.5057\n",
      "[10/25][191/782] Loss_D: 0.1233 Loss_G: 4.7778\n",
      "[10/25][192/782] Loss_D: 0.1268 Loss_G: 4.1157\n",
      "[10/25][193/782] Loss_D: 0.0866 Loss_G: 4.3222\n",
      "[10/25][194/782] Loss_D: 0.0739 Loss_G: 4.3549\n",
      "[10/25][195/782] Loss_D: 0.1129 Loss_G: 4.1089\n",
      "[10/25][196/782] Loss_D: 0.1506 Loss_G: 4.4959\n",
      "[10/25][197/782] Loss_D: 0.3293 Loss_G: 2.3136\n",
      "[10/25][198/782] Loss_D: 0.3221 Loss_G: 6.4957\n",
      "[10/25][199/782] Loss_D: 0.2048 Loss_G: 4.3718\n",
      "[10/25][200/782] Loss_D: 0.0507 Loss_G: 4.5629\n",
      "[10/25][201/782] Loss_D: 0.1219 Loss_G: 3.9644\n",
      "[10/25][202/782] Loss_D: 0.0969 Loss_G: 4.0982\n",
      "[10/25][203/782] Loss_D: 0.0669 Loss_G: 4.1818\n",
      "[10/25][204/782] Loss_D: 0.1207 Loss_G: 5.6437\n",
      "[10/25][205/782] Loss_D: 0.1608 Loss_G: 3.8277\n",
      "[10/25][206/782] Loss_D: 0.1612 Loss_G: 5.9172\n",
      "[10/25][207/782] Loss_D: 0.1643 Loss_G: 3.7570\n",
      "[10/25][208/782] Loss_D: 0.0573 Loss_G: 4.3839\n",
      "[10/25][209/782] Loss_D: 0.0927 Loss_G: 5.2002\n",
      "[10/25][210/782] Loss_D: 0.0375 Loss_G: 5.5542\n",
      "[10/25][211/782] Loss_D: 0.0625 Loss_G: 4.4958\n",
      "[10/25][212/782] Loss_D: 0.0319 Loss_G: 4.6150\n",
      "[10/25][213/782] Loss_D: 0.0718 Loss_G: 4.4549\n",
      "[10/25][214/782] Loss_D: 0.0282 Loss_G: 5.1619\n",
      "[10/25][215/782] Loss_D: 0.0173 Loss_G: 5.6297\n",
      "[10/25][216/782] Loss_D: 0.0334 Loss_G: 4.7928\n",
      "[10/25][217/782] Loss_D: 0.0339 Loss_G: 4.6731\n",
      "[10/25][218/782] Loss_D: 0.0370 Loss_G: 5.0671\n",
      "[10/25][219/782] Loss_D: 0.0270 Loss_G: 4.9802\n",
      "[10/25][220/782] Loss_D: 0.0317 Loss_G: 5.0151\n",
      "[10/25][221/782] Loss_D: 0.0571 Loss_G: 4.8206\n",
      "[10/25][222/782] Loss_D: 0.0767 Loss_G: 4.4958\n",
      "[10/25][223/782] Loss_D: 0.0568 Loss_G: 4.4509\n",
      "[10/25][224/782] Loss_D: 0.0151 Loss_G: 5.6088\n",
      "[10/25][225/782] Loss_D: 0.0509 Loss_G: 4.6322\n",
      "[10/25][226/782] Loss_D: 0.0375 Loss_G: 5.0419\n",
      "[10/25][227/782] Loss_D: 0.0623 Loss_G: 4.8752\n",
      "[10/25][228/782] Loss_D: 0.0600 Loss_G: 4.2018\n",
      "[10/25][229/782] Loss_D: 0.0719 Loss_G: 5.0592\n",
      "[10/25][230/782] Loss_D: 0.0598 Loss_G: 5.3367\n",
      "[10/25][231/782] Loss_D: 0.0702 Loss_G: 4.2459\n",
      "[10/25][232/782] Loss_D: 0.0238 Loss_G: 4.8736\n",
      "[10/25][233/782] Loss_D: 0.1556 Loss_G: 7.1244\n",
      "[10/25][234/782] Loss_D: 0.2169 Loss_G: 5.4293\n",
      "[10/25][235/782] Loss_D: 0.0480 Loss_G: 4.9714\n",
      "[10/25][236/782] Loss_D: 0.0217 Loss_G: 6.0928\n",
      "[10/25][237/782] Loss_D: 0.1255 Loss_G: 5.6310\n",
      "[10/25][238/782] Loss_D: 0.2757 Loss_G: 6.1955\n",
      "[10/25][239/782] Loss_D: 0.0840 Loss_G: 3.4434\n",
      "[10/25][240/782] Loss_D: 0.0155 Loss_G: 5.1574\n",
      "[10/25][241/782] Loss_D: 2.0462 Loss_G: 12.2502\n",
      "[10/25][242/782] Loss_D: 9.5278 Loss_G: 4.4916\n",
      "[10/25][243/782] Loss_D: 2.4493 Loss_G: 0.0108\n",
      "[10/25][244/782] Loss_D: 5.2151 Loss_G: 1.1308\n",
      "[10/25][245/782] Loss_D: 1.6893 Loss_G: 6.6723\n",
      "[10/25][246/782] Loss_D: 3.5831 Loss_G: 3.1175\n",
      "[10/25][247/782] Loss_D: 0.6585 Loss_G: 1.0305\n",
      "[10/25][248/782] Loss_D: 1.4869 Loss_G: 2.4977\n",
      "[10/25][249/782] Loss_D: 0.7782 Loss_G: 3.8550\n",
      "[10/25][250/782] Loss_D: 1.4374 Loss_G: 1.4309\n",
      "[10/25][251/782] Loss_D: 0.9744 Loss_G: 2.9179\n",
      "[10/25][252/782] Loss_D: 0.6901 Loss_G: 2.6191\n",
      "[10/25][253/782] Loss_D: 0.9057 Loss_G: 2.1644\n",
      "[10/25][254/782] Loss_D: 0.7600 Loss_G: 1.9635\n",
      "[10/25][255/782] Loss_D: 0.7161 Loss_G: 2.5292\n",
      "[10/25][256/782] Loss_D: 0.8973 Loss_G: 1.8989\n",
      "[10/25][257/782] Loss_D: 0.9074 Loss_G: 2.5844\n",
      "[10/25][258/782] Loss_D: 0.6505 Loss_G: 2.4709\n",
      "[10/25][259/782] Loss_D: 0.7635 Loss_G: 1.6053\n",
      "[10/25][260/782] Loss_D: 1.1104 Loss_G: 3.0891\n",
      "[10/25][261/782] Loss_D: 1.0760 Loss_G: 1.2987\n",
      "[10/25][262/782] Loss_D: 1.3063 Loss_G: 2.0203\n",
      "[10/25][263/782] Loss_D: 0.8198 Loss_G: 1.9678\n",
      "[10/25][264/782] Loss_D: 1.0234 Loss_G: 2.6796\n",
      "[10/25][265/782] Loss_D: 1.2139 Loss_G: 1.9350\n",
      "[10/25][266/782] Loss_D: 1.0536 Loss_G: 2.7164\n",
      "[10/25][267/782] Loss_D: 0.5848 Loss_G: 2.4666\n",
      "[10/25][268/782] Loss_D: 0.8395 Loss_G: 1.7632\n",
      "[10/25][269/782] Loss_D: 0.7568 Loss_G: 2.9856\n",
      "[10/25][270/782] Loss_D: 0.6706 Loss_G: 2.2448\n",
      "[10/25][271/782] Loss_D: 0.8572 Loss_G: 2.6501\n",
      "[10/25][272/782] Loss_D: 0.8620 Loss_G: 1.2617\n",
      "[10/25][273/782] Loss_D: 0.8205 Loss_G: 3.8680\n",
      "[10/25][274/782] Loss_D: 0.8443 Loss_G: 1.2058\n",
      "[10/25][275/782] Loss_D: 0.9126 Loss_G: 3.4824\n",
      "[10/25][276/782] Loss_D: 0.6097 Loss_G: 2.7686\n",
      "[10/25][277/782] Loss_D: 0.9007 Loss_G: 0.7320\n",
      "[10/25][278/782] Loss_D: 1.3042 Loss_G: 4.3003\n",
      "[10/25][279/782] Loss_D: 0.8776 Loss_G: 1.4596\n",
      "[10/25][280/782] Loss_D: 1.4419 Loss_G: 4.5817\n",
      "[10/25][281/782] Loss_D: 1.9518 Loss_G: 0.6894\n",
      "[10/25][282/782] Loss_D: 1.9270 Loss_G: 4.0861\n",
      "[10/25][283/782] Loss_D: 0.8447 Loss_G: 2.5603\n",
      "[10/25][284/782] Loss_D: 0.8748 Loss_G: 1.6496\n",
      "[10/25][285/782] Loss_D: 0.5680 Loss_G: 2.7846\n",
      "[10/25][286/782] Loss_D: 0.8427 Loss_G: 3.7445\n",
      "[10/25][287/782] Loss_D: 0.8539 Loss_G: 2.2733\n",
      "[10/25][288/782] Loss_D: 1.0260 Loss_G: 1.7785\n",
      "[10/25][289/782] Loss_D: 0.7857 Loss_G: 2.4038\n",
      "[10/25][290/782] Loss_D: 0.8029 Loss_G: 2.8485\n",
      "[10/25][291/782] Loss_D: 0.5486 Loss_G: 2.5440\n",
      "[10/25][292/782] Loss_D: 0.6369 Loss_G: 2.6204\n",
      "[10/25][293/782] Loss_D: 0.3717 Loss_G: 2.9599\n",
      "[10/25][294/782] Loss_D: 0.3522 Loss_G: 3.0831\n",
      "[10/25][295/782] Loss_D: 0.5863 Loss_G: 3.3226\n",
      "[10/25][296/782] Loss_D: 0.6341 Loss_G: 2.1296\n",
      "[10/25][297/782] Loss_D: 0.8226 Loss_G: 4.7414\n",
      "[10/25][298/782] Loss_D: 0.7696 Loss_G: 2.5593\n",
      "[10/25][299/782] Loss_D: 0.5842 Loss_G: 3.0653\n",
      "[10/25][300/782] Loss_D: 0.4668 Loss_G: 4.0909\n",
      "[10/25][301/782] Loss_D: 0.5664 Loss_G: 1.9467\n",
      "[10/25][302/782] Loss_D: 0.4806 Loss_G: 3.4844\n",
      "[10/25][303/782] Loss_D: 0.3648 Loss_G: 3.0085\n",
      "[10/25][304/782] Loss_D: 0.3748 Loss_G: 3.8708\n",
      "[10/25][305/782] Loss_D: 0.3564 Loss_G: 3.4153\n",
      "[10/25][306/782] Loss_D: 0.7063 Loss_G: 3.3876\n",
      "[10/25][307/782] Loss_D: 0.6011 Loss_G: 2.2518\n",
      "[10/25][308/782] Loss_D: 0.7510 Loss_G: 3.7709\n",
      "[10/25][309/782] Loss_D: 0.3640 Loss_G: 3.5188\n",
      "[10/25][310/782] Loss_D: 0.2579 Loss_G: 2.4736\n",
      "[10/25][311/782] Loss_D: 0.5592 Loss_G: 4.2133\n",
      "[10/25][312/782] Loss_D: 0.3686 Loss_G: 3.6683\n",
      "[10/25][313/782] Loss_D: 0.3961 Loss_G: 2.2928\n",
      "[10/25][314/782] Loss_D: 0.4101 Loss_G: 4.6704\n",
      "[10/25][315/782] Loss_D: 0.3736 Loss_G: 3.1670\n",
      "[10/25][316/782] Loss_D: 0.1548 Loss_G: 3.4824\n",
      "[10/25][317/782] Loss_D: 0.1418 Loss_G: 3.6200\n",
      "[10/25][318/782] Loss_D: 0.1964 Loss_G: 3.9798\n",
      "[10/25][319/782] Loss_D: 0.1347 Loss_G: 3.9226\n",
      "[10/25][320/782] Loss_D: 0.1264 Loss_G: 3.7967\n",
      "[10/25][321/782] Loss_D: 0.0877 Loss_G: 3.6466\n",
      "[10/25][322/782] Loss_D: 0.1704 Loss_G: 4.2648\n",
      "[10/25][323/782] Loss_D: 0.1832 Loss_G: 3.5342\n",
      "[10/25][324/782] Loss_D: 0.0919 Loss_G: 3.6161\n",
      "[10/25][325/782] Loss_D: 0.1542 Loss_G: 4.5126\n",
      "[10/25][326/782] Loss_D: 0.1101 Loss_G: 4.4637\n",
      "[10/25][327/782] Loss_D: 0.1078 Loss_G: 3.4855\n",
      "[10/25][328/782] Loss_D: 0.0974 Loss_G: 4.0120\n",
      "[10/25][329/782] Loss_D: 0.0816 Loss_G: 4.2320\n",
      "[10/25][330/782] Loss_D: 0.0860 Loss_G: 4.4580\n",
      "[10/25][331/782] Loss_D: 0.0828 Loss_G: 4.3463\n",
      "[10/25][332/782] Loss_D: 0.0422 Loss_G: 4.0609\n",
      "[10/25][333/782] Loss_D: 0.0870 Loss_G: 3.7701\n",
      "[10/25][334/782] Loss_D: 0.1055 Loss_G: 3.8461\n",
      "[10/25][335/782] Loss_D: 0.0736 Loss_G: 4.4329\n",
      "[10/25][336/782] Loss_D: 0.0523 Loss_G: 4.5404\n",
      "[10/25][337/782] Loss_D: 0.1006 Loss_G: 4.5429\n",
      "[10/25][338/782] Loss_D: 0.1095 Loss_G: 3.9838\n",
      "[10/25][339/782] Loss_D: 0.1405 Loss_G: 4.6817\n",
      "[10/25][340/782] Loss_D: 0.0446 Loss_G: 5.2808\n",
      "[10/25][341/782] Loss_D: 0.0690 Loss_G: 4.6605\n",
      "[10/25][342/782] Loss_D: 0.0568 Loss_G: 4.9543\n",
      "[10/25][343/782] Loss_D: 0.0586 Loss_G: 4.2394\n",
      "[10/25][344/782] Loss_D: 0.0713 Loss_G: 4.8021\n",
      "[10/25][345/782] Loss_D: 0.0344 Loss_G: 5.0738\n",
      "[10/25][346/782] Loss_D: 0.0631 Loss_G: 4.5789\n",
      "[10/25][347/782] Loss_D: 0.0191 Loss_G: 5.3742\n",
      "[10/25][348/782] Loss_D: 0.0502 Loss_G: 4.4323\n",
      "[10/25][349/782] Loss_D: 0.0514 Loss_G: 5.4838\n",
      "[10/25][350/782] Loss_D: 0.0506 Loss_G: 4.2993\n",
      "[10/25][351/782] Loss_D: 0.0380 Loss_G: 4.8858\n",
      "[10/25][352/782] Loss_D: 0.0265 Loss_G: 4.9862\n",
      "[10/25][353/782] Loss_D: 0.0360 Loss_G: 4.6922\n",
      "[10/25][354/782] Loss_D: 0.0349 Loss_G: 4.8375\n",
      "[10/25][355/782] Loss_D: 0.0540 Loss_G: 4.5072\n",
      "[10/25][356/782] Loss_D: 0.0357 Loss_G: 4.9656\n",
      "[10/25][357/782] Loss_D: 0.0507 Loss_G: 4.3388\n",
      "[10/25][358/782] Loss_D: 0.0061 Loss_G: 6.1778\n",
      "[10/25][359/782] Loss_D: 0.1243 Loss_G: 5.0715\n",
      "[10/25][360/782] Loss_D: 0.1487 Loss_G: 5.5336\n",
      "[10/25][361/782] Loss_D: 0.1615 Loss_G: 6.1485\n",
      "[10/25][362/782] Loss_D: 0.6439 Loss_G: 6.0818\n",
      "[10/25][363/782] Loss_D: 3.5592 Loss_G: 0.0759\n",
      "[10/25][364/782] Loss_D: 2.6284 Loss_G: 4.9908\n",
      "[10/25][365/782] Loss_D: 1.9615 Loss_G: 0.6640\n",
      "[10/25][366/782] Loss_D: 1.0514 Loss_G: 3.0750\n",
      "[10/25][367/782] Loss_D: 0.6454 Loss_G: 2.3172\n",
      "[10/25][368/782] Loss_D: 0.6522 Loss_G: 2.6881\n",
      "[10/25][369/782] Loss_D: 0.6893 Loss_G: 2.5779\n",
      "[10/25][370/782] Loss_D: 0.5078 Loss_G: 2.4145\n",
      "[10/25][371/782] Loss_D: 0.7253 Loss_G: 2.9398\n",
      "[10/25][372/782] Loss_D: 0.6848 Loss_G: 2.1249\n",
      "[10/25][373/782] Loss_D: 0.7150 Loss_G: 4.5368\n",
      "[10/25][374/782] Loss_D: 1.1297 Loss_G: 0.6419\n",
      "[10/25][375/782] Loss_D: 1.7670 Loss_G: 6.7907\n",
      "[10/25][376/782] Loss_D: 2.3073 Loss_G: 1.8508\n",
      "[10/25][377/782] Loss_D: 0.5922 Loss_G: 1.2535\n",
      "[10/25][378/782] Loss_D: 0.8886 Loss_G: 4.1132\n",
      "[10/25][379/782] Loss_D: 0.3747 Loss_G: 4.3458\n",
      "[10/25][380/782] Loss_D: 0.9342 Loss_G: 1.8816\n",
      "[10/25][381/782] Loss_D: 0.5223 Loss_G: 2.5684\n",
      "[10/25][382/782] Loss_D: 0.6634 Loss_G: 3.0393\n",
      "[10/25][383/782] Loss_D: 0.7554 Loss_G: 2.3237\n",
      "[10/25][384/782] Loss_D: 0.5342 Loss_G: 2.8017\n",
      "[10/25][385/782] Loss_D: 0.6599 Loss_G: 2.2537\n",
      "[10/25][386/782] Loss_D: 0.6180 Loss_G: 2.2585\n",
      "[10/25][387/782] Loss_D: 0.4812 Loss_G: 3.6946\n",
      "[10/25][388/782] Loss_D: 0.7428 Loss_G: 2.1338\n",
      "[10/25][389/782] Loss_D: 0.6632 Loss_G: 4.3470\n",
      "[10/25][390/782] Loss_D: 0.6120 Loss_G: 2.0997\n",
      "[10/25][391/782] Loss_D: 0.6088 Loss_G: 4.4013\n",
      "[10/25][392/782] Loss_D: 0.4670 Loss_G: 3.0145\n",
      "[10/25][393/782] Loss_D: 0.5419 Loss_G: 1.7004\n",
      "[10/25][394/782] Loss_D: 0.5885 Loss_G: 4.3276\n",
      "[10/25][395/782] Loss_D: 0.6174 Loss_G: 2.1999\n",
      "[10/25][396/782] Loss_D: 0.8209 Loss_G: 2.5207\n",
      "[10/25][397/782] Loss_D: 0.7879 Loss_G: 4.0764\n",
      "[10/25][398/782] Loss_D: 0.8257 Loss_G: 1.3820\n",
      "[10/25][399/782] Loss_D: 0.6598 Loss_G: 3.9011\n",
      "[10/25][400/782] Loss_D: 0.5086 Loss_G: 2.7814\n",
      "[10/25][401/782] Loss_D: 0.5187 Loss_G: 2.4593\n",
      "[10/25][402/782] Loss_D: 0.5093 Loss_G: 2.6795\n",
      "[10/25][403/782] Loss_D: 0.5058 Loss_G: 4.0878\n",
      "[10/25][404/782] Loss_D: 0.4275 Loss_G: 2.3720\n",
      "[10/25][405/782] Loss_D: 0.4558 Loss_G: 2.5800\n",
      "[10/25][406/782] Loss_D: 0.3606 Loss_G: 3.9533\n",
      "[10/25][407/782] Loss_D: 0.7345 Loss_G: 0.9579\n",
      "[10/25][408/782] Loss_D: 0.9516 Loss_G: 4.9571\n",
      "[10/25][409/782] Loss_D: 0.6659 Loss_G: 2.2163\n",
      "[10/25][410/782] Loss_D: 0.3296 Loss_G: 2.4349\n",
      "[10/25][411/782] Loss_D: 0.6330 Loss_G: 3.7140\n",
      "[10/25][412/782] Loss_D: 0.6468 Loss_G: 1.8696\n",
      "[10/25][413/782] Loss_D: 0.6002 Loss_G: 3.3066\n",
      "[10/25][414/782] Loss_D: 0.4828 Loss_G: 3.0641\n",
      "[10/25][415/782] Loss_D: 0.4243 Loss_G: 1.8691\n",
      "[10/25][416/782] Loss_D: 0.6276 Loss_G: 3.6140\n",
      "[10/25][417/782] Loss_D: 0.5607 Loss_G: 1.8889\n",
      "[10/25][418/782] Loss_D: 0.6492 Loss_G: 4.3489\n",
      "[10/25][419/782] Loss_D: 0.4605 Loss_G: 2.5987\n",
      "[10/25][420/782] Loss_D: 0.3861 Loss_G: 2.3241\n",
      "[10/25][421/782] Loss_D: 0.4408 Loss_G: 3.1567\n",
      "[10/25][422/782] Loss_D: 0.5033 Loss_G: 3.7563\n",
      "[10/25][423/782] Loss_D: 0.6736 Loss_G: 0.5093\n",
      "[10/25][424/782] Loss_D: 2.1463 Loss_G: 9.5442\n",
      "[10/25][425/782] Loss_D: 5.2005 Loss_G: 0.6074\n",
      "[10/25][426/782] Loss_D: 1.7100 Loss_G: 2.9845\n",
      "[10/25][427/782] Loss_D: 0.9285 Loss_G: 2.1022\n",
      "[10/25][428/782] Loss_D: 0.8149 Loss_G: 1.0480\n",
      "[10/25][429/782] Loss_D: 1.0818 Loss_G: 2.9958\n",
      "[10/25][430/782] Loss_D: 1.0646 Loss_G: 1.9294\n",
      "[10/25][431/782] Loss_D: 0.8975 Loss_G: 1.4741\n",
      "[10/25][432/782] Loss_D: 0.8707 Loss_G: 2.7482\n",
      "[10/25][433/782] Loss_D: 0.8349 Loss_G: 1.6479\n",
      "[10/25][434/782] Loss_D: 0.8824 Loss_G: 2.3264\n",
      "[10/25][435/782] Loss_D: 0.7890 Loss_G: 2.6285\n",
      "[10/25][436/782] Loss_D: 0.7561 Loss_G: 1.6317\n",
      "[10/25][437/782] Loss_D: 1.0832 Loss_G: 3.1999\n",
      "[10/25][438/782] Loss_D: 0.8396 Loss_G: 1.4910\n",
      "[10/25][439/782] Loss_D: 0.5817 Loss_G: 3.0780\n",
      "[10/25][440/782] Loss_D: 0.6123 Loss_G: 2.2961\n",
      "[10/25][441/782] Loss_D: 0.6742 Loss_G: 2.3716\n",
      "[10/25][442/782] Loss_D: 0.6284 Loss_G: 2.2449\n",
      "[10/25][443/782] Loss_D: 0.7171 Loss_G: 2.2194\n",
      "[10/25][444/782] Loss_D: 0.7700 Loss_G: 2.7559\n",
      "[10/25][445/782] Loss_D: 0.6613 Loss_G: 2.2845\n",
      "[10/25][446/782] Loss_D: 0.7177 Loss_G: 2.2146\n",
      "[10/25][447/782] Loss_D: 0.6655 Loss_G: 2.4090\n",
      "[10/25][448/782] Loss_D: 0.6813 Loss_G: 1.6894\n",
      "[10/25][449/782] Loss_D: 0.7177 Loss_G: 4.1414\n",
      "[10/25][450/782] Loss_D: 0.6999 Loss_G: 1.7443\n",
      "[10/25][451/782] Loss_D: 0.4567 Loss_G: 3.3345\n",
      "[10/25][452/782] Loss_D: 0.5502 Loss_G: 2.2364\n",
      "[10/25][453/782] Loss_D: 0.5257 Loss_G: 2.9383\n",
      "[10/25][454/782] Loss_D: 0.3568 Loss_G: 3.3438\n",
      "[10/25][455/782] Loss_D: 0.3554 Loss_G: 2.6908\n",
      "[10/25][456/782] Loss_D: 0.3892 Loss_G: 2.5370\n",
      "[10/25][457/782] Loss_D: 0.4583 Loss_G: 3.6976\n",
      "[10/25][458/782] Loss_D: 0.1896 Loss_G: 3.8280\n",
      "[10/25][459/782] Loss_D: 0.3030 Loss_G: 2.2977\n",
      "[10/25][460/782] Loss_D: 0.3726 Loss_G: 3.5285\n",
      "[10/25][461/782] Loss_D: 0.2484 Loss_G: 3.2654\n",
      "[10/25][462/782] Loss_D: 0.3467 Loss_G: 3.1172\n",
      "[10/25][463/782] Loss_D: 0.2183 Loss_G: 3.4534\n",
      "[10/25][464/782] Loss_D: 0.2519 Loss_G: 2.7861\n",
      "[10/25][465/782] Loss_D: 0.2116 Loss_G: 4.1636\n",
      "[10/25][466/782] Loss_D: 0.3000 Loss_G: 2.3704\n",
      "[10/25][467/782] Loss_D: 0.3242 Loss_G: 4.5933\n",
      "[10/25][468/782] Loss_D: 0.1750 Loss_G: 3.7608\n",
      "[10/25][469/782] Loss_D: 0.1312 Loss_G: 3.6445\n",
      "[10/25][470/782] Loss_D: 0.2219 Loss_G: 3.2215\n",
      "[10/25][471/782] Loss_D: 0.1053 Loss_G: 3.4170\n",
      "[10/25][472/782] Loss_D: 0.1944 Loss_G: 5.5454\n",
      "[10/25][473/782] Loss_D: 0.1152 Loss_G: 4.4718\n",
      "[10/25][474/782] Loss_D: 0.3002 Loss_G: 2.4546\n",
      "[10/25][475/782] Loss_D: 0.1534 Loss_G: 5.0041\n",
      "[10/25][476/782] Loss_D: 0.1515 Loss_G: 3.7521\n",
      "[10/25][477/782] Loss_D: 0.0556 Loss_G: 4.8160\n",
      "[10/25][478/782] Loss_D: 0.0189 Loss_G: 5.4537\n",
      "[10/25][479/782] Loss_D: 0.0698 Loss_G: 4.0471\n",
      "[10/25][480/782] Loss_D: 0.0398 Loss_G: 4.3334\n",
      "[10/25][481/782] Loss_D: 0.0182 Loss_G: 5.4315\n",
      "[10/25][482/782] Loss_D: 0.1246 Loss_G: 5.4113\n",
      "[10/25][483/782] Loss_D: 0.1174 Loss_G: 4.1297\n",
      "[10/25][484/782] Loss_D: 0.0375 Loss_G: 4.3155\n",
      "[10/25][485/782] Loss_D: 0.1087 Loss_G: 5.1492\n",
      "[10/25][486/782] Loss_D: 0.0479 Loss_G: 5.0427\n",
      "[10/25][487/782] Loss_D: 0.0486 Loss_G: 4.3982\n",
      "[10/25][488/782] Loss_D: 0.0432 Loss_G: 4.3113\n",
      "[10/25][489/782] Loss_D: 0.0460 Loss_G: 4.3200\n",
      "[10/25][490/782] Loss_D: 0.0613 Loss_G: 4.5696\n",
      "[10/25][491/782] Loss_D: 0.0623 Loss_G: 4.5985\n",
      "[10/25][492/782] Loss_D: 0.0694 Loss_G: 4.2779\n",
      "[10/25][493/782] Loss_D: 0.0729 Loss_G: 4.0507\n",
      "[10/25][494/782] Loss_D: 0.0417 Loss_G: 5.0120\n",
      "[10/25][495/782] Loss_D: 0.0684 Loss_G: 5.2595\n",
      "[10/25][496/782] Loss_D: 0.1130 Loss_G: 4.7198\n",
      "[10/25][497/782] Loss_D: 0.0354 Loss_G: 4.1728\n",
      "[10/25][498/782] Loss_D: 0.0506 Loss_G: 5.0427\n",
      "[10/25][499/782] Loss_D: 0.0265 Loss_G: 5.4524\n",
      "[10/25][500/782] Loss_D: 0.0191 Loss_G: 5.5497\n",
      "[10/25][501/782] Loss_D: 0.0368 Loss_G: 4.9787\n",
      "[10/25][502/782] Loss_D: 0.1258 Loss_G: 3.2439\n",
      "[10/25][503/782] Loss_D: 0.0241 Loss_G: 4.3195\n",
      "[10/25][504/782] Loss_D: 0.0771 Loss_G: 6.4789\n",
      "[10/25][505/782] Loss_D: 0.0719 Loss_G: 5.0529\n",
      "[10/25][506/782] Loss_D: 0.2255 Loss_G: 3.9974\n",
      "[10/25][507/782] Loss_D: 0.1250 Loss_G: 6.3706\n",
      "[10/25][508/782] Loss_D: 1.3220 Loss_G: 4.7214\n",
      "[10/25][509/782] Loss_D: 2.4568 Loss_G: 0.0115\n",
      "[10/25][510/782] Loss_D: 5.7601 Loss_G: 2.5181\n",
      "[10/25][511/782] Loss_D: 1.3652 Loss_G: 2.2946\n",
      "[10/25][512/782] Loss_D: 0.8121 Loss_G: 1.7995\n",
      "[10/25][513/782] Loss_D: 0.8097 Loss_G: 2.6190\n",
      "[10/25][514/782] Loss_D: 0.9870 Loss_G: 1.6893\n",
      "[10/25][515/782] Loss_D: 0.9120 Loss_G: 3.3104\n",
      "[10/25][516/782] Loss_D: 1.0411 Loss_G: 1.0700\n",
      "[10/25][517/782] Loss_D: 1.5660 Loss_G: 3.9370\n",
      "[10/25][518/782] Loss_D: 1.6345 Loss_G: 1.1567\n",
      "[10/25][519/782] Loss_D: 0.9074 Loss_G: 1.9486\n",
      "[10/25][520/782] Loss_D: 0.5266 Loss_G: 3.3042\n",
      "[10/25][521/782] Loss_D: 0.5354 Loss_G: 2.2908\n",
      "[10/25][522/782] Loss_D: 0.5992 Loss_G: 1.8489\n",
      "[10/25][523/782] Loss_D: 0.6876 Loss_G: 2.4036\n",
      "[10/25][524/782] Loss_D: 0.5781 Loss_G: 2.9765\n",
      "[10/25][525/782] Loss_D: 1.1168 Loss_G: 0.7759\n",
      "[10/25][526/782] Loss_D: 1.4059 Loss_G: 3.8200\n",
      "[10/25][527/782] Loss_D: 1.2630 Loss_G: 1.3999\n",
      "[10/25][528/782] Loss_D: 0.7281 Loss_G: 2.4958\n",
      "[10/25][529/782] Loss_D: 0.7862 Loss_G: 1.9362\n",
      "[10/25][530/782] Loss_D: 0.7681 Loss_G: 2.9506\n",
      "[10/25][531/782] Loss_D: 0.9354 Loss_G: 1.3701\n",
      "[10/25][532/782] Loss_D: 0.8117 Loss_G: 1.9234\n",
      "[10/25][533/782] Loss_D: 0.9082 Loss_G: 2.7222\n",
      "[10/25][534/782] Loss_D: 0.9451 Loss_G: 1.0704\n",
      "[10/25][535/782] Loss_D: 1.0072 Loss_G: 2.7988\n",
      "[10/25][536/782] Loss_D: 0.7217 Loss_G: 2.1428\n",
      "[10/25][537/782] Loss_D: 0.8559 Loss_G: 1.8295\n",
      "[10/25][538/782] Loss_D: 0.7897 Loss_G: 1.9111\n",
      "[10/25][539/782] Loss_D: 0.9431 Loss_G: 2.9655\n",
      "[10/25][540/782] Loss_D: 0.8206 Loss_G: 1.9118\n",
      "[10/25][541/782] Loss_D: 0.9661 Loss_G: 1.4531\n",
      "[10/25][542/782] Loss_D: 1.3406 Loss_G: 3.3158\n",
      "[10/25][543/782] Loss_D: 1.1113 Loss_G: 0.9667\n",
      "[10/25][544/782] Loss_D: 1.2082 Loss_G: 3.6773\n",
      "[10/25][545/782] Loss_D: 1.0016 Loss_G: 1.7215\n",
      "[10/25][546/782] Loss_D: 0.8526 Loss_G: 1.6163\n",
      "[10/25][547/782] Loss_D: 1.2978 Loss_G: 4.2605\n",
      "[10/25][548/782] Loss_D: 1.8393 Loss_G: 1.1973\n",
      "[10/25][549/782] Loss_D: 1.1240 Loss_G: 2.7971\n",
      "[10/25][550/782] Loss_D: 0.7958 Loss_G: 2.4131\n",
      "[10/25][551/782] Loss_D: 0.8882 Loss_G: 1.8312\n",
      "[10/25][552/782] Loss_D: 0.7857 Loss_G: 3.2140\n",
      "[10/25][553/782] Loss_D: 0.8373 Loss_G: 1.6081\n",
      "[10/25][554/782] Loss_D: 0.7082 Loss_G: 3.0835\n",
      "[10/25][555/782] Loss_D: 0.6572 Loss_G: 2.3969\n",
      "[10/25][556/782] Loss_D: 0.7664 Loss_G: 2.4738\n",
      "[10/25][557/782] Loss_D: 0.5793 Loss_G: 2.4503\n",
      "[10/25][558/782] Loss_D: 0.7342 Loss_G: 2.0880\n",
      "[10/25][559/782] Loss_D: 0.9012 Loss_G: 3.0016\n",
      "[10/25][560/782] Loss_D: 0.7703 Loss_G: 1.5510\n",
      "[10/25][561/782] Loss_D: 0.6455 Loss_G: 3.4254\n",
      "[10/25][562/782] Loss_D: 1.0927 Loss_G: 1.1944\n",
      "[10/25][563/782] Loss_D: 1.1083 Loss_G: 2.6363\n",
      "[10/25][564/782] Loss_D: 0.5789 Loss_G: 3.0550\n",
      "[10/25][565/782] Loss_D: 1.0360 Loss_G: 1.1098\n",
      "[10/25][566/782] Loss_D: 1.2304 Loss_G: 4.0675\n",
      "[10/25][567/782] Loss_D: 1.4513 Loss_G: 0.7494\n",
      "[10/25][568/782] Loss_D: 1.3412 Loss_G: 4.0509\n",
      "[10/25][569/782] Loss_D: 0.7543 Loss_G: 2.6538\n",
      "[10/25][570/782] Loss_D: 0.4920 Loss_G: 2.2474\n",
      "[10/25][571/782] Loss_D: 0.7802 Loss_G: 2.9706\n",
      "[10/25][572/782] Loss_D: 0.7946 Loss_G: 2.6497\n",
      "[10/25][573/782] Loss_D: 0.7626 Loss_G: 2.9273\n",
      "[10/25][574/782] Loss_D: 1.1817 Loss_G: 0.8190\n",
      "[10/25][575/782] Loss_D: 1.4723 Loss_G: 5.1946\n",
      "[10/25][576/782] Loss_D: 0.9940 Loss_G: 2.3892\n",
      "[10/25][577/782] Loss_D: 0.5855 Loss_G: 2.1995\n",
      "[10/25][578/782] Loss_D: 0.9414 Loss_G: 3.7086\n",
      "[10/25][579/782] Loss_D: 0.9159 Loss_G: 1.3466\n",
      "[10/25][580/782] Loss_D: 1.1474 Loss_G: 4.1321\n",
      "[10/25][581/782] Loss_D: 1.2765 Loss_G: 1.0312\n",
      "[10/25][582/782] Loss_D: 1.1447 Loss_G: 4.1810\n",
      "[10/25][583/782] Loss_D: 1.1607 Loss_G: 1.5789\n",
      "[10/25][584/782] Loss_D: 0.6271 Loss_G: 2.8545\n",
      "[10/25][585/782] Loss_D: 0.6262 Loss_G: 3.4170\n",
      "[10/25][586/782] Loss_D: 0.5793 Loss_G: 2.0463\n",
      "[10/25][587/782] Loss_D: 0.7545 Loss_G: 2.0207\n",
      "[10/25][588/782] Loss_D: 0.7883 Loss_G: 4.7160\n",
      "[10/25][589/782] Loss_D: 1.0405 Loss_G: 1.6466\n",
      "[10/25][590/782] Loss_D: 0.7700 Loss_G: 3.5978\n",
      "[10/25][591/782] Loss_D: 0.4346 Loss_G: 3.2271\n",
      "[10/25][592/782] Loss_D: 0.4499 Loss_G: 1.9880\n",
      "[10/25][593/782] Loss_D: 0.5260 Loss_G: 2.5759\n",
      "[10/25][594/782] Loss_D: 0.8223 Loss_G: 3.4944\n",
      "[10/25][595/782] Loss_D: 0.7187 Loss_G: 2.0656\n",
      "[10/25][596/782] Loss_D: 0.7093 Loss_G: 2.2960\n",
      "[10/25][597/782] Loss_D: 0.9788 Loss_G: 3.2448\n",
      "[10/25][598/782] Loss_D: 0.6146 Loss_G: 2.0291\n",
      "[10/25][599/782] Loss_D: 0.6282 Loss_G: 3.3449\n",
      "[10/25][600/782] Loss_D: 0.6906 Loss_G: 2.3163\n",
      "[10/25][601/782] Loss_D: 0.5550 Loss_G: 2.5538\n",
      "[10/25][602/782] Loss_D: 0.6789 Loss_G: 3.7039\n",
      "[10/25][603/782] Loss_D: 0.9554 Loss_G: 1.2545\n",
      "[10/25][604/782] Loss_D: 0.9196 Loss_G: 3.6694\n",
      "[10/25][605/782] Loss_D: 0.6011 Loss_G: 2.0072\n",
      "[10/25][606/782] Loss_D: 0.9864 Loss_G: 4.0503\n",
      "[10/25][607/782] Loss_D: 0.8844 Loss_G: 1.3976\n",
      "[10/25][608/782] Loss_D: 0.6159 Loss_G: 2.9379\n",
      "[10/25][609/782] Loss_D: 0.4132 Loss_G: 3.8867\n",
      "[10/25][610/782] Loss_D: 0.8989 Loss_G: 1.2024\n",
      "[10/25][611/782] Loss_D: 0.6920 Loss_G: 3.7965\n",
      "[10/25][612/782] Loss_D: 0.5433 Loss_G: 2.6295\n",
      "[10/25][613/782] Loss_D: 0.6119 Loss_G: 2.5908\n",
      "[10/25][614/782] Loss_D: 0.4539 Loss_G: 2.8481\n",
      "[10/25][615/782] Loss_D: 0.6010 Loss_G: 2.4155\n",
      "[10/25][616/782] Loss_D: 0.6226 Loss_G: 3.8019\n",
      "[10/25][617/782] Loss_D: 0.5862 Loss_G: 1.7671\n",
      "[10/25][618/782] Loss_D: 0.8138 Loss_G: 4.9933\n",
      "[10/25][619/782] Loss_D: 0.8643 Loss_G: 1.5872\n",
      "[10/25][620/782] Loss_D: 0.6716 Loss_G: 4.0958\n",
      "[10/25][621/782] Loss_D: 0.5233 Loss_G: 2.2504\n",
      "[10/25][622/782] Loss_D: 0.4938 Loss_G: 4.1255\n",
      "[10/25][623/782] Loss_D: 0.5953 Loss_G: 1.6593\n",
      "[10/25][624/782] Loss_D: 0.8349 Loss_G: 5.2327\n",
      "[10/25][625/782] Loss_D: 0.8063 Loss_G: 2.0762\n",
      "[10/25][626/782] Loss_D: 0.5181 Loss_G: 3.4482\n",
      "[10/25][627/782] Loss_D: 0.5841 Loss_G: 3.8240\n",
      "[10/25][628/782] Loss_D: 0.5769 Loss_G: 2.3781\n",
      "[10/25][629/782] Loss_D: 0.5706 Loss_G: 2.8081\n",
      "[10/25][630/782] Loss_D: 0.7204 Loss_G: 1.7736\n",
      "[10/25][631/782] Loss_D: 0.7932 Loss_G: 5.1135\n",
      "[10/25][632/782] Loss_D: 0.9948 Loss_G: 1.6141\n",
      "[10/25][633/782] Loss_D: 0.5497 Loss_G: 2.9882\n",
      "[10/25][634/782] Loss_D: 0.5509 Loss_G: 3.4091\n",
      "[10/25][635/782] Loss_D: 0.4337 Loss_G: 3.1023\n",
      "[10/25][636/782] Loss_D: 0.3233 Loss_G: 3.2472\n",
      "[10/25][637/782] Loss_D: 0.4627 Loss_G: 1.9591\n",
      "[10/25][638/782] Loss_D: 0.4659 Loss_G: 4.5838\n",
      "[10/25][639/782] Loss_D: 0.4702 Loss_G: 2.8668\n",
      "[10/25][640/782] Loss_D: 0.3299 Loss_G: 3.0656\n",
      "[10/25][641/782] Loss_D: 0.3135 Loss_G: 3.7480\n",
      "[10/25][642/782] Loss_D: 0.2802 Loss_G: 3.6267\n",
      "[10/25][643/782] Loss_D: 0.2706 Loss_G: 2.4434\n",
      "[10/25][644/782] Loss_D: 2.0290 Loss_G: 9.6653\n",
      "[10/25][645/782] Loss_D: 5.4285 Loss_G: 3.4377\n",
      "[10/25][646/782] Loss_D: 1.1217 Loss_G: 0.0997\n",
      "[10/25][647/782] Loss_D: 3.1850 Loss_G: 2.7012\n",
      "[10/25][648/782] Loss_D: 0.8622 Loss_G: 3.2293\n",
      "[10/25][649/782] Loss_D: 0.8699 Loss_G: 1.3311\n",
      "[10/25][650/782] Loss_D: 0.7849 Loss_G: 1.7377\n",
      "[10/25][651/782] Loss_D: 1.0147 Loss_G: 2.4867\n",
      "[10/25][652/782] Loss_D: 0.9887 Loss_G: 2.4061\n",
      "[10/25][653/782] Loss_D: 0.7747 Loss_G: 1.6903\n",
      "[10/25][654/782] Loss_D: 0.7905 Loss_G: 2.6954\n",
      "[10/25][655/782] Loss_D: 0.6456 Loss_G: 2.3088\n",
      "[10/25][656/782] Loss_D: 0.5345 Loss_G: 2.8136\n",
      "[10/25][657/782] Loss_D: 0.7095 Loss_G: 1.7151\n",
      "[10/25][658/782] Loss_D: 0.6306 Loss_G: 3.1125\n",
      "[10/25][659/782] Loss_D: 0.7582 Loss_G: 2.0035\n",
      "[10/25][660/782] Loss_D: 0.6991 Loss_G: 2.7711\n",
      "[10/25][661/782] Loss_D: 0.7522 Loss_G: 1.7466\n",
      "[10/25][662/782] Loss_D: 0.6876 Loss_G: 3.1756\n",
      "[10/25][663/782] Loss_D: 0.6146 Loss_G: 2.3274\n",
      "[10/25][664/782] Loss_D: 0.7236 Loss_G: 2.0976\n",
      "[10/25][665/782] Loss_D: 0.3812 Loss_G: 2.9086\n",
      "[10/25][666/782] Loss_D: 0.8861 Loss_G: 1.5518\n",
      "[10/25][667/782] Loss_D: 0.6795 Loss_G: 4.1804\n",
      "[10/25][668/782] Loss_D: 0.8198 Loss_G: 1.5159\n",
      "[10/25][669/782] Loss_D: 0.6838 Loss_G: 3.8290\n",
      "[10/25][670/782] Loss_D: 0.8289 Loss_G: 1.7129\n",
      "[10/25][671/782] Loss_D: 0.6360 Loss_G: 3.4710\n",
      "[10/25][672/782] Loss_D: 0.4001 Loss_G: 3.1703\n",
      "[10/25][673/782] Loss_D: 0.4026 Loss_G: 2.7219\n",
      "[10/25][674/782] Loss_D: 0.2745 Loss_G: 2.7911\n",
      "[10/25][675/782] Loss_D: 0.4103 Loss_G: 3.3051\n",
      "[10/25][676/782] Loss_D: 0.5719 Loss_G: 1.9349\n",
      "[10/25][677/782] Loss_D: 0.5669 Loss_G: 3.1370\n",
      "[10/25][678/782] Loss_D: 0.4868 Loss_G: 2.3507\n",
      "[10/25][679/782] Loss_D: 0.6438 Loss_G: 3.4816\n",
      "[10/25][680/782] Loss_D: 0.7113 Loss_G: 1.8147\n",
      "[10/25][681/782] Loss_D: 0.5872 Loss_G: 3.3557\n",
      "[10/25][682/782] Loss_D: 0.3789 Loss_G: 3.0806\n",
      "[10/25][683/782] Loss_D: 0.3641 Loss_G: 2.1824\n",
      "[10/25][684/782] Loss_D: 0.5783 Loss_G: 2.9981\n",
      "[10/25][685/782] Loss_D: 0.2738 Loss_G: 3.4432\n",
      "[10/25][686/782] Loss_D: 0.3814 Loss_G: 2.5142\n",
      "[10/25][687/782] Loss_D: 0.3498 Loss_G: 2.8788\n",
      "[10/25][688/782] Loss_D: 0.3370 Loss_G: 2.9486\n",
      "[10/25][689/782] Loss_D: 0.3058 Loss_G: 3.2483\n",
      "[10/25][690/782] Loss_D: 0.3531 Loss_G: 2.3017\n",
      "[10/25][691/782] Loss_D: 0.3403 Loss_G: 2.3133\n",
      "[10/25][692/782] Loss_D: 0.5332 Loss_G: 4.0376\n",
      "[10/25][693/782] Loss_D: 0.2753 Loss_G: 3.7055\n",
      "[10/25][694/782] Loss_D: 0.2392 Loss_G: 2.6808\n",
      "[10/25][695/782] Loss_D: 0.2870 Loss_G: 3.5703\n",
      "[10/25][696/782] Loss_D: 0.3366 Loss_G: 2.5868\n",
      "[10/25][697/782] Loss_D: 0.3250 Loss_G: 4.0236\n",
      "[10/25][698/782] Loss_D: 0.2876 Loss_G: 2.9822\n",
      "[10/25][699/782] Loss_D: 0.2991 Loss_G: 3.5984\n",
      "[10/25][700/782] Loss_D: 0.4622 Loss_G: 1.8391\n",
      "[10/25][701/782] Loss_D: 0.3859 Loss_G: 5.3536\n",
      "[10/25][702/782] Loss_D: 0.5901 Loss_G: 3.1576\n",
      "[10/25][703/782] Loss_D: 0.5955 Loss_G: 8.3166\n",
      "[10/25][704/782] Loss_D: 5.1913 Loss_G: 0.3770\n",
      "[10/25][705/782] Loss_D: 2.4083 Loss_G: 5.5183\n",
      "[10/25][706/782] Loss_D: 1.6241 Loss_G: 0.9153\n",
      "[10/25][707/782] Loss_D: 0.9978 Loss_G: 4.7733\n",
      "[10/25][708/782] Loss_D: 0.8136 Loss_G: 1.6726\n",
      "[10/25][709/782] Loss_D: 0.5944 Loss_G: 3.1137\n",
      "[10/25][710/782] Loss_D: 0.4154 Loss_G: 3.0241\n",
      "[10/25][711/782] Loss_D: 0.4265 Loss_G: 2.1883\n",
      "[10/25][712/782] Loss_D: 0.6732 Loss_G: 3.9465\n",
      "[10/25][713/782] Loss_D: 0.7208 Loss_G: 2.6941\n",
      "[10/25][714/782] Loss_D: 0.5461 Loss_G: 4.0365\n",
      "[10/25][715/782] Loss_D: 0.3687 Loss_G: 2.9561\n",
      "[10/25][716/782] Loss_D: 0.1959 Loss_G: 3.0889\n",
      "[10/25][717/782] Loss_D: 0.5636 Loss_G: 4.3557\n",
      "[10/25][718/782] Loss_D: 0.5358 Loss_G: 2.7205\n",
      "[10/25][719/782] Loss_D: 0.3526 Loss_G: 3.7522\n",
      "[10/25][720/782] Loss_D: 0.2480 Loss_G: 4.6239\n",
      "[10/25][721/782] Loss_D: 0.1700 Loss_G: 3.3755\n",
      "[10/25][722/782] Loss_D: 0.1803 Loss_G: 4.7435\n",
      "[10/25][723/782] Loss_D: 0.1762 Loss_G: 3.7166\n",
      "[10/25][724/782] Loss_D: 0.0978 Loss_G: 3.9039\n",
      "[10/25][725/782] Loss_D: 0.0858 Loss_G: 4.1088\n",
      "[10/25][726/782] Loss_D: 0.0438 Loss_G: 4.3453\n",
      "[10/25][727/782] Loss_D: 0.1113 Loss_G: 5.0658\n",
      "[10/25][728/782] Loss_D: 0.0674 Loss_G: 4.9270\n",
      "[10/25][729/782] Loss_D: 0.2537 Loss_G: 6.9933\n",
      "[10/25][730/782] Loss_D: 0.6300 Loss_G: 2.1099\n",
      "[10/25][731/782] Loss_D: 0.4739 Loss_G: 8.5447\n",
      "[10/25][732/782] Loss_D: 1.5319 Loss_G: 1.8856\n",
      "[10/25][733/782] Loss_D: 3.2794 Loss_G: 7.4726\n",
      "[10/25][734/782] Loss_D: 3.7166 Loss_G: 2.4680\n",
      "[10/25][735/782] Loss_D: 0.3790 Loss_G: 2.6085\n",
      "[10/25][736/782] Loss_D: 0.5393 Loss_G: 4.4000\n",
      "[10/25][737/782] Loss_D: 1.0984 Loss_G: 1.5677\n",
      "[10/25][738/782] Loss_D: 0.9066 Loss_G: 2.7605\n",
      "[10/25][739/782] Loss_D: 0.3089 Loss_G: 4.4526\n",
      "[10/25][740/782] Loss_D: 0.4429 Loss_G: 2.4021\n",
      "[10/25][741/782] Loss_D: 0.5783 Loss_G: 3.5517\n",
      "[10/25][742/782] Loss_D: 0.3356 Loss_G: 5.1892\n",
      "[10/25][743/782] Loss_D: 0.7719 Loss_G: 1.7854\n",
      "[10/25][744/782] Loss_D: 0.5250 Loss_G: 3.8497\n",
      "[10/25][745/782] Loss_D: 0.7536 Loss_G: 6.1795\n",
      "[10/25][746/782] Loss_D: 2.6759 Loss_G: 2.8704\n",
      "[10/25][747/782] Loss_D: 0.1018 Loss_G: 2.1636\n",
      "[10/25][748/782] Loss_D: 1.1284 Loss_G: 6.7454\n",
      "[10/25][749/782] Loss_D: 2.2204 Loss_G: 0.4980\n",
      "[10/25][750/782] Loss_D: 2.4626 Loss_G: 4.5227\n",
      "[10/25][751/782] Loss_D: 0.6464 Loss_G: 4.0008\n",
      "[10/25][752/782] Loss_D: 0.4378 Loss_G: 2.4883\n",
      "[10/25][753/782] Loss_D: 0.3552 Loss_G: 2.8960\n",
      "[10/25][754/782] Loss_D: 0.2470 Loss_G: 3.7251\n",
      "[10/25][755/782] Loss_D: 0.4759 Loss_G: 2.8335\n",
      "[10/25][756/782] Loss_D: 0.5662 Loss_G: 3.1896\n",
      "[10/25][757/782] Loss_D: 0.4365 Loss_G: 2.2036\n",
      "[10/25][758/782] Loss_D: 0.5325 Loss_G: 5.0876\n",
      "[10/25][759/782] Loss_D: 0.3797 Loss_G: 2.7175\n",
      "[10/25][760/782] Loss_D: 0.3081 Loss_G: 5.0155\n",
      "[10/25][761/782] Loss_D: 0.2410 Loss_G: 4.8757\n",
      "[10/25][762/782] Loss_D: 0.2038 Loss_G: 3.5025\n",
      "[10/25][763/782] Loss_D: 0.1198 Loss_G: 4.4843\n",
      "[10/25][764/782] Loss_D: 0.0622 Loss_G: 5.0759\n",
      "[10/25][765/782] Loss_D: 0.2138 Loss_G: 5.7133\n",
      "[10/25][766/782] Loss_D: 0.2006 Loss_G: 4.5678\n",
      "[10/25][767/782] Loss_D: 0.1138 Loss_G: 3.2215\n",
      "[10/25][768/782] Loss_D: 0.0778 Loss_G: 4.8758\n",
      "[10/25][769/782] Loss_D: 0.1028 Loss_G: 5.9713\n",
      "[10/25][770/782] Loss_D: 0.0998 Loss_G: 5.4644\n",
      "[10/25][771/782] Loss_D: 0.0340 Loss_G: 4.6190\n",
      "[10/25][772/782] Loss_D: 0.0303 Loss_G: 4.6445\n",
      "[10/25][773/782] Loss_D: 0.5049 Loss_G: 8.4086\n",
      "[10/25][774/782] Loss_D: 4.0340 Loss_G: 2.5056\n",
      "[10/25][775/782] Loss_D: 1.1948 Loss_G: 4.4314\n",
      "[10/25][776/782] Loss_D: 1.0645 Loss_G: 0.3207\n",
      "[10/25][777/782] Loss_D: 3.7478 Loss_G: 8.2249\n",
      "[10/25][778/782] Loss_D: 2.8788 Loss_G: 3.8173\n",
      "[10/25][779/782] Loss_D: 0.5198 Loss_G: 0.4644\n",
      "[10/25][780/782] Loss_D: 1.8545 Loss_G: 4.4806\n",
      "[10/25][781/782] Loss_D: 0.3135 Loss_G: 4.9027\n",
      "[11/25][0/782] Loss_D: 0.8457 Loss_G: 2.0686\n",
      "[11/25][1/782] Loss_D: 0.5607 Loss_G: 2.1986\n",
      "[11/25][2/782] Loss_D: 0.4856 Loss_G: 3.3624\n",
      "[11/25][3/782] Loss_D: 0.4451 Loss_G: 3.3193\n",
      "[11/25][4/782] Loss_D: 0.6694 Loss_G: 1.9428\n",
      "[11/25][5/782] Loss_D: 0.5117 Loss_G: 2.3660\n",
      "[11/25][6/782] Loss_D: 0.5406 Loss_G: 3.1832\n",
      "[11/25][7/782] Loss_D: 0.4302 Loss_G: 3.3202\n",
      "[11/25][8/782] Loss_D: 0.6848 Loss_G: 1.4178\n",
      "[11/25][9/782] Loss_D: 0.8498 Loss_G: 3.9781\n",
      "[11/25][10/782] Loss_D: 0.5206 Loss_G: 2.9036\n",
      "[11/25][11/782] Loss_D: 0.3972 Loss_G: 2.4290\n",
      "[11/25][12/782] Loss_D: 0.2999 Loss_G: 2.8814\n",
      "[11/25][13/782] Loss_D: 0.6688 Loss_G: 5.0066\n",
      "[11/25][14/782] Loss_D: 0.6483 Loss_G: 2.3882\n",
      "[11/25][15/782] Loss_D: 0.4168 Loss_G: 3.7549\n",
      "[11/25][16/782] Loss_D: 0.3616 Loss_G: 3.4337\n",
      "[11/25][17/782] Loss_D: 0.2691 Loss_G: 3.8378\n",
      "[11/25][18/782] Loss_D: 0.2610 Loss_G: 3.3932\n",
      "[11/25][19/782] Loss_D: 0.3054 Loss_G: 3.8507\n",
      "[11/25][20/782] Loss_D: 0.0927 Loss_G: 4.4872\n",
      "[11/25][21/782] Loss_D: 0.2443 Loss_G: 3.2905\n",
      "[11/25][22/782] Loss_D: 0.0870 Loss_G: 4.0407\n",
      "[11/25][23/782] Loss_D: 0.4602 Loss_G: 4.8856\n",
      "[11/25][24/782] Loss_D: 0.4984 Loss_G: 3.8763\n",
      "[11/25][25/782] Loss_D: 0.3639 Loss_G: 4.8242\n",
      "[11/25][26/782] Loss_D: 1.0826 Loss_G: 2.8620\n",
      "[11/25][27/782] Loss_D: 0.5671 Loss_G: 0.8509\n",
      "[11/25][28/782] Loss_D: 0.7655 Loss_G: 4.6697\n",
      "[11/25][29/782] Loss_D: 1.3561 Loss_G: 0.1484\n",
      "[11/25][30/782] Loss_D: 3.3756 Loss_G: 7.2818\n",
      "[11/25][31/782] Loss_D: 2.0411 Loss_G: 2.3653\n",
      "[11/25][32/782] Loss_D: 0.3966 Loss_G: 1.7041\n",
      "[11/25][33/782] Loss_D: 0.5141 Loss_G: 3.6422\n",
      "[11/25][34/782] Loss_D: 0.5408 Loss_G: 3.7584\n",
      "[11/25][35/782] Loss_D: 0.9034 Loss_G: 1.6802\n",
      "[11/25][36/782] Loss_D: 1.1121 Loss_G: 3.5130\n",
      "[11/25][37/782] Loss_D: 0.8622 Loss_G: 2.1273\n",
      "[11/25][38/782] Loss_D: 0.9723 Loss_G: 2.0885\n",
      "[11/25][39/782] Loss_D: 0.9100 Loss_G: 3.8438\n",
      "[11/25][40/782] Loss_D: 1.0702 Loss_G: 1.3377\n",
      "[11/25][41/782] Loss_D: 0.6769 Loss_G: 3.3615\n",
      "[11/25][42/782] Loss_D: 0.3775 Loss_G: 3.6230\n",
      "[11/25][43/782] Loss_D: 0.3518 Loss_G: 2.8524\n",
      "[11/25][44/782] Loss_D: 0.4347 Loss_G: 2.4634\n",
      "[11/25][45/782] Loss_D: 0.6898 Loss_G: 5.1442\n",
      "[11/25][46/782] Loss_D: 0.3536 Loss_G: 3.5263\n",
      "[11/25][47/782] Loss_D: 0.1762 Loss_G: 3.0829\n",
      "[11/25][48/782] Loss_D: 0.4279 Loss_G: 5.1821\n",
      "[11/25][49/782] Loss_D: 0.1848 Loss_G: 4.2335\n",
      "[11/25][50/782] Loss_D: 0.2196 Loss_G: 3.9631\n",
      "[11/25][51/782] Loss_D: 0.4366 Loss_G: 1.7397\n",
      "[11/25][52/782] Loss_D: 0.6329 Loss_G: 7.7206\n",
      "[11/25][53/782] Loss_D: 0.8292 Loss_G: 1.3443\n",
      "[11/25][54/782] Loss_D: 0.7080 Loss_G: 7.0867\n",
      "[11/25][55/782] Loss_D: 2.2113 Loss_G: 4.2654\n",
      "[11/25][56/782] Loss_D: 0.1879 Loss_G: 2.9764\n",
      "[11/25][57/782] Loss_D: 0.4460 Loss_G: 3.9254\n",
      "[11/25][58/782] Loss_D: 0.6261 Loss_G: 1.4786\n",
      "[11/25][59/782] Loss_D: 1.5349 Loss_G: 7.5907\n",
      "[11/25][60/782] Loss_D: 3.8191 Loss_G: 1.9498\n",
      "[11/25][61/782] Loss_D: 0.7463 Loss_G: 1.8395\n",
      "[11/25][62/782] Loss_D: 1.0158 Loss_G: 5.6574\n",
      "[11/25][63/782] Loss_D: 1.2052 Loss_G: 2.1985\n",
      "[11/25][64/782] Loss_D: 0.5344 Loss_G: 3.5935\n",
      "[11/25][65/782] Loss_D: 0.3942 Loss_G: 4.1375\n",
      "[11/25][66/782] Loss_D: 0.4386 Loss_G: 3.1968\n",
      "[11/25][67/782] Loss_D: 0.2704 Loss_G: 3.6600\n",
      "[11/25][68/782] Loss_D: 0.2845 Loss_G: 3.4306\n",
      "[11/25][69/782] Loss_D: 0.2154 Loss_G: 3.8976\n",
      "[11/25][70/782] Loss_D: 0.1947 Loss_G: 3.6742\n",
      "[11/25][71/782] Loss_D: 0.4582 Loss_G: 5.7749\n",
      "[11/25][72/782] Loss_D: 0.4044 Loss_G: 3.6839\n",
      "[11/25][73/782] Loss_D: 0.1394 Loss_G: 3.2393\n",
      "[11/25][74/782] Loss_D: 0.1689 Loss_G: 4.6065\n",
      "[11/25][75/782] Loss_D: 0.1239 Loss_G: 5.9212\n",
      "[11/25][76/782] Loss_D: 0.2398 Loss_G: 5.3840\n",
      "[11/25][77/782] Loss_D: 0.2397 Loss_G: 2.9898\n",
      "[11/25][78/782] Loss_D: 0.2450 Loss_G: 5.8230\n",
      "[11/25][79/782] Loss_D: 0.5104 Loss_G: 3.2894\n",
      "[11/25][80/782] Loss_D: 0.6132 Loss_G: 3.2517\n",
      "[11/25][81/782] Loss_D: 0.5581 Loss_G: 1.9953\n",
      "[11/25][82/782] Loss_D: 0.1627 Loss_G: 6.1023\n",
      "[11/25][83/782] Loss_D: 0.5192 Loss_G: 4.4073\n",
      "[11/25][84/782] Loss_D: 0.2524 Loss_G: 2.7921\n",
      "[11/25][85/782] Loss_D: 0.8504 Loss_G: 8.7722\n",
      "[11/25][86/782] Loss_D: 2.3560 Loss_G: 1.8497\n",
      "[11/25][87/782] Loss_D: 0.7240 Loss_G: 7.0684\n",
      "[11/25][88/782] Loss_D: 2.7285 Loss_G: 0.2801\n",
      "[11/25][89/782] Loss_D: 1.8355 Loss_G: 5.7337\n",
      "[11/25][90/782] Loss_D: 0.4183 Loss_G: 3.8133\n",
      "[11/25][91/782] Loss_D: 0.2688 Loss_G: 2.6479\n",
      "[11/25][92/782] Loss_D: 0.5313 Loss_G: 3.3712\n",
      "[11/25][93/782] Loss_D: 1.2419 Loss_G: 6.6772\n",
      "[11/25][94/782] Loss_D: 2.4375 Loss_G: 2.2934\n",
      "[11/25][95/782] Loss_D: 0.6717 Loss_G: 1.5473\n",
      "[11/25][96/782] Loss_D: 1.0225 Loss_G: 4.6995\n",
      "[11/25][97/782] Loss_D: 1.7729 Loss_G: 0.9646\n",
      "[11/25][98/782] Loss_D: 0.8180 Loss_G: 2.9340\n",
      "[11/25][99/782] Loss_D: 0.4899 Loss_G: 3.4453\n",
      "[11/25][100/782] Loss_D: 0.4722 Loss_G: 2.6430\n",
      "[11/25][101/782] Loss_D: 0.4737 Loss_G: 3.3668\n",
      "[11/25][102/782] Loss_D: 0.4274 Loss_G: 2.3821\n",
      "[11/25][103/782] Loss_D: 0.1949 Loss_G: 3.6556\n",
      "[11/25][104/782] Loss_D: 0.2981 Loss_G: 4.4563\n",
      "[11/25][105/782] Loss_D: 0.2445 Loss_G: 3.5757\n",
      "[11/25][106/782] Loss_D: 0.0991 Loss_G: 3.9409\n",
      "[11/25][107/782] Loss_D: 0.3607 Loss_G: 5.6633\n",
      "[11/25][108/782] Loss_D: 0.2823 Loss_G: 4.2722\n",
      "[11/25][109/782] Loss_D: 0.0629 Loss_G: 3.7407\n",
      "[11/25][110/782] Loss_D: 0.2013 Loss_G: 4.5499\n",
      "[11/25][111/782] Loss_D: 0.1001 Loss_G: 4.6334\n",
      "[11/25][112/782] Loss_D: 0.1872 Loss_G: 3.5195\n",
      "[11/25][113/782] Loss_D: 0.1089 Loss_G: 3.9965\n",
      "[11/25][114/782] Loss_D: 0.2253 Loss_G: 4.7902\n",
      "[11/25][115/782] Loss_D: 0.1530 Loss_G: 4.1636\n",
      "[11/25][116/782] Loss_D: 0.0329 Loss_G: 4.8244\n",
      "[11/25][117/782] Loss_D: 0.0588 Loss_G: 4.2449\n",
      "[11/25][118/782] Loss_D: 0.0503 Loss_G: 4.7996\n",
      "[11/25][119/782] Loss_D: 0.1583 Loss_G: 4.7916\n",
      "[11/25][120/782] Loss_D: 0.0671 Loss_G: 5.2498\n",
      "[11/25][121/782] Loss_D: 0.0322 Loss_G: 6.1579\n",
      "[11/25][122/782] Loss_D: 0.0302 Loss_G: 4.9326\n",
      "[11/25][123/782] Loss_D: 0.0768 Loss_G: 4.0226\n",
      "[11/25][124/782] Loss_D: 0.0229 Loss_G: 5.3117\n",
      "[11/25][125/782] Loss_D: 0.0343 Loss_G: 4.6902\n",
      "[11/25][126/782] Loss_D: 0.0566 Loss_G: 4.5269\n",
      "[11/25][127/782] Loss_D: 0.0322 Loss_G: 5.8164\n",
      "[11/25][128/782] Loss_D: 0.0582 Loss_G: 4.3520\n",
      "[11/25][129/782] Loss_D: 0.0389 Loss_G: 6.4050\n",
      "[11/25][130/782] Loss_D: 0.0979 Loss_G: 4.4736\n",
      "[11/25][131/782] Loss_D: 0.0704 Loss_G: 4.7259\n",
      "[11/25][132/782] Loss_D: 0.1204 Loss_G: 4.6369\n",
      "[11/25][133/782] Loss_D: 0.0662 Loss_G: 3.9488\n",
      "[11/25][134/782] Loss_D: 0.1040 Loss_G: 5.0745\n",
      "[11/25][135/782] Loss_D: 0.0262 Loss_G: 5.6293\n",
      "[11/25][136/782] Loss_D: 0.0693 Loss_G: 4.6379\n",
      "[11/25][137/782] Loss_D: 0.0217 Loss_G: 5.2630\n",
      "[11/25][138/782] Loss_D: 0.0552 Loss_G: 4.4258\n",
      "[11/25][139/782] Loss_D: 0.0124 Loss_G: 6.2755\n",
      "[11/25][140/782] Loss_D: 0.0448 Loss_G: 5.2489\n",
      "[11/25][141/782] Loss_D: 0.0059 Loss_G: 8.1196\n",
      "[11/25][142/782] Loss_D: 0.0156 Loss_G: 5.8168\n",
      "[11/25][143/782] Loss_D: 0.0379 Loss_G: 6.1995\n",
      "[11/25][144/782] Loss_D: 0.1997 Loss_G: 6.5431\n",
      "[11/25][145/782] Loss_D: 0.1405 Loss_G: 8.0042\n",
      "[11/25][146/782] Loss_D: 0.0766 Loss_G: 5.0715\n",
      "[11/25][147/782] Loss_D: 0.0138 Loss_G: 5.0443\n",
      "[11/25][148/782] Loss_D: 0.3457 Loss_G: 9.2020\n",
      "[11/25][149/782] Loss_D: 1.9788 Loss_G: 4.2235\n",
      "[11/25][150/782] Loss_D: 2.2938 Loss_G: 0.0055\n",
      "[11/25][151/782] Loss_D: 6.3298 Loss_G: 2.6917\n",
      "[11/25][152/782] Loss_D: 1.1538 Loss_G: 4.5032\n",
      "[11/25][153/782] Loss_D: 1.7760 Loss_G: 1.2044\n",
      "[11/25][154/782] Loss_D: 0.9028 Loss_G: 2.2628\n",
      "[11/25][155/782] Loss_D: 0.8244 Loss_G: 3.5594\n",
      "[11/25][156/782] Loss_D: 1.0821 Loss_G: 1.2067\n",
      "[11/25][157/782] Loss_D: 0.8600 Loss_G: 2.7525\n",
      "[11/25][158/782] Loss_D: 0.5206 Loss_G: 2.7559\n",
      "[11/25][159/782] Loss_D: 0.7331 Loss_G: 1.3648\n",
      "[11/25][160/782] Loss_D: 0.8018 Loss_G: 2.4765\n",
      "[11/25][161/782] Loss_D: 0.4967 Loss_G: 2.9034\n",
      "[11/25][162/782] Loss_D: 1.0278 Loss_G: 1.2865\n",
      "[11/25][163/782] Loss_D: 0.6857 Loss_G: 2.0864\n",
      "[11/25][164/782] Loss_D: 0.8507 Loss_G: 3.8306\n",
      "[11/25][165/782] Loss_D: 1.0664 Loss_G: 1.5287\n",
      "[11/25][166/782] Loss_D: 0.8290 Loss_G: 2.4206\n",
      "[11/25][167/782] Loss_D: 1.0092 Loss_G: 2.3333\n",
      "[11/25][168/782] Loss_D: 0.7074 Loss_G: 1.9173\n",
      "[11/25][169/782] Loss_D: 0.8973 Loss_G: 2.5051\n",
      "[11/25][170/782] Loss_D: 0.9151 Loss_G: 1.8746\n",
      "[11/25][171/782] Loss_D: 0.9110 Loss_G: 1.9597\n",
      "[11/25][172/782] Loss_D: 0.9444 Loss_G: 2.7684\n",
      "[11/25][173/782] Loss_D: 1.1725 Loss_G: 0.9579\n",
      "[11/25][174/782] Loss_D: 1.2749 Loss_G: 3.9515\n",
      "[11/25][175/782] Loss_D: 1.5696 Loss_G: 1.3237\n",
      "[11/25][176/782] Loss_D: 1.1870 Loss_G: 2.1808\n",
      "[11/25][177/782] Loss_D: 0.8390 Loss_G: 2.2602\n",
      "[11/25][178/782] Loss_D: 0.6840 Loss_G: 1.8234\n",
      "[11/25][179/782] Loss_D: 1.2026 Loss_G: 3.4895\n",
      "[11/25][180/782] Loss_D: 1.1093 Loss_G: 1.4341\n",
      "[11/25][181/782] Loss_D: 0.5895 Loss_G: 2.1665\n",
      "[11/25][182/782] Loss_D: 0.6217 Loss_G: 2.6834\n",
      "[11/25][183/782] Loss_D: 0.6045 Loss_G: 2.0967\n",
      "[11/25][184/782] Loss_D: 0.7559 Loss_G: 2.0698\n",
      "[11/25][185/782] Loss_D: 0.5812 Loss_G: 2.6849\n",
      "[11/25][186/782] Loss_D: 0.8116 Loss_G: 1.3050\n",
      "[11/25][187/782] Loss_D: 0.7876 Loss_G: 3.6591\n",
      "[11/25][188/782] Loss_D: 0.9197 Loss_G: 1.5247\n",
      "[11/25][189/782] Loss_D: 0.6620 Loss_G: 2.4093\n",
      "[11/25][190/782] Loss_D: 0.6656 Loss_G: 2.5930\n",
      "[11/25][191/782] Loss_D: 0.8384 Loss_G: 1.3411\n",
      "[11/25][192/782] Loss_D: 0.8486 Loss_G: 3.0754\n",
      "[11/25][193/782] Loss_D: 0.7701 Loss_G: 1.6749\n",
      "[11/25][194/782] Loss_D: 0.6945 Loss_G: 2.5188\n",
      "[11/25][195/782] Loss_D: 0.5517 Loss_G: 2.3103\n",
      "[11/25][196/782] Loss_D: 0.6688 Loss_G: 3.3252\n",
      "[11/25][197/782] Loss_D: 0.6435 Loss_G: 1.9869\n",
      "[11/25][198/782] Loss_D: 0.4466 Loss_G: 1.7700\n",
      "[11/25][199/782] Loss_D: 0.6886 Loss_G: 4.2537\n",
      "[11/25][200/782] Loss_D: 0.9378 Loss_G: 1.1195\n",
      "[11/25][201/782] Loss_D: 0.7777 Loss_G: 3.2356\n",
      "[11/25][202/782] Loss_D: 0.4775 Loss_G: 2.4578\n",
      "[11/25][203/782] Loss_D: 0.5996 Loss_G: 2.0360\n",
      "[11/25][204/782] Loss_D: 0.6155 Loss_G: 3.2540\n",
      "[11/25][205/782] Loss_D: 0.7475 Loss_G: 1.4984\n",
      "[11/25][206/782] Loss_D: 0.6352 Loss_G: 3.1054\n",
      "[11/25][207/782] Loss_D: 0.4277 Loss_G: 2.5923\n",
      "[11/25][208/782] Loss_D: 0.4299 Loss_G: 2.1219\n",
      "[11/25][209/782] Loss_D: 0.3683 Loss_G: 3.3273\n",
      "[11/25][210/782] Loss_D: 0.4659 Loss_G: 2.9435\n",
      "[11/25][211/782] Loss_D: 0.5389 Loss_G: 1.4211\n",
      "[11/25][212/782] Loss_D: 0.7180 Loss_G: 3.6021\n",
      "[11/25][213/782] Loss_D: 0.3191 Loss_G: 3.4789\n",
      "[11/25][214/782] Loss_D: 0.4915 Loss_G: 1.5924\n",
      "[11/25][215/782] Loss_D: 0.5408 Loss_G: 3.6608\n",
      "[11/25][216/782] Loss_D: 0.4263 Loss_G: 2.6563\n",
      "[11/25][217/782] Loss_D: 0.2839 Loss_G: 2.9651\n",
      "[11/25][218/782] Loss_D: 0.6282 Loss_G: 4.1958\n",
      "[11/25][219/782] Loss_D: 0.7767 Loss_G: 1.5794\n",
      "[11/25][220/782] Loss_D: 0.7328 Loss_G: 5.2111\n",
      "[11/25][221/782] Loss_D: 0.5764 Loss_G: 2.3524\n",
      "[11/25][222/782] Loss_D: 0.6252 Loss_G: 3.5638\n",
      "[11/25][223/782] Loss_D: 0.2578 Loss_G: 3.2058\n",
      "[11/25][224/782] Loss_D: 0.3804 Loss_G: 2.0275\n",
      "[11/25][225/782] Loss_D: 0.6448 Loss_G: 4.2187\n",
      "[11/25][226/782] Loss_D: 0.3804 Loss_G: 3.3832\n",
      "[11/25][227/782] Loss_D: 0.3808 Loss_G: 2.0782\n",
      "[11/25][228/782] Loss_D: 0.3727 Loss_G: 3.4600\n",
      "[11/25][229/782] Loss_D: 0.2483 Loss_G: 4.1325\n",
      "[11/25][230/782] Loss_D: 0.3892 Loss_G: 2.6686\n",
      "[11/25][231/782] Loss_D: 0.3358 Loss_G: 3.5639\n",
      "[11/25][232/782] Loss_D: 0.1656 Loss_G: 4.0570\n",
      "[11/25][233/782] Loss_D: 0.2657 Loss_G: 5.1031\n",
      "[11/25][234/782] Loss_D: 0.2225 Loss_G: 5.6022\n",
      "[11/25][235/782] Loss_D: 0.2194 Loss_G: 4.6422\n",
      "[11/25][236/782] Loss_D: 0.0982 Loss_G: 6.5684\n",
      "[11/25][237/782] Loss_D: 0.0163 Loss_G: 5.1108\n",
      "[11/25][238/782] Loss_D: 0.0175 Loss_G: 4.9678\n",
      "[11/25][239/782] Loss_D: 0.2786 Loss_G: 5.9523\n",
      "[11/25][240/782] Loss_D: 0.1785 Loss_G: 6.1362\n",
      "[11/25][241/782] Loss_D: 0.1194 Loss_G: 3.9987\n",
      "[11/25][242/782] Loss_D: 0.0495 Loss_G: 4.7960\n",
      "[11/25][243/782] Loss_D: 0.0964 Loss_G: 4.4195\n",
      "[11/25][244/782] Loss_D: 0.0266 Loss_G: 7.5003\n",
      "[11/25][245/782] Loss_D: 0.0348 Loss_G: 4.9033\n",
      "[11/25][246/782] Loss_D: 0.0272 Loss_G: 4.9567\n",
      "[11/25][247/782] Loss_D: 0.0452 Loss_G: 4.5770\n",
      "[11/25][248/782] Loss_D: 0.0430 Loss_G: 4.6119\n",
      "[11/25][249/782] Loss_D: 0.0362 Loss_G: 4.5443\n",
      "[11/25][250/782] Loss_D: 0.1987 Loss_G: 6.7555\n",
      "[11/25][251/782] Loss_D: 0.3199 Loss_G: 4.7964\n",
      "[11/25][252/782] Loss_D: 0.1333 Loss_G: 4.1668\n",
      "[11/25][253/782] Loss_D: 0.1567 Loss_G: 3.0619\n",
      "[11/25][254/782] Loss_D: 0.4006 Loss_G: 7.4232\n",
      "[11/25][255/782] Loss_D: 1.5547 Loss_G: 5.2106\n",
      "[11/25][256/782] Loss_D: 1.6277 Loss_G: 0.0046\n",
      "[11/25][257/782] Loss_D: 5.9442 Loss_G: 6.0928\n",
      "[11/25][258/782] Loss_D: 2.3225 Loss_G: 0.9394\n",
      "[11/25][259/782] Loss_D: 1.0218 Loss_G: 3.5726\n",
      "[11/25][260/782] Loss_D: 0.9386 Loss_G: 2.6262\n",
      "[11/25][261/782] Loss_D: 0.9639 Loss_G: 1.6528\n",
      "[11/25][262/782] Loss_D: 1.1155 Loss_G: 3.8178\n",
      "[11/25][263/782] Loss_D: 0.4560 Loss_G: 3.1560\n",
      "[11/25][264/782] Loss_D: 0.6347 Loss_G: 2.0083\n",
      "[11/25][265/782] Loss_D: 0.8666 Loss_G: 4.0541\n",
      "[11/25][266/782] Loss_D: 0.9358 Loss_G: 1.4630\n",
      "[11/25][267/782] Loss_D: 0.9966 Loss_G: 3.8597\n",
      "[11/25][268/782] Loss_D: 0.7768 Loss_G: 2.3808\n",
      "[11/25][269/782] Loss_D: 0.9239 Loss_G: 3.0183\n",
      "[11/25][270/782] Loss_D: 0.6594 Loss_G: 2.0829\n",
      "[11/25][271/782] Loss_D: 0.6316 Loss_G: 3.8505\n",
      "[11/25][272/782] Loss_D: 0.4781 Loss_G: 2.9401\n",
      "[11/25][273/782] Loss_D: 0.5418 Loss_G: 1.9667\n",
      "[11/25][274/782] Loss_D: 0.9340 Loss_G: 4.8563\n",
      "[11/25][275/782] Loss_D: 0.8928 Loss_G: 2.6354\n",
      "[11/25][276/782] Loss_D: 0.3430 Loss_G: 1.9935\n",
      "[11/25][277/782] Loss_D: 1.3973 Loss_G: 6.3548\n",
      "[11/25][278/782] Loss_D: 1.8302 Loss_G: 2.3201\n",
      "[11/25][279/782] Loss_D: 0.8178 Loss_G: 2.2584\n",
      "[11/25][280/782] Loss_D: 0.8226 Loss_G: 5.6348\n",
      "[11/25][281/782] Loss_D: 1.4915 Loss_G: 3.0559\n",
      "[11/25][282/782] Loss_D: 0.7618 Loss_G: 3.5568\n",
      "[11/25][283/782] Loss_D: 0.5177 Loss_G: 2.6756\n",
      "[11/25][284/782] Loss_D: 0.4849 Loss_G: 3.8258\n",
      "[11/25][285/782] Loss_D: 0.8726 Loss_G: 5.3884\n",
      "[11/25][286/782] Loss_D: 1.0438 Loss_G: 2.5070\n",
      "[11/25][287/782] Loss_D: 0.1798 Loss_G: 2.8468\n",
      "[11/25][288/782] Loss_D: 0.1186 Loss_G: 3.9325\n",
      "[11/25][289/782] Loss_D: 0.7108 Loss_G: 7.2232\n",
      "[11/25][290/782] Loss_D: 1.8587 Loss_G: 2.1759\n",
      "[11/25][291/782] Loss_D: 1.0012 Loss_G: 6.6771\n",
      "[11/25][292/782] Loss_D: 1.0215 Loss_G: 2.1217\n",
      "[11/25][293/782] Loss_D: 1.3826 Loss_G: 6.3718\n",
      "[11/25][294/782] Loss_D: 0.7240 Loss_G: 5.2998\n",
      "[11/25][295/782] Loss_D: 0.5253 Loss_G: 1.7005\n",
      "[11/25][296/782] Loss_D: 0.3476 Loss_G: 4.3329\n",
      "[11/25][297/782] Loss_D: 0.5218 Loss_G: 5.8823\n",
      "[11/25][298/782] Loss_D: 0.7950 Loss_G: 2.4679\n",
      "[11/25][299/782] Loss_D: 0.1449 Loss_G: 3.2952\n",
      "[11/25][300/782] Loss_D: 0.1157 Loss_G: 4.0743\n",
      "[11/25][301/782] Loss_D: 0.6189 Loss_G: 6.7758\n",
      "[11/25][302/782] Loss_D: 1.6136 Loss_G: 4.1346\n",
      "[11/25][303/782] Loss_D: 0.4394 Loss_G: 4.9143\n",
      "[11/25][304/782] Loss_D: 0.4288 Loss_G: 2.6828\n",
      "[11/25][305/782] Loss_D: 0.9930 Loss_G: 7.0376\n",
      "[11/25][306/782] Loss_D: 2.3819 Loss_G: 2.7569\n",
      "[11/25][307/782] Loss_D: 0.7651 Loss_G: 5.2594\n",
      "[11/25][308/782] Loss_D: 1.1664 Loss_G: 2.1972\n",
      "[11/25][309/782] Loss_D: 0.9759 Loss_G: 6.4316\n",
      "[11/25][310/782] Loss_D: 0.5079 Loss_G: 2.6760\n",
      "[11/25][311/782] Loss_D: 0.5434 Loss_G: 4.4099\n",
      "[11/25][312/782] Loss_D: 0.2154 Loss_G: 4.0347\n",
      "[11/25][313/782] Loss_D: 0.1674 Loss_G: 3.4182\n",
      "[11/25][314/782] Loss_D: 0.1010 Loss_G: 3.8512\n",
      "[11/25][315/782] Loss_D: 0.6634 Loss_G: 6.4751\n",
      "[11/25][316/782] Loss_D: 1.0574 Loss_G: 4.7910\n",
      "[11/25][317/782] Loss_D: 0.0659 Loss_G: 2.6823\n",
      "[11/25][318/782] Loss_D: 0.9006 Loss_G: 6.1447\n",
      "[11/25][319/782] Loss_D: 1.9182 Loss_G: 1.7502\n",
      "[11/25][320/782] Loss_D: 1.2896 Loss_G: 5.5364\n",
      "[11/25][321/782] Loss_D: 2.3317 Loss_G: 1.0928\n",
      "[11/25][322/782] Loss_D: 1.6956 Loss_G: 3.5698\n",
      "[11/25][323/782] Loss_D: 0.4970 Loss_G: 3.6804\n",
      "[11/25][324/782] Loss_D: 0.3261 Loss_G: 3.2363\n",
      "[11/25][325/782] Loss_D: 0.2348 Loss_G: 3.4247\n",
      "[11/25][326/782] Loss_D: 0.4000 Loss_G: 3.8034\n",
      "[11/25][327/782] Loss_D: 0.9071 Loss_G: 2.3273\n",
      "[11/25][328/782] Loss_D: 0.8004 Loss_G: 5.9044\n",
      "[11/25][329/782] Loss_D: 2.8238 Loss_G: 1.3129\n",
      "[11/25][330/782] Loss_D: 0.8814 Loss_G: 4.7276\n",
      "[11/25][331/782] Loss_D: 0.5506 Loss_G: 2.8649\n",
      "[11/25][332/782] Loss_D: 0.2467 Loss_G: 2.6184\n",
      "[11/25][333/782] Loss_D: 0.1885 Loss_G: 3.1097\n",
      "[11/25][334/782] Loss_D: 0.4456 Loss_G: 3.6474\n",
      "[11/25][335/782] Loss_D: 0.3224 Loss_G: 3.7341\n",
      "[11/25][336/782] Loss_D: 0.0939 Loss_G: 4.4929\n",
      "[11/25][337/782] Loss_D: 0.1655 Loss_G: 3.4318\n",
      "[11/25][338/782] Loss_D: 0.1398 Loss_G: 3.8185\n",
      "[11/25][339/782] Loss_D: 0.0691 Loss_G: 4.2144\n",
      "[11/25][340/782] Loss_D: 0.0965 Loss_G: 4.0153\n",
      "[11/25][341/782] Loss_D: 0.0412 Loss_G: 4.6543\n",
      "[11/25][342/782] Loss_D: 0.0544 Loss_G: 4.2402\n",
      "[11/25][343/782] Loss_D: 0.0673 Loss_G: 4.1528\n",
      "[11/25][344/782] Loss_D: 0.0979 Loss_G: 4.3495\n",
      "[11/25][345/782] Loss_D: 0.0889 Loss_G: 4.2915\n",
      "[11/25][346/782] Loss_D: 0.1783 Loss_G: 4.4533\n",
      "[11/25][347/782] Loss_D: 0.2732 Loss_G: 3.2024\n",
      "[11/25][348/782] Loss_D: 0.0712 Loss_G: 3.8448\n",
      "[11/25][349/782] Loss_D: 0.1712 Loss_G: 5.0684\n",
      "[11/25][350/782] Loss_D: 0.0541 Loss_G: 5.1340\n",
      "[11/25][351/782] Loss_D: 0.1586 Loss_G: 3.5054\n",
      "[11/25][352/782] Loss_D: 0.0518 Loss_G: 3.8075\n",
      "[11/25][353/782] Loss_D: 0.0894 Loss_G: 4.4549\n",
      "[11/25][354/782] Loss_D: 0.0215 Loss_G: 5.7727\n",
      "[11/25][355/782] Loss_D: 0.0409 Loss_G: 5.1264\n",
      "[11/25][356/782] Loss_D: 0.0195 Loss_G: 5.1665\n",
      "[11/25][357/782] Loss_D: 0.0762 Loss_G: 4.4172\n",
      "[11/25][358/782] Loss_D: 0.0565 Loss_G: 5.0820\n",
      "[11/25][359/782] Loss_D: 0.0976 Loss_G: 4.4363\n",
      "[11/25][360/782] Loss_D: 0.0322 Loss_G: 6.0933\n",
      "[11/25][361/782] Loss_D: 0.0867 Loss_G: 4.0642\n",
      "[11/25][362/782] Loss_D: 0.0153 Loss_G: 6.5733\n",
      "[11/25][363/782] Loss_D: 0.0594 Loss_G: 4.4964\n",
      "[11/25][364/782] Loss_D: 0.0375 Loss_G: 4.6221\n",
      "[11/25][365/782] Loss_D: 0.0403 Loss_G: 4.5021\n",
      "[11/25][366/782] Loss_D: 0.0288 Loss_G: 4.9672\n",
      "[11/25][367/782] Loss_D: 0.1157 Loss_G: 5.0420\n",
      "[11/25][368/782] Loss_D: 0.0943 Loss_G: 4.5197\n",
      "[11/25][369/782] Loss_D: 0.0986 Loss_G: 5.1058\n",
      "[11/25][370/782] Loss_D: 0.0290 Loss_G: 4.8933\n",
      "[11/25][371/782] Loss_D: 0.1443 Loss_G: 5.4211\n",
      "[11/25][372/782] Loss_D: 0.0669 Loss_G: 4.7286\n",
      "[11/25][373/782] Loss_D: 0.1006 Loss_G: 4.8433\n",
      "[11/25][374/782] Loss_D: 0.0403 Loss_G: 4.2705\n",
      "[11/25][375/782] Loss_D: 0.0274 Loss_G: 4.6552\n",
      "[11/25][376/782] Loss_D: 0.0958 Loss_G: 4.6624\n",
      "[11/25][377/782] Loss_D: 0.0187 Loss_G: 6.3698\n",
      "[11/25][378/782] Loss_D: 0.0998 Loss_G: 5.8758\n",
      "[11/25][379/782] Loss_D: 0.0721 Loss_G: 4.3117\n",
      "[11/25][380/782] Loss_D: 0.0286 Loss_G: 5.6864\n",
      "[11/25][381/782] Loss_D: 0.1120 Loss_G: 4.7439\n",
      "[11/25][382/782] Loss_D: 0.1063 Loss_G: 5.2147\n",
      "[11/25][383/782] Loss_D: 0.0442 Loss_G: 4.4078\n",
      "[11/25][384/782] Loss_D: 0.0223 Loss_G: 6.3540\n",
      "[11/25][385/782] Loss_D: 0.0580 Loss_G: 4.2966\n",
      "[11/25][386/782] Loss_D: 0.0326 Loss_G: 4.4760\n",
      "[11/25][387/782] Loss_D: 0.0512 Loss_G: 4.9704\n",
      "[11/25][388/782] Loss_D: 0.1509 Loss_G: 5.2441\n",
      "[11/25][389/782] Loss_D: 0.1363 Loss_G: 7.9070\n",
      "[11/25][390/782] Loss_D: 0.1231 Loss_G: 6.2437\n",
      "[11/25][391/782] Loss_D: 0.0662 Loss_G: 5.5514\n",
      "[11/25][392/782] Loss_D: 0.0235 Loss_G: 4.8320\n",
      "[11/25][393/782] Loss_D: 0.0422 Loss_G: 4.9379\n",
      "[11/25][394/782] Loss_D: 0.0198 Loss_G: 5.2386\n",
      "[11/25][395/782] Loss_D: 0.0544 Loss_G: 4.7387\n",
      "[11/25][396/782] Loss_D: 0.0281 Loss_G: 4.9724\n",
      "[11/25][397/782] Loss_D: 0.0256 Loss_G: 5.0794\n",
      "[11/25][398/782] Loss_D: 0.0260 Loss_G: 5.0518\n",
      "[11/25][399/782] Loss_D: 0.0375 Loss_G: 4.9134\n",
      "[11/25][400/782] Loss_D: 0.0256 Loss_G: 4.9129\n",
      "[11/25][401/782] Loss_D: 0.0051 Loss_G: 7.1292\n",
      "[11/25][402/782] Loss_D: 0.5450 Loss_G: 9.7867\n",
      "[11/25][403/782] Loss_D: 4.7410 Loss_G: 5.4563\n",
      "[11/25][404/782] Loss_D: 2.2853 Loss_G: 0.0977\n",
      "[11/25][405/782] Loss_D: 2.8801 Loss_G: 3.1460\n",
      "[11/25][406/782] Loss_D: 0.6071 Loss_G: 4.7023\n",
      "[11/25][407/782] Loss_D: 0.8805 Loss_G: 2.8726\n",
      "[11/25][408/782] Loss_D: 0.2643 Loss_G: 2.1771\n",
      "[11/25][409/782] Loss_D: 0.2821 Loss_G: 3.4129\n",
      "[11/25][410/782] Loss_D: 0.3332 Loss_G: 3.2718\n",
      "[11/25][411/782] Loss_D: 0.2515 Loss_G: 3.3505\n",
      "[11/25][412/782] Loss_D: 0.5727 Loss_G: 3.6974\n",
      "[11/25][413/782] Loss_D: 0.4278 Loss_G: 2.8703\n",
      "[11/25][414/782] Loss_D: 0.3193 Loss_G: 3.2167\n",
      "[11/25][415/782] Loss_D: 2.2674 Loss_G: 8.1359\n",
      "[11/25][416/782] Loss_D: 2.9410 Loss_G: 3.4697\n",
      "[11/25][417/782] Loss_D: 0.5472 Loss_G: 1.1928\n",
      "[11/25][418/782] Loss_D: 0.7213 Loss_G: 3.4090\n",
      "[11/25][419/782] Loss_D: 0.6142 Loss_G: 5.9496\n",
      "[11/25][420/782] Loss_D: 1.5090 Loss_G: 3.3333\n",
      "[11/25][421/782] Loss_D: 0.2595 Loss_G: 2.5473\n",
      "[11/25][422/782] Loss_D: 0.8961 Loss_G: 4.5990\n",
      "[11/25][423/782] Loss_D: 0.4996 Loss_G: 5.1404\n",
      "[11/25][424/782] Loss_D: 0.3008 Loss_G: 3.3621\n",
      "[11/25][425/782] Loss_D: 0.4874 Loss_G: 3.3197\n",
      "[11/25][426/782] Loss_D: 0.2087 Loss_G: 3.5982\n",
      "[11/25][427/782] Loss_D: 0.2704 Loss_G: 3.2887\n",
      "[11/25][428/782] Loss_D: 0.1829 Loss_G: 3.7446\n",
      "[11/25][429/782] Loss_D: 0.4236 Loss_G: 3.1777\n",
      "[11/25][430/782] Loss_D: 0.2361 Loss_G: 3.9111\n",
      "[11/25][431/782] Loss_D: 0.2686 Loss_G: 2.8558\n",
      "[11/25][432/782] Loss_D: 0.8608 Loss_G: 3.6557\n",
      "[11/25][433/782] Loss_D: 0.9303 Loss_G: 2.1620\n",
      "[11/25][434/782] Loss_D: 0.4710 Loss_G: 2.6392\n",
      "[11/25][435/782] Loss_D: 0.3890 Loss_G: 3.3664\n",
      "[11/25][436/782] Loss_D: 0.3701 Loss_G: 2.9124\n",
      "[11/25][437/782] Loss_D: 0.2625 Loss_G: 2.9460\n",
      "[11/25][438/782] Loss_D: 0.1312 Loss_G: 3.2915\n",
      "[11/25][439/782] Loss_D: 0.1034 Loss_G: 3.8333\n",
      "[11/25][440/782] Loss_D: 0.3553 Loss_G: 4.4088\n",
      "[11/25][441/782] Loss_D: 0.2683 Loss_G: 3.4564\n",
      "[11/25][442/782] Loss_D: 0.1455 Loss_G: 3.7928\n",
      "[11/25][443/782] Loss_D: 0.0663 Loss_G: 4.6490\n",
      "[11/25][444/782] Loss_D: 0.1039 Loss_G: 4.1078\n",
      "[11/25][445/782] Loss_D: 0.0680 Loss_G: 4.2361\n",
      "[11/25][446/782] Loss_D: 0.2264 Loss_G: 6.2354\n",
      "[11/25][447/782] Loss_D: 0.5556 Loss_G: 3.9724\n",
      "[11/25][448/782] Loss_D: 0.1377 Loss_G: 5.0918\n",
      "[11/25][449/782] Loss_D: 0.0521 Loss_G: 5.8424\n",
      "[11/25][450/782] Loss_D: 0.0994 Loss_G: 3.8286\n",
      "[11/25][451/782] Loss_D: 0.1465 Loss_G: 4.9918\n",
      "[11/25][452/782] Loss_D: 0.4798 Loss_G: 7.4362\n",
      "[11/25][453/782] Loss_D: 0.4994 Loss_G: 5.3345\n",
      "[11/25][454/782] Loss_D: 0.3020 Loss_G: 5.6218\n",
      "[11/25][455/782] Loss_D: 0.0459 Loss_G: 5.9663\n",
      "[11/25][456/782] Loss_D: 0.1193 Loss_G: 3.8708\n",
      "[11/25][457/782] Loss_D: 0.0312 Loss_G: 5.5056\n",
      "[11/25][458/782] Loss_D: 0.1303 Loss_G: 5.1631\n",
      "[11/25][459/782] Loss_D: 0.0964 Loss_G: 5.8211\n",
      "[11/25][460/782] Loss_D: 0.1173 Loss_G: 4.5376\n",
      "[11/25][461/782] Loss_D: 0.0089 Loss_G: 6.4617\n",
      "[11/25][462/782] Loss_D: 0.0205 Loss_G: 5.3636\n",
      "[11/25][463/782] Loss_D: 0.0401 Loss_G: 4.6782\n",
      "[11/25][464/782] Loss_D: 0.1079 Loss_G: 4.6442\n",
      "[11/25][465/782] Loss_D: 0.0835 Loss_G: 4.3682\n",
      "[11/25][466/782] Loss_D: 0.0543 Loss_G: 4.5333\n",
      "[11/25][467/782] Loss_D: 0.0333 Loss_G: 4.8129\n",
      "[11/25][468/782] Loss_D: 0.0322 Loss_G: 5.6989\n",
      "[11/25][469/782] Loss_D: 0.0338 Loss_G: 4.3808\n",
      "[11/25][470/782] Loss_D: 0.0243 Loss_G: 5.1469\n",
      "[11/25][471/782] Loss_D: 0.0990 Loss_G: 4.3045\n",
      "[11/25][472/782] Loss_D: 0.0415 Loss_G: 4.8664\n",
      "[11/25][473/782] Loss_D: 0.0355 Loss_G: 6.4648\n",
      "[11/25][474/782] Loss_D: 0.0659 Loss_G: 4.0663\n",
      "[11/25][475/782] Loss_D: 0.0210 Loss_G: 5.3237\n",
      "[11/25][476/782] Loss_D: 0.1157 Loss_G: 4.1910\n",
      "[11/25][477/782] Loss_D: 0.0334 Loss_G: 5.4475\n",
      "[11/25][478/782] Loss_D: 0.1012 Loss_G: 3.9203\n",
      "[11/25][479/782] Loss_D: 0.0145 Loss_G: 4.9286\n",
      "[11/25][480/782] Loss_D: 0.0223 Loss_G: 4.5320\n",
      "[11/25][481/782] Loss_D: 0.1157 Loss_G: 5.9391\n",
      "[11/25][482/782] Loss_D: 0.0516 Loss_G: 5.5889\n",
      "[11/25][483/782] Loss_D: 0.0462 Loss_G: 4.6424\n",
      "[11/25][484/782] Loss_D: 0.0111 Loss_G: 5.8429\n",
      "[11/25][485/782] Loss_D: 0.0231 Loss_G: 5.2669\n",
      "[11/25][486/782] Loss_D: 0.0562 Loss_G: 4.4915\n",
      "[11/25][487/782] Loss_D: 0.0192 Loss_G: 5.5210\n",
      "[11/25][488/782] Loss_D: 0.0370 Loss_G: 4.8906\n",
      "[11/25][489/782] Loss_D: 0.1044 Loss_G: 3.9014\n",
      "[11/25][490/782] Loss_D: 0.0325 Loss_G: 4.5848\n",
      "[11/25][491/782] Loss_D: 0.0251 Loss_G: 5.9091\n",
      "[11/25][492/782] Loss_D: 0.0353 Loss_G: 4.4733\n",
      "[11/25][493/782] Loss_D: 0.0263 Loss_G: 4.7760\n",
      "[11/25][494/782] Loss_D: 0.0752 Loss_G: 4.7007\n",
      "[11/25][495/782] Loss_D: 0.0551 Loss_G: 4.8995\n",
      "[11/25][496/782] Loss_D: 0.0310 Loss_G: 5.4446\n",
      "[11/25][497/782] Loss_D: 0.0254 Loss_G: 7.1954\n",
      "[11/25][498/782] Loss_D: 0.0338 Loss_G: 4.5445\n",
      "[11/25][499/782] Loss_D: 0.0049 Loss_G: 8.4355\n",
      "[11/25][500/782] Loss_D: 0.0493 Loss_G: 6.1735\n",
      "[11/25][501/782] Loss_D: 0.0999 Loss_G: 4.9022\n",
      "[11/25][502/782] Loss_D: 0.0273 Loss_G: 6.0640\n",
      "[11/25][503/782] Loss_D: 0.0419 Loss_G: 5.3469\n",
      "[11/25][504/782] Loss_D: 0.0520 Loss_G: 4.5181\n",
      "[11/25][505/782] Loss_D: 0.0159 Loss_G: 6.9148\n",
      "[11/25][506/782] Loss_D: 0.1100 Loss_G: 5.2558\n",
      "[11/25][507/782] Loss_D: 0.1452 Loss_G: 7.6487\n",
      "[11/25][508/782] Loss_D: 0.0152 Loss_G: 4.7152\n",
      "[11/25][509/782] Loss_D: 0.0195 Loss_G: 5.2706\n",
      "[11/25][510/782] Loss_D: 0.1085 Loss_G: 5.8851\n",
      "[11/25][511/782] Loss_D: 0.0302 Loss_G: 6.1984\n",
      "[11/25][512/782] Loss_D: 0.0561 Loss_G: 5.0200\n",
      "[11/25][513/782] Loss_D: 0.0339 Loss_G: 4.5744\n",
      "[11/25][514/782] Loss_D: 0.0138 Loss_G: 5.4056\n",
      "[11/25][515/782] Loss_D: 0.0667 Loss_G: 4.8153\n",
      "[11/25][516/782] Loss_D: 0.0114 Loss_G: 6.8510\n",
      "[11/25][517/782] Loss_D: 0.0287 Loss_G: 5.2517\n",
      "[11/25][518/782] Loss_D: 0.0177 Loss_G: 5.8792\n",
      "[11/25][519/782] Loss_D: 0.0143 Loss_G: 5.6062\n",
      "[11/25][520/782] Loss_D: 0.0158 Loss_G: 5.1221\n",
      "[11/25][521/782] Loss_D: 0.0162 Loss_G: 5.3575\n",
      "[11/25][522/782] Loss_D: 0.0098 Loss_G: 5.8946\n",
      "[11/25][523/782] Loss_D: 0.0130 Loss_G: 5.1750\n",
      "[11/25][524/782] Loss_D: 0.0146 Loss_G: 5.3189\n",
      "[11/25][525/782] Loss_D: 0.0507 Loss_G: 4.5382\n",
      "[11/25][526/782] Loss_D: 0.0327 Loss_G: 4.9741\n",
      "[11/25][527/782] Loss_D: 0.0333 Loss_G: 6.1416\n",
      "[11/25][528/782] Loss_D: 0.0253 Loss_G: 4.8741\n",
      "[11/25][529/782] Loss_D: 0.0179 Loss_G: 7.8536\n",
      "[11/25][530/782] Loss_D: 0.0322 Loss_G: 4.5525\n",
      "[11/25][531/782] Loss_D: 0.0110 Loss_G: 5.6331\n",
      "[11/25][532/782] Loss_D: 0.0109 Loss_G: 5.7204\n",
      "[11/25][533/782] Loss_D: 0.0123 Loss_G: 5.4153\n",
      "[11/25][534/782] Loss_D: 0.0689 Loss_G: 5.1489\n",
      "[11/25][535/782] Loss_D: 0.0380 Loss_G: 6.4184\n",
      "[11/25][536/782] Loss_D: 0.0298 Loss_G: 6.7273\n",
      "[11/25][537/782] Loss_D: 0.0480 Loss_G: 4.5092\n",
      "[11/25][538/782] Loss_D: 0.0186 Loss_G: 4.6877\n",
      "[11/25][539/782] Loss_D: 0.0038 Loss_G: 7.1152\n",
      "[11/25][540/782] Loss_D: 0.0374 Loss_G: 4.7600\n",
      "[11/25][541/782] Loss_D: 0.0024 Loss_G: 8.5679\n",
      "[11/25][542/782] Loss_D: 0.0099 Loss_G: 6.8078\n",
      "[11/25][543/782] Loss_D: 0.0567 Loss_G: 4.9352\n",
      "[11/25][544/782] Loss_D: 0.0071 Loss_G: 8.4951\n",
      "[11/25][545/782] Loss_D: 0.1027 Loss_G: 3.9940\n",
      "[11/25][546/782] Loss_D: 0.0031 Loss_G: 8.2958\n",
      "[11/25][547/782] Loss_D: 0.0061 Loss_G: 6.0526\n",
      "[11/25][548/782] Loss_D: 0.0615 Loss_G: 6.1735\n",
      "[11/25][549/782] Loss_D: 0.0122 Loss_G: 7.0927\n",
      "[11/25][550/782] Loss_D: 0.0477 Loss_G: 4.6702\n",
      "[11/25][551/782] Loss_D: 0.0117 Loss_G: 7.9797\n",
      "[11/25][552/782] Loss_D: 0.0455 Loss_G: 4.6572\n",
      "[11/25][553/782] Loss_D: 0.0746 Loss_G: 7.2862\n",
      "[11/25][554/782] Loss_D: 0.0401 Loss_G: 4.1713\n",
      "[11/25][555/782] Loss_D: 0.0074 Loss_G: 6.1300\n",
      "[11/25][556/782] Loss_D: 0.0190 Loss_G: 5.4385\n",
      "[11/25][557/782] Loss_D: 0.0116 Loss_G: 7.9696\n",
      "[11/25][558/782] Loss_D: 0.0380 Loss_G: 4.9280\n",
      "[11/25][559/782] Loss_D: 0.0153 Loss_G: 7.6445\n",
      "[11/25][560/782] Loss_D: 0.0165 Loss_G: 5.1279\n",
      "[11/25][561/782] Loss_D: 0.0085 Loss_G: 5.7963\n",
      "[11/25][562/782] Loss_D: 0.0435 Loss_G: 5.0174\n",
      "[11/25][563/782] Loss_D: 0.0153 Loss_G: 6.1802\n",
      "[11/25][564/782] Loss_D: 0.0154 Loss_G: 5.7630\n",
      "[11/25][565/782] Loss_D: 0.0107 Loss_G: 7.1945\n",
      "[11/25][566/782] Loss_D: 0.1067 Loss_G: 5.8572\n",
      "[11/25][567/782] Loss_D: 0.1962 Loss_G: 6.1755\n",
      "[11/25][568/782] Loss_D: 0.0224 Loss_G: 4.6540\n",
      "[11/25][569/782] Loss_D: 0.0248 Loss_G: 6.8244\n",
      "[11/25][570/782] Loss_D: 0.1201 Loss_G: 7.5706\n",
      "[11/25][571/782] Loss_D: 0.0877 Loss_G: 6.5457\n",
      "[11/25][572/782] Loss_D: 0.1459 Loss_G: 7.2709\n",
      "[11/25][573/782] Loss_D: 0.0224 Loss_G: 6.8921\n",
      "[11/25][574/782] Loss_D: 0.0837 Loss_G: 6.4049\n",
      "[11/25][575/782] Loss_D: 0.2153 Loss_G: 9.7559\n",
      "[11/25][576/782] Loss_D: 0.2645 Loss_G: 5.1325\n",
      "[11/25][577/782] Loss_D: 0.1255 Loss_G: 6.8782\n",
      "[11/25][578/782] Loss_D: 1.8868 Loss_G: 5.0559\n",
      "[11/25][579/782] Loss_D: 0.1216 Loss_G: 2.7117\n",
      "[11/25][580/782] Loss_D: 0.4270 Loss_G: 1.8520\n",
      "[11/25][581/782] Loss_D: 0.5661 Loss_G: 3.3119\n",
      "[11/25][582/782] Loss_D: 0.6204 Loss_G: 0.9522\n",
      "[11/25][583/782] Loss_D: 1.3002 Loss_G: 7.4062\n",
      "[11/25][584/782] Loss_D: 1.6753 Loss_G: 3.5973\n",
      "[11/25][585/782] Loss_D: 0.1922 Loss_G: 2.1053\n",
      "[11/25][586/782] Loss_D: 0.7300 Loss_G: 3.9650\n",
      "[11/25][587/782] Loss_D: 0.2825 Loss_G: 3.9634\n",
      "[11/25][588/782] Loss_D: 0.4943 Loss_G: 2.2124\n",
      "[11/25][589/782] Loss_D: 0.3114 Loss_G: 3.0621\n",
      "[11/25][590/782] Loss_D: 0.2596 Loss_G: 4.0639\n",
      "[11/25][591/782] Loss_D: 0.3261 Loss_G: 3.2350\n",
      "[11/25][592/782] Loss_D: 0.3150 Loss_G: 3.5156\n",
      "[11/25][593/782] Loss_D: 0.2443 Loss_G: 3.5926\n",
      "[11/25][594/782] Loss_D: 0.4121 Loss_G: 2.6662\n",
      "[11/25][595/782] Loss_D: 0.5258 Loss_G: 5.1356\n",
      "[11/25][596/782] Loss_D: 0.5205 Loss_G: 3.1413\n",
      "[11/25][597/782] Loss_D: 0.4297 Loss_G: 2.5968\n",
      "[11/25][598/782] Loss_D: 0.4868 Loss_G: 4.5835\n",
      "[11/25][599/782] Loss_D: 0.2717 Loss_G: 3.5572\n",
      "[11/25][600/782] Loss_D: 0.2070 Loss_G: 3.1295\n",
      "[11/25][601/782] Loss_D: 0.3058 Loss_G: 3.2231\n",
      "[11/25][602/782] Loss_D: 0.5251 Loss_G: 2.1260\n",
      "[11/25][603/782] Loss_D: 1.2394 Loss_G: 7.2447\n",
      "[11/25][604/782] Loss_D: 0.7179 Loss_G: 3.4426\n",
      "[11/25][605/782] Loss_D: 0.2379 Loss_G: 2.6495\n",
      "[11/25][606/782] Loss_D: 0.1869 Loss_G: 3.0484\n",
      "[11/25][607/782] Loss_D: 0.5075 Loss_G: 5.1479\n",
      "[11/25][608/782] Loss_D: 0.3239 Loss_G: 4.1260\n",
      "[11/25][609/782] Loss_D: 0.2411 Loss_G: 3.0382\n",
      "[11/25][610/782] Loss_D: 0.2843 Loss_G: 2.7497\n",
      "[11/25][611/782] Loss_D: 0.3610 Loss_G: 3.6506\n",
      "[11/25][612/782] Loss_D: 0.2637 Loss_G: 3.6444\n",
      "[11/25][613/782] Loss_D: 0.2524 Loss_G: 2.9420\n",
      "[11/25][614/782] Loss_D: 0.2772 Loss_G: 3.0446\n",
      "[11/25][615/782] Loss_D: 0.2715 Loss_G: 3.3519\n",
      "[11/25][616/782] Loss_D: 0.3565 Loss_G: 3.5737\n",
      "[11/25][617/782] Loss_D: 0.4820 Loss_G: 1.9131\n",
      "[11/25][618/782] Loss_D: 0.2738 Loss_G: 3.2048\n",
      "[11/25][619/782] Loss_D: 0.3018 Loss_G: 3.8554\n",
      "[11/25][620/782] Loss_D: 0.3704 Loss_G: 2.5314\n",
      "[11/25][621/782] Loss_D: 0.5784 Loss_G: 5.1832\n",
      "[11/25][622/782] Loss_D: 0.4485 Loss_G: 3.8728\n",
      "[11/25][623/782] Loss_D: 0.2584 Loss_G: 1.9854\n",
      "[11/25][624/782] Loss_D: 0.5953 Loss_G: 4.8010\n",
      "[11/25][625/782] Loss_D: 0.3941 Loss_G: 4.7480\n",
      "[11/25][626/782] Loss_D: 0.2550 Loss_G: 3.6870\n",
      "[11/25][627/782] Loss_D: 0.2037 Loss_G: 4.3922\n",
      "[11/25][628/782] Loss_D: 0.2719 Loss_G: 3.5873\n",
      "[11/25][629/782] Loss_D: 0.0866 Loss_G: 4.4504\n",
      "[11/25][630/782] Loss_D: 0.2363 Loss_G: 3.8187\n",
      "[11/25][631/782] Loss_D: 0.0843 Loss_G: 5.4367\n",
      "[11/25][632/782] Loss_D: 0.3625 Loss_G: 4.7538\n",
      "[11/25][633/782] Loss_D: 0.4930 Loss_G: 2.8197\n",
      "[11/25][634/782] Loss_D: 1.5807 Loss_G: 8.6444\n",
      "[11/25][635/782] Loss_D: 2.6169 Loss_G: 2.1176\n",
      "[11/25][636/782] Loss_D: 0.2314 Loss_G: 1.4924\n",
      "[11/25][637/782] Loss_D: 1.1635 Loss_G: 5.1420\n",
      "[11/25][638/782] Loss_D: 0.7368 Loss_G: 2.9570\n",
      "[11/25][639/782] Loss_D: 0.2634 Loss_G: 2.6586\n",
      "[11/25][640/782] Loss_D: 0.2414 Loss_G: 3.2539\n",
      "[11/25][641/782] Loss_D: 0.4723 Loss_G: 4.1440\n",
      "[11/25][642/782] Loss_D: 0.2848 Loss_G: 4.0553\n",
      "[11/25][643/782] Loss_D: 0.1084 Loss_G: 3.9487\n",
      "[11/25][644/782] Loss_D: 0.1819 Loss_G: 3.7693\n",
      "[11/25][645/782] Loss_D: 0.0822 Loss_G: 4.2658\n",
      "[11/25][646/782] Loss_D: 0.2569 Loss_G: 4.3297\n",
      "[11/25][647/782] Loss_D: 0.1015 Loss_G: 5.2882\n",
      "[11/25][648/782] Loss_D: 0.0788 Loss_G: 3.9661\n",
      "[11/25][649/782] Loss_D: 0.1808 Loss_G: 4.1838\n",
      "[11/25][650/782] Loss_D: 0.1177 Loss_G: 4.5785\n",
      "[11/25][651/782] Loss_D: 0.0726 Loss_G: 4.8194\n",
      "[11/25][652/782] Loss_D: 0.0990 Loss_G: 4.3149\n",
      "[11/25][653/782] Loss_D: 0.0874 Loss_G: 4.0458\n",
      "[11/25][654/782] Loss_D: 0.2311 Loss_G: 5.7423\n",
      "[11/25][655/782] Loss_D: 0.3648 Loss_G: 3.6327\n",
      "[11/25][656/782] Loss_D: 0.6661 Loss_G: 9.7024\n",
      "[11/25][657/782] Loss_D: 3.1559 Loss_G: 2.2815\n",
      "[11/25][658/782] Loss_D: 0.9634 Loss_G: 6.4887\n",
      "[11/25][659/782] Loss_D: 1.4954 Loss_G: 2.5136\n",
      "[11/25][660/782] Loss_D: 0.5653 Loss_G: 5.3964\n",
      "[11/25][661/782] Loss_D: 0.6689 Loss_G: 1.4416\n",
      "[11/25][662/782] Loss_D: 1.2271 Loss_G: 6.6063\n",
      "[11/25][663/782] Loss_D: 1.2582 Loss_G: 2.6433\n",
      "[11/25][664/782] Loss_D: 1.1791 Loss_G: 6.1695\n",
      "[11/25][665/782] Loss_D: 1.1739 Loss_G: 4.0216\n",
      "[11/25][666/782] Loss_D: 0.1633 Loss_G: 3.6651\n",
      "[11/25][667/782] Loss_D: 0.2851 Loss_G: 4.0632\n",
      "[11/25][668/782] Loss_D: 0.3985 Loss_G: 2.9834\n",
      "[11/25][669/782] Loss_D: 0.5533 Loss_G: 4.0515\n",
      "[11/25][670/782] Loss_D: 0.2473 Loss_G: 4.2020\n",
      "[11/25][671/782] Loss_D: 0.2046 Loss_G: 4.1059\n",
      "[11/25][672/782] Loss_D: 0.0767 Loss_G: 4.5759\n",
      "[11/25][673/782] Loss_D: 0.1211 Loss_G: 4.2134\n",
      "[11/25][674/782] Loss_D: 0.1867 Loss_G: 5.0063\n",
      "[11/25][675/782] Loss_D: 0.4372 Loss_G: 1.1973\n",
      "[11/25][676/782] Loss_D: 1.0022 Loss_G: 9.9641\n",
      "[11/25][677/782] Loss_D: 4.9065 Loss_G: 4.0139\n",
      "[11/25][678/782] Loss_D: 0.2549 Loss_G: 1.7777\n",
      "[11/25][679/782] Loss_D: 0.9221 Loss_G: 5.9357\n",
      "[11/25][680/782] Loss_D: 1.1776 Loss_G: 2.4565\n",
      "[11/25][681/782] Loss_D: 0.6638 Loss_G: 2.7135\n",
      "[11/25][682/782] Loss_D: 0.3532 Loss_G: 4.3619\n",
      "[11/25][683/782] Loss_D: 0.1696 Loss_G: 3.8562\n",
      "[11/25][684/782] Loss_D: 0.4493 Loss_G: 2.4340\n",
      "[11/25][685/782] Loss_D: 0.6385 Loss_G: 5.3639\n",
      "[11/25][686/782] Loss_D: 1.2623 Loss_G: 3.9364\n",
      "[11/25][687/782] Loss_D: 0.5833 Loss_G: 4.4348\n",
      "[11/25][688/782] Loss_D: 0.3919 Loss_G: 3.5026\n",
      "[11/25][689/782] Loss_D: 0.1333 Loss_G: 3.5544\n",
      "[11/25][690/782] Loss_D: 0.4720 Loss_G: 4.0404\n",
      "[11/25][691/782] Loss_D: 0.2593 Loss_G: 4.0105\n",
      "[11/25][692/782] Loss_D: 0.1845 Loss_G: 3.1689\n",
      "[11/25][693/782] Loss_D: 0.2380 Loss_G: 3.3476\n",
      "[11/25][694/782] Loss_D: 0.2243 Loss_G: 3.6683\n",
      "[11/25][695/782] Loss_D: 0.2558 Loss_G: 3.1068\n",
      "[11/25][696/782] Loss_D: 0.2585 Loss_G: 3.2589\n",
      "[11/25][697/782] Loss_D: 0.1327 Loss_G: 3.6348\n",
      "[11/25][698/782] Loss_D: 0.1771 Loss_G: 3.9091\n",
      "[11/25][699/782] Loss_D: 0.2190 Loss_G: 2.9976\n",
      "[11/25][700/782] Loss_D: 0.3433 Loss_G: 4.7670\n",
      "[11/25][701/782] Loss_D: 0.2788 Loss_G: 3.2703\n",
      "[11/25][702/782] Loss_D: 0.1639 Loss_G: 3.7706\n",
      "[11/25][703/782] Loss_D: 0.1193 Loss_G: 4.1481\n",
      "[11/25][704/782] Loss_D: 0.2128 Loss_G: 3.1750\n",
      "[11/25][705/782] Loss_D: 0.1118 Loss_G: 3.6868\n",
      "[11/25][706/782] Loss_D: 0.0804 Loss_G: 4.2181\n",
      "[11/25][707/782] Loss_D: 0.2101 Loss_G: 3.4801\n",
      "[11/25][708/782] Loss_D: 0.1038 Loss_G: 3.8349\n",
      "[11/25][709/782] Loss_D: 0.1092 Loss_G: 4.3211\n",
      "[11/25][710/782] Loss_D: 0.0614 Loss_G: 4.5157\n",
      "[11/25][711/782] Loss_D: 0.0779 Loss_G: 3.9206\n",
      "[11/25][712/782] Loss_D: 0.1507 Loss_G: 4.7412\n",
      "[11/25][713/782] Loss_D: 0.1937 Loss_G: 4.3134\n",
      "[11/25][714/782] Loss_D: 0.0370 Loss_G: 4.0869\n",
      "[11/25][715/782] Loss_D: 0.1066 Loss_G: 4.8481\n",
      "[11/25][716/782] Loss_D: 0.0838 Loss_G: 4.9628\n",
      "[11/25][717/782] Loss_D: 0.0780 Loss_G: 4.8688\n",
      "[11/25][718/782] Loss_D: 0.0684 Loss_G: 4.1394\n",
      "[11/25][719/782] Loss_D: 0.0122 Loss_G: 5.3374\n",
      "[11/25][720/782] Loss_D: 0.1658 Loss_G: 6.0400\n",
      "[11/25][721/782] Loss_D: 0.1041 Loss_G: 4.5820\n",
      "[11/25][722/782] Loss_D: 0.0438 Loss_G: 4.4756\n",
      "[11/25][723/782] Loss_D: 0.0288 Loss_G: 4.8487\n",
      "[11/25][724/782] Loss_D: 0.0366 Loss_G: 4.8028\n",
      "[11/25][725/782] Loss_D: 0.0598 Loss_G: 5.6093\n",
      "[11/25][726/782] Loss_D: 0.0638 Loss_G: 4.8171\n",
      "[11/25][727/782] Loss_D: 0.0421 Loss_G: 5.2345\n",
      "[11/25][728/782] Loss_D: 0.0477 Loss_G: 4.7994\n",
      "[11/25][729/782] Loss_D: 0.0510 Loss_G: 6.1160\n",
      "[11/25][730/782] Loss_D: 0.0398 Loss_G: 5.6305\n",
      "[11/25][731/782] Loss_D: 0.0380 Loss_G: 4.5962\n",
      "[11/25][732/782] Loss_D: 0.0692 Loss_G: 5.0475\n",
      "[11/25][733/782] Loss_D: 0.0247 Loss_G: 5.2460\n",
      "[11/25][734/782] Loss_D: 0.0481 Loss_G: 5.1226\n",
      "[11/25][735/782] Loss_D: 0.0310 Loss_G: 5.1409\n",
      "[11/25][736/782] Loss_D: 0.0170 Loss_G: 6.8859\n",
      "[11/25][737/782] Loss_D: 0.2390 Loss_G: 3.0669\n",
      "[11/25][738/782] Loss_D: 0.0178 Loss_G: 4.7167\n",
      "[11/25][739/782] Loss_D: 0.0167 Loss_G: 5.6252\n",
      "[11/25][740/782] Loss_D: 0.0133 Loss_G: 6.0109\n",
      "[11/25][741/782] Loss_D: 0.0179 Loss_G: 5.6146\n",
      "[11/25][742/782] Loss_D: 0.1242 Loss_G: 7.0482\n",
      "[11/25][743/782] Loss_D: 0.2426 Loss_G: 4.3878\n",
      "[11/25][744/782] Loss_D: 0.0391 Loss_G: 5.5723\n",
      "[11/25][745/782] Loss_D: 0.2049 Loss_G: 4.3468\n",
      "[11/25][746/782] Loss_D: 1.4889 Loss_G: 12.5943\n",
      "[11/25][747/782] Loss_D: 8.8924 Loss_G: 5.8052\n",
      "[11/25][748/782] Loss_D: 2.6299 Loss_G: 0.0449\n",
      "[11/25][749/782] Loss_D: 4.1525 Loss_G: 0.8261\n",
      "[11/25][750/782] Loss_D: 1.2591 Loss_G: 5.3595\n",
      "[11/25][751/782] Loss_D: 2.1173 Loss_G: 2.3457\n",
      "[11/25][752/782] Loss_D: 0.7259 Loss_G: 0.9822\n",
      "[11/25][753/782] Loss_D: 0.8192 Loss_G: 2.6054\n",
      "[11/25][754/782] Loss_D: 0.6317 Loss_G: 3.0135\n",
      "[11/25][755/782] Loss_D: 0.9250 Loss_G: 1.9903\n",
      "[11/25][756/782] Loss_D: 0.6518 Loss_G: 2.3143\n",
      "[11/25][757/782] Loss_D: 0.5186 Loss_G: 2.9432\n",
      "[11/25][758/782] Loss_D: 0.6395 Loss_G: 2.1526\n",
      "[11/25][759/782] Loss_D: 0.5575 Loss_G: 2.5824\n",
      "[11/25][760/782] Loss_D: 0.4089 Loss_G: 2.8399\n",
      "[11/25][761/782] Loss_D: 0.3690 Loss_G: 2.4681\n",
      "[11/25][762/782] Loss_D: 0.5475 Loss_G: 2.9330\n",
      "[11/25][763/782] Loss_D: 0.4682 Loss_G: 2.6211\n",
      "[11/25][764/782] Loss_D: 0.5648 Loss_G: 2.4869\n",
      "[11/25][765/782] Loss_D: 0.5959 Loss_G: 1.7972\n",
      "[11/25][766/782] Loss_D: 0.5395 Loss_G: 3.4041\n",
      "[11/25][767/782] Loss_D: 0.6019 Loss_G: 2.4734\n",
      "[11/25][768/782] Loss_D: 0.5221 Loss_G: 1.6935\n",
      "[11/25][769/782] Loss_D: 0.5425 Loss_G: 4.8518\n",
      "[11/25][770/782] Loss_D: 0.4858 Loss_G: 3.4438\n",
      "[11/25][771/782] Loss_D: 0.3622 Loss_G: 2.2281\n",
      "[11/25][772/782] Loss_D: 0.5306 Loss_G: 5.0723\n",
      "[11/25][773/782] Loss_D: 0.6988 Loss_G: 2.1356\n",
      "[11/25][774/782] Loss_D: 0.4575 Loss_G: 3.6896\n",
      "[11/25][775/782] Loss_D: 0.3208 Loss_G: 3.2529\n",
      "[11/25][776/782] Loss_D: 0.2507 Loss_G: 4.0625\n",
      "[11/25][777/782] Loss_D: 0.3434 Loss_G: 3.0508\n",
      "[11/25][778/782] Loss_D: 0.1537 Loss_G: 3.9550\n",
      "[11/25][779/782] Loss_D: 0.1140 Loss_G: 4.3208\n",
      "[11/25][780/782] Loss_D: 0.1761 Loss_G: 4.3670\n",
      "[11/25][781/782] Loss_D: 0.0998 Loss_G: 3.7823\n",
      "[12/25][0/782] Loss_D: 0.1612 Loss_G: 4.2905\n",
      "[12/25][1/782] Loss_D: 0.0595 Loss_G: 4.6912\n",
      "[12/25][2/782] Loss_D: 0.1495 Loss_G: 4.1522\n",
      "[12/25][3/782] Loss_D: 0.0635 Loss_G: 4.7000\n",
      "[12/25][4/782] Loss_D: 0.0491 Loss_G: 4.8334\n",
      "[12/25][5/782] Loss_D: 0.1252 Loss_G: 4.0072\n",
      "[12/25][6/782] Loss_D: 0.2934 Loss_G: 1.8992\n",
      "[12/25][7/782] Loss_D: 0.6968 Loss_G: 8.3724\n",
      "[12/25][8/782] Loss_D: 2.8406 Loss_G: 3.0681\n",
      "[12/25][9/782] Loss_D: 1.1232 Loss_G: 0.4464\n",
      "[12/25][10/782] Loss_D: 1.3605 Loss_G: 7.4999\n",
      "[12/25][11/782] Loss_D: 3.7440 Loss_G: 1.0886\n",
      "[12/25][12/782] Loss_D: 0.9514 Loss_G: 2.3269\n",
      "[12/25][13/782] Loss_D: 0.6862 Loss_G: 4.0010\n",
      "[12/25][14/782] Loss_D: 0.6694 Loss_G: 2.7948\n",
      "[12/25][15/782] Loss_D: 0.4280 Loss_G: 2.0186\n",
      "[12/25][16/782] Loss_D: 0.5001 Loss_G: 3.0411\n",
      "[12/25][17/782] Loss_D: 0.5962 Loss_G: 3.2810\n",
      "[12/25][18/782] Loss_D: 0.3481 Loss_G: 2.8629\n",
      "[12/25][19/782] Loss_D: 0.3500 Loss_G: 2.4663\n",
      "[12/25][20/782] Loss_D: 0.4644 Loss_G: 3.0877\n",
      "[12/25][21/782] Loss_D: 0.3524 Loss_G: 3.5823\n",
      "[12/25][22/782] Loss_D: 0.4467 Loss_G: 2.4471\n",
      "[12/25][23/782] Loss_D: 0.3812 Loss_G: 2.8304\n",
      "[12/25][24/782] Loss_D: 0.4213 Loss_G: 3.5234\n",
      "[12/25][25/782] Loss_D: 0.5772 Loss_G: 2.1229\n",
      "[12/25][26/782] Loss_D: 0.7064 Loss_G: 5.1018\n",
      "[12/25][27/782] Loss_D: 1.2324 Loss_G: 0.9272\n",
      "[12/25][28/782] Loss_D: 1.3972 Loss_G: 6.0990\n",
      "[12/25][29/782] Loss_D: 0.4662 Loss_G: 4.0786\n",
      "[12/25][30/782] Loss_D: 0.1329 Loss_G: 3.1893\n",
      "[12/25][31/782] Loss_D: 0.3045 Loss_G: 4.5822\n",
      "[12/25][32/782] Loss_D: 0.3415 Loss_G: 3.8876\n",
      "[12/25][33/782] Loss_D: 0.4486 Loss_G: 3.2837\n",
      "[12/25][34/782] Loss_D: 0.4680 Loss_G: 3.2925\n",
      "[12/25][35/782] Loss_D: 0.3034 Loss_G: 4.6892\n",
      "[12/25][36/782] Loss_D: 0.3138 Loss_G: 2.8113\n",
      "[12/25][37/782] Loss_D: 0.5746 Loss_G: 8.5668\n",
      "[12/25][38/782] Loss_D: 1.4834 Loss_G: 1.5806\n",
      "[12/25][39/782] Loss_D: 1.2832 Loss_G: 8.4851\n",
      "[12/25][40/782] Loss_D: 5.4010 Loss_G: 1.4582\n",
      "[12/25][41/782] Loss_D: 0.8746 Loss_G: 2.7544\n",
      "[12/25][42/782] Loss_D: 0.6473 Loss_G: 3.3087\n",
      "[12/25][43/782] Loss_D: 0.9408 Loss_G: 1.4004\n",
      "[12/25][44/782] Loss_D: 1.1480 Loss_G: 5.0016\n",
      "[12/25][45/782] Loss_D: 2.3598 Loss_G: 0.4101\n",
      "[12/25][46/782] Loss_D: 1.9118 Loss_G: 5.4320\n",
      "[12/25][47/782] Loss_D: 0.2628 Loss_G: 5.2480\n",
      "[12/25][48/782] Loss_D: 0.4726 Loss_G: 1.9789\n",
      "[12/25][49/782] Loss_D: 0.9807 Loss_G: 4.5700\n",
      "[12/25][50/782] Loss_D: 0.5072 Loss_G: 3.3259\n",
      "[12/25][51/782] Loss_D: 0.4788 Loss_G: 2.6656\n",
      "[12/25][52/782] Loss_D: 0.3704 Loss_G: 4.2675\n",
      "[12/25][53/782] Loss_D: 0.5362 Loss_G: 2.1976\n",
      "[12/25][54/782] Loss_D: 0.6268 Loss_G: 6.6513\n",
      "[12/25][55/782] Loss_D: 0.8153 Loss_G: 2.5218\n",
      "[12/25][56/782] Loss_D: 0.3377 Loss_G: 4.6972\n",
      "[12/25][57/782] Loss_D: 0.1631 Loss_G: 4.3162\n",
      "[12/25][58/782] Loss_D: 0.5594 Loss_G: 2.0642\n",
      "[12/25][59/782] Loss_D: 0.7761 Loss_G: 6.2015\n",
      "[12/25][60/782] Loss_D: 1.1665 Loss_G: 1.6660\n",
      "[12/25][61/782] Loss_D: 0.7255 Loss_G: 5.1023\n",
      "[12/25][62/782] Loss_D: 0.3347 Loss_G: 3.0619\n",
      "[12/25][63/782] Loss_D: 0.2570 Loss_G: 3.2680\n",
      "[12/25][64/782] Loss_D: 0.1813 Loss_G: 4.3235\n",
      "[12/25][65/782] Loss_D: 0.2469 Loss_G: 3.4557\n",
      "[12/25][66/782] Loss_D: 0.2221 Loss_G: 4.6373\n",
      "[12/25][67/782] Loss_D: 0.1267 Loss_G: 4.4085\n",
      "[12/25][68/782] Loss_D: 0.1819 Loss_G: 3.3687\n",
      "[12/25][69/782] Loss_D: 0.3320 Loss_G: 5.9159\n",
      "[12/25][70/782] Loss_D: 0.1214 Loss_G: 6.5977\n",
      "[12/25][71/782] Loss_D: 0.0940 Loss_G: 4.2844\n",
      "[12/25][72/782] Loss_D: 0.0652 Loss_G: 3.5820\n",
      "[12/25][73/782] Loss_D: 0.0582 Loss_G: 4.1943\n",
      "[12/25][74/782] Loss_D: 0.1172 Loss_G: 4.4632\n",
      "[12/25][75/782] Loss_D: 0.0361 Loss_G: 5.0333\n",
      "[12/25][76/782] Loss_D: 0.1285 Loss_G: 3.9952\n",
      "[12/25][77/782] Loss_D: 0.0671 Loss_G: 3.6247\n",
      "[12/25][78/782] Loss_D: 0.1371 Loss_G: 4.7323\n",
      "[12/25][79/782] Loss_D: 0.0566 Loss_G: 5.1448\n",
      "[12/25][80/782] Loss_D: 0.0798 Loss_G: 5.0018\n",
      "[12/25][81/782] Loss_D: 0.0821 Loss_G: 4.1826\n",
      "[12/25][82/782] Loss_D: 0.0799 Loss_G: 4.4993\n",
      "[12/25][83/782] Loss_D: 0.0463 Loss_G: 4.8622\n",
      "[12/25][84/782] Loss_D: 0.0237 Loss_G: 4.9940\n",
      "[12/25][85/782] Loss_D: 0.0706 Loss_G: 4.9033\n",
      "[12/25][86/782] Loss_D: 0.0625 Loss_G: 4.6290\n",
      "[12/25][87/782] Loss_D: 0.0678 Loss_G: 4.4583\n",
      "[12/25][88/782] Loss_D: 0.0623 Loss_G: 4.4179\n",
      "[12/25][89/782] Loss_D: 0.0504 Loss_G: 4.5625\n",
      "[12/25][90/782] Loss_D: 0.0199 Loss_G: 5.5413\n",
      "[12/25][91/782] Loss_D: 0.1062 Loss_G: 4.8546\n",
      "[12/25][92/782] Loss_D: 0.0336 Loss_G: 5.5613\n",
      "[12/25][93/782] Loss_D: 0.1389 Loss_G: 4.0608\n",
      "[12/25][94/782] Loss_D: 0.0262 Loss_G: 4.4825\n",
      "[12/25][95/782] Loss_D: 0.0148 Loss_G: 4.8948\n",
      "[12/25][96/782] Loss_D: 0.2653 Loss_G: 7.8947\n",
      "[12/25][97/782] Loss_D: 0.5212 Loss_G: 6.9374\n",
      "[12/25][98/782] Loss_D: 3.1652 Loss_G: 0.3341\n",
      "[12/25][99/782] Loss_D: 2.6559 Loss_G: 8.3691\n",
      "[12/25][100/782] Loss_D: 5.2479 Loss_G: 1.8288\n",
      "[12/25][101/782] Loss_D: 1.4692 Loss_G: 0.0710\n",
      "[12/25][102/782] Loss_D: 4.0574 Loss_G: 1.9847\n",
      "[12/25][103/782] Loss_D: 1.2162 Loss_G: 3.2387\n",
      "[12/25][104/782] Loss_D: 1.9219 Loss_G: 0.8159\n",
      "[12/25][105/782] Loss_D: 1.1110 Loss_G: 2.3958\n",
      "[12/25][106/782] Loss_D: 1.0621 Loss_G: 1.6721\n",
      "[12/25][107/782] Loss_D: 0.8585 Loss_G: 1.3940\n",
      "[12/25][108/782] Loss_D: 1.0907 Loss_G: 2.4585\n",
      "[12/25][109/782] Loss_D: 1.0937 Loss_G: 1.2581\n",
      "[12/25][110/782] Loss_D: 1.1639 Loss_G: 1.4313\n",
      "[12/25][111/782] Loss_D: 0.8999 Loss_G: 2.3146\n",
      "[12/25][112/782] Loss_D: 1.0276 Loss_G: 1.3954\n",
      "[12/25][113/782] Loss_D: 0.7669 Loss_G: 1.5493\n",
      "[12/25][114/782] Loss_D: 0.8616 Loss_G: 1.8317\n",
      "[12/25][115/782] Loss_D: 1.0794 Loss_G: 1.3402\n",
      "[12/25][116/782] Loss_D: 1.2549 Loss_G: 1.4863\n",
      "[12/25][117/782] Loss_D: 0.9829 Loss_G: 1.4879\n",
      "[12/25][118/782] Loss_D: 0.9727 Loss_G: 1.5347\n",
      "[12/25][119/782] Loss_D: 1.0967 Loss_G: 2.5565\n",
      "[12/25][120/782] Loss_D: 1.1693 Loss_G: 0.9982\n",
      "[12/25][121/782] Loss_D: 1.1533 Loss_G: 1.6193\n",
      "[12/25][122/782] Loss_D: 1.0284 Loss_G: 1.5340\n",
      "[12/25][123/782] Loss_D: 0.7575 Loss_G: 2.0700\n",
      "[12/25][124/782] Loss_D: 0.9275 Loss_G: 1.8126\n",
      "[12/25][125/782] Loss_D: 0.9552 Loss_G: 1.4734\n",
      "[12/25][126/782] Loss_D: 0.8458 Loss_G: 1.7103\n",
      "[12/25][127/782] Loss_D: 0.8447 Loss_G: 2.0754\n",
      "[12/25][128/782] Loss_D: 1.2429 Loss_G: 0.8521\n",
      "[12/25][129/782] Loss_D: 1.3979 Loss_G: 2.7940\n",
      "[12/25][130/782] Loss_D: 1.3675 Loss_G: 0.8223\n",
      "[12/25][131/782] Loss_D: 1.1829 Loss_G: 1.8898\n",
      "[12/25][132/782] Loss_D: 0.9710 Loss_G: 2.0009\n",
      "[12/25][133/782] Loss_D: 0.9901 Loss_G: 1.2123\n",
      "[12/25][134/782] Loss_D: 0.9136 Loss_G: 1.3428\n",
      "[12/25][135/782] Loss_D: 1.0757 Loss_G: 2.3455\n",
      "[12/25][136/782] Loss_D: 0.8421 Loss_G: 2.0076\n",
      "[12/25][137/782] Loss_D: 0.8852 Loss_G: 1.2235\n",
      "[12/25][138/782] Loss_D: 1.2865 Loss_G: 2.5875\n",
      "[12/25][139/782] Loss_D: 1.3025 Loss_G: 0.7480\n",
      "[12/25][140/782] Loss_D: 1.2947 Loss_G: 2.8046\n",
      "[12/25][141/782] Loss_D: 1.0171 Loss_G: 1.7538\n",
      "[12/25][142/782] Loss_D: 0.9943 Loss_G: 1.3636\n",
      "[12/25][143/782] Loss_D: 0.9745 Loss_G: 2.8179\n",
      "[12/25][144/782] Loss_D: 1.4630 Loss_G: 0.6145\n",
      "[12/25][145/782] Loss_D: 1.6910 Loss_G: 2.6069\n",
      "[12/25][146/782] Loss_D: 0.9949 Loss_G: 2.1071\n",
      "[12/25][147/782] Loss_D: 0.8440 Loss_G: 1.4028\n",
      "[12/25][148/782] Loss_D: 1.0519 Loss_G: 1.7693\n",
      "[12/25][149/782] Loss_D: 0.9965 Loss_G: 2.4463\n",
      "[12/25][150/782] Loss_D: 0.6670 Loss_G: 2.1956\n",
      "[12/25][151/782] Loss_D: 0.9741 Loss_G: 1.5195\n",
      "[12/25][152/782] Loss_D: 0.7996 Loss_G: 2.2298\n",
      "[12/25][153/782] Loss_D: 1.0550 Loss_G: 0.8452\n",
      "[12/25][154/782] Loss_D: 1.2875 Loss_G: 3.0676\n",
      "[12/25][155/782] Loss_D: 0.9087 Loss_G: 2.1203\n",
      "[12/25][156/782] Loss_D: 1.2985 Loss_G: 0.9533\n",
      "[12/25][157/782] Loss_D: 1.2354 Loss_G: 2.0745\n",
      "[12/25][158/782] Loss_D: 1.2234 Loss_G: 1.0009\n",
      "[12/25][159/782] Loss_D: 1.2910 Loss_G: 2.3188\n",
      "[12/25][160/782] Loss_D: 1.7070 Loss_G: 0.6283\n",
      "[12/25][161/782] Loss_D: 1.5342 Loss_G: 2.6942\n",
      "[12/25][162/782] Loss_D: 1.1600 Loss_G: 1.9060\n",
      "[12/25][163/782] Loss_D: 0.9312 Loss_G: 1.2784\n",
      "[12/25][164/782] Loss_D: 0.9910 Loss_G: 1.9680\n",
      "[12/25][165/782] Loss_D: 0.9915 Loss_G: 2.0772\n",
      "[12/25][166/782] Loss_D: 0.9240 Loss_G: 2.0851\n",
      "[12/25][167/782] Loss_D: 0.7857 Loss_G: 1.9961\n",
      "[12/25][168/782] Loss_D: 0.9447 Loss_G: 0.8806\n",
      "[12/25][169/782] Loss_D: 1.0939 Loss_G: 3.4495\n",
      "[12/25][170/782] Loss_D: 0.9325 Loss_G: 1.8927\n",
      "[12/25][171/782] Loss_D: 0.8790 Loss_G: 0.8269\n",
      "[12/25][172/782] Loss_D: 1.0332 Loss_G: 3.9849\n",
      "[12/25][173/782] Loss_D: 1.0114 Loss_G: 1.7055\n",
      "[12/25][174/782] Loss_D: 0.8237 Loss_G: 1.3877\n",
      "[12/25][175/782] Loss_D: 0.9668 Loss_G: 2.8690\n",
      "[12/25][176/782] Loss_D: 0.7612 Loss_G: 1.7257\n",
      "[12/25][177/782] Loss_D: 0.8645 Loss_G: 2.6628\n",
      "[12/25][178/782] Loss_D: 1.0376 Loss_G: 1.4792\n",
      "[12/25][179/782] Loss_D: 1.3129 Loss_G: 1.7144\n",
      "[12/25][180/782] Loss_D: 1.1072 Loss_G: 1.5441\n",
      "[12/25][181/782] Loss_D: 0.9990 Loss_G: 1.4825\n",
      "[12/25][182/782] Loss_D: 1.0758 Loss_G: 2.2404\n",
      "[12/25][183/782] Loss_D: 0.7430 Loss_G: 2.0910\n",
      "[12/25][184/782] Loss_D: 0.9227 Loss_G: 1.5688\n",
      "[12/25][185/782] Loss_D: 1.1058 Loss_G: 1.8170\n",
      "[12/25][186/782] Loss_D: 0.9266 Loss_G: 2.0767\n",
      "[12/25][187/782] Loss_D: 1.0598 Loss_G: 1.4479\n",
      "[12/25][188/782] Loss_D: 1.0169 Loss_G: 2.0403\n",
      "[12/25][189/782] Loss_D: 0.9993 Loss_G: 1.4192\n",
      "[12/25][190/782] Loss_D: 0.9880 Loss_G: 2.2489\n",
      "[12/25][191/782] Loss_D: 1.1728 Loss_G: 1.7097\n",
      "[12/25][192/782] Loss_D: 1.0129 Loss_G: 1.1244\n",
      "[12/25][193/782] Loss_D: 1.1248 Loss_G: 3.3253\n",
      "[12/25][194/782] Loss_D: 1.4378 Loss_G: 0.7347\n",
      "[12/25][195/782] Loss_D: 1.3701 Loss_G: 2.9254\n",
      "[12/25][196/782] Loss_D: 1.3712 Loss_G: 1.2967\n",
      "[12/25][197/782] Loss_D: 0.8109 Loss_G: 1.9944\n",
      "[12/25][198/782] Loss_D: 0.9027 Loss_G: 1.9634\n",
      "[12/25][199/782] Loss_D: 0.8751 Loss_G: 1.5568\n",
      "[12/25][200/782] Loss_D: 1.1967 Loss_G: 1.8753\n",
      "[12/25][201/782] Loss_D: 1.2479 Loss_G: 1.5245\n",
      "[12/25][202/782] Loss_D: 1.0199 Loss_G: 2.4007\n",
      "[12/25][203/782] Loss_D: 1.3355 Loss_G: 1.1684\n",
      "[12/25][204/782] Loss_D: 1.0066 Loss_G: 2.2427\n",
      "[12/25][205/782] Loss_D: 1.0492 Loss_G: 1.5994\n",
      "[12/25][206/782] Loss_D: 0.9139 Loss_G: 1.9340\n",
      "[12/25][207/782] Loss_D: 0.9948 Loss_G: 2.1796\n",
      "[12/25][208/782] Loss_D: 0.6148 Loss_G: 2.4406\n",
      "[12/25][209/782] Loss_D: 0.7325 Loss_G: 1.7460\n",
      "[12/25][210/782] Loss_D: 0.7023 Loss_G: 2.3046\n",
      "[12/25][211/782] Loss_D: 0.6854 Loss_G: 2.0737\n",
      "[12/25][212/782] Loss_D: 0.7923 Loss_G: 2.2613\n",
      "[12/25][213/782] Loss_D: 0.6587 Loss_G: 2.6841\n",
      "[12/25][214/782] Loss_D: 0.9810 Loss_G: 2.0208\n",
      "[12/25][215/782] Loss_D: 0.6821 Loss_G: 1.7030\n",
      "[12/25][216/782] Loss_D: 0.8864 Loss_G: 1.8553\n",
      "[12/25][217/782] Loss_D: 0.6993 Loss_G: 2.3244\n",
      "[12/25][218/782] Loss_D: 0.9309 Loss_G: 2.3263\n",
      "[12/25][219/782] Loss_D: 1.3321 Loss_G: 0.6436\n",
      "[12/25][220/782] Loss_D: 1.4060 Loss_G: 3.8577\n",
      "[12/25][221/782] Loss_D: 1.2550 Loss_G: 1.7322\n",
      "[12/25][222/782] Loss_D: 0.8273 Loss_G: 2.0003\n",
      "[12/25][223/782] Loss_D: 0.6696 Loss_G: 2.0402\n",
      "[12/25][224/782] Loss_D: 0.6202 Loss_G: 1.9253\n",
      "[12/25][225/782] Loss_D: 0.8641 Loss_G: 2.1853\n",
      "[12/25][226/782] Loss_D: 1.0199 Loss_G: 1.5859\n",
      "[12/25][227/782] Loss_D: 0.7873 Loss_G: 2.1425\n",
      "[12/25][228/782] Loss_D: 0.9148 Loss_G: 2.2653\n",
      "[12/25][229/782] Loss_D: 0.9875 Loss_G: 1.4887\n",
      "[12/25][230/782] Loss_D: 0.8106 Loss_G: 2.7497\n",
      "[12/25][231/782] Loss_D: 0.7698 Loss_G: 2.0091\n",
      "[12/25][232/782] Loss_D: 0.7776 Loss_G: 1.5567\n",
      "[12/25][233/782] Loss_D: 1.0176 Loss_G: 2.6936\n",
      "[12/25][234/782] Loss_D: 0.7991 Loss_G: 1.6714\n",
      "[12/25][235/782] Loss_D: 0.8670 Loss_G: 1.4991\n",
      "[12/25][236/782] Loss_D: 0.8600 Loss_G: 3.2117\n",
      "[12/25][237/782] Loss_D: 1.0598 Loss_G: 1.3300\n",
      "[12/25][238/782] Loss_D: 0.8071 Loss_G: 2.2517\n",
      "[12/25][239/782] Loss_D: 0.7770 Loss_G: 2.2564\n",
      "[12/25][240/782] Loss_D: 1.0262 Loss_G: 1.6642\n",
      "[12/25][241/782] Loss_D: 0.7759 Loss_G: 2.1301\n",
      "[12/25][242/782] Loss_D: 0.7226 Loss_G: 2.3455\n",
      "[12/25][243/782] Loss_D: 0.7225 Loss_G: 2.0638\n",
      "[12/25][244/782] Loss_D: 0.8418 Loss_G: 1.8702\n",
      "[12/25][245/782] Loss_D: 1.0188 Loss_G: 1.2021\n",
      "[12/25][246/782] Loss_D: 1.0973 Loss_G: 3.5556\n",
      "[12/25][247/782] Loss_D: 0.8271 Loss_G: 1.9481\n",
      "[12/25][248/782] Loss_D: 0.8302 Loss_G: 1.2560\n",
      "[12/25][249/782] Loss_D: 0.9607 Loss_G: 3.5759\n",
      "[12/25][250/782] Loss_D: 1.1399 Loss_G: 1.2474\n",
      "[12/25][251/782] Loss_D: 0.9920 Loss_G: 2.2795\n",
      "[12/25][252/782] Loss_D: 0.6179 Loss_G: 2.2225\n",
      "[12/25][253/782] Loss_D: 0.7277 Loss_G: 1.9313\n",
      "[12/25][254/782] Loss_D: 0.8507 Loss_G: 2.4177\n",
      "[12/25][255/782] Loss_D: 0.8114 Loss_G: 2.3957\n",
      "[12/25][256/782] Loss_D: 0.8732 Loss_G: 1.2720\n",
      "[12/25][257/782] Loss_D: 1.0805 Loss_G: 2.6407\n",
      "[12/25][258/782] Loss_D: 0.4822 Loss_G: 3.2175\n",
      "[12/25][259/782] Loss_D: 1.1611 Loss_G: 1.0077\n",
      "[12/25][260/782] Loss_D: 1.0142 Loss_G: 2.3712\n",
      "[12/25][261/782] Loss_D: 0.6716 Loss_G: 2.6153\n",
      "[12/25][262/782] Loss_D: 0.6887 Loss_G: 1.9341\n",
      "[12/25][263/782] Loss_D: 0.5957 Loss_G: 2.3542\n",
      "[12/25][264/782] Loss_D: 0.8138 Loss_G: 1.8442\n",
      "[12/25][265/782] Loss_D: 1.1839 Loss_G: 2.5022\n",
      "[12/25][266/782] Loss_D: 0.7674 Loss_G: 2.1070\n",
      "[12/25][267/782] Loss_D: 1.0217 Loss_G: 2.4302\n",
      "[12/25][268/782] Loss_D: 0.7430 Loss_G: 2.1249\n",
      "[12/25][269/782] Loss_D: 0.4830 Loss_G: 2.5320\n",
      "[12/25][270/782] Loss_D: 0.7015 Loss_G: 3.1073\n",
      "[12/25][271/782] Loss_D: 0.7000 Loss_G: 1.5987\n",
      "[12/25][272/782] Loss_D: 0.5361 Loss_G: 3.3884\n",
      "[12/25][273/782] Loss_D: 0.9205 Loss_G: 2.5040\n",
      "[12/25][274/782] Loss_D: 1.0810 Loss_G: 0.8707\n",
      "[12/25][275/782] Loss_D: 1.3851 Loss_G: 3.4098\n",
      "[12/25][276/782] Loss_D: 0.6830 Loss_G: 2.3614\n",
      "[12/25][277/782] Loss_D: 0.9856 Loss_G: 1.5285\n",
      "[12/25][278/782] Loss_D: 0.8164 Loss_G: 2.5395\n",
      "[12/25][279/782] Loss_D: 0.7899 Loss_G: 1.8056\n",
      "[12/25][280/782] Loss_D: 0.6261 Loss_G: 2.3333\n",
      "[12/25][281/782] Loss_D: 0.7196 Loss_G: 1.4866\n",
      "[12/25][282/782] Loss_D: 0.8526 Loss_G: 3.4550\n",
      "[12/25][283/782] Loss_D: 1.0579 Loss_G: 1.2831\n",
      "[12/25][284/782] Loss_D: 0.7515 Loss_G: 2.6160\n",
      "[12/25][285/782] Loss_D: 0.7514 Loss_G: 1.9148\n",
      "[12/25][286/782] Loss_D: 0.7018 Loss_G: 2.5941\n",
      "[12/25][287/782] Loss_D: 0.7684 Loss_G: 2.2660\n",
      "[12/25][288/782] Loss_D: 0.4579 Loss_G: 2.3298\n",
      "[12/25][289/782] Loss_D: 0.6828 Loss_G: 1.8796\n",
      "[12/25][290/782] Loss_D: 0.7877 Loss_G: 2.8841\n",
      "[12/25][291/782] Loss_D: 0.8468 Loss_G: 1.4461\n",
      "[12/25][292/782] Loss_D: 0.8601 Loss_G: 3.1472\n",
      "[12/25][293/782] Loss_D: 0.9859 Loss_G: 1.1550\n",
      "[12/25][294/782] Loss_D: 1.2807 Loss_G: 3.7962\n",
      "[12/25][295/782] Loss_D: 0.7893 Loss_G: 1.8859\n",
      "[12/25][296/782] Loss_D: 0.5742 Loss_G: 2.0538\n",
      "[12/25][297/782] Loss_D: 0.5982 Loss_G: 3.0605\n",
      "[12/25][298/782] Loss_D: 0.5634 Loss_G: 1.9971\n",
      "[12/25][299/782] Loss_D: 0.6289 Loss_G: 2.7567\n",
      "[12/25][300/782] Loss_D: 0.4109 Loss_G: 2.6980\n",
      "[12/25][301/782] Loss_D: 0.5954 Loss_G: 1.5909\n",
      "[12/25][302/782] Loss_D: 0.5870 Loss_G: 3.2871\n",
      "[12/25][303/782] Loss_D: 0.5055 Loss_G: 2.0794\n",
      "[12/25][304/782] Loss_D: 0.6773 Loss_G: 3.8827\n",
      "[12/25][305/782] Loss_D: 0.6425 Loss_G: 1.8890\n",
      "[12/25][306/782] Loss_D: 0.3763 Loss_G: 2.1776\n",
      "[12/25][307/782] Loss_D: 0.5145 Loss_G: 4.2548\n",
      "[12/25][308/782] Loss_D: 0.5347 Loss_G: 1.9385\n",
      "[12/25][309/782] Loss_D: 0.5575 Loss_G: 4.3517\n",
      "[12/25][310/782] Loss_D: 0.3360 Loss_G: 3.3559\n",
      "[12/25][311/782] Loss_D: 0.2995 Loss_G: 2.8861\n",
      "[12/25][312/782] Loss_D: 0.2633 Loss_G: 2.9793\n",
      "[12/25][313/782] Loss_D: 0.2542 Loss_G: 3.7034\n",
      "[12/25][314/782] Loss_D: 0.3561 Loss_G: 4.5052\n",
      "[12/25][315/782] Loss_D: 0.9207 Loss_G: 0.1748\n",
      "[12/25][316/782] Loss_D: 2.7391 Loss_G: 8.5512\n",
      "[12/25][317/782] Loss_D: 4.8537 Loss_G: 1.5435\n",
      "[12/25][318/782] Loss_D: 0.9449 Loss_G: 1.0972\n",
      "[12/25][319/782] Loss_D: 1.3353 Loss_G: 4.3314\n",
      "[12/25][320/782] Loss_D: 2.1106 Loss_G: 0.2587\n",
      "[12/25][321/782] Loss_D: 1.6642 Loss_G: 3.5255\n",
      "[12/25][322/782] Loss_D: 0.8804 Loss_G: 2.8249\n",
      "[12/25][323/782] Loss_D: 0.9734 Loss_G: 1.0226\n",
      "[12/25][324/782] Loss_D: 1.2625 Loss_G: 3.2312\n",
      "[12/25][325/782] Loss_D: 1.0597 Loss_G: 1.9420\n",
      "[12/25][326/782] Loss_D: 0.6072 Loss_G: 3.0849\n",
      "[12/25][327/782] Loss_D: 0.5636 Loss_G: 2.7337\n",
      "[12/25][328/782] Loss_D: 0.7983 Loss_G: 1.4405\n",
      "[12/25][329/782] Loss_D: 0.9520 Loss_G: 3.4054\n",
      "[12/25][330/782] Loss_D: 0.8680 Loss_G: 1.6384\n",
      "[12/25][331/782] Loss_D: 0.8833 Loss_G: 2.9822\n",
      "[12/25][332/782] Loss_D: 0.4867 Loss_G: 2.3511\n",
      "[12/25][333/782] Loss_D: 0.5436 Loss_G: 2.5067\n",
      "[12/25][334/782] Loss_D: 0.5982 Loss_G: 2.0710\n",
      "[12/25][335/782] Loss_D: 0.5795 Loss_G: 3.5189\n",
      "[12/25][336/782] Loss_D: 0.7265 Loss_G: 1.8393\n",
      "[12/25][337/782] Loss_D: 0.7838 Loss_G: 3.1767\n",
      "[12/25][338/782] Loss_D: 0.4687 Loss_G: 2.4182\n",
      "[12/25][339/782] Loss_D: 0.3958 Loss_G: 3.4631\n",
      "[12/25][340/782] Loss_D: 0.3674 Loss_G: 2.7772\n",
      "[12/25][341/782] Loss_D: 0.4083 Loss_G: 4.3664\n",
      "[12/25][342/782] Loss_D: 0.2993 Loss_G: 4.3989\n",
      "[12/25][343/782] Loss_D: 0.3101 Loss_G: 4.9960\n",
      "[12/25][344/782] Loss_D: 0.1647 Loss_G: 4.4010\n",
      "[12/25][345/782] Loss_D: 0.0652 Loss_G: 4.5614\n",
      "[12/25][346/782] Loss_D: 0.1076 Loss_G: 4.0774\n",
      "[12/25][347/782] Loss_D: 0.0525 Loss_G: 4.4255\n",
      "[12/25][348/782] Loss_D: 0.1697 Loss_G: 5.2179\n",
      "[12/25][349/782] Loss_D: 0.1351 Loss_G: 3.9974\n",
      "[12/25][350/782] Loss_D: 0.0391 Loss_G: 4.7688\n",
      "[12/25][351/782] Loss_D: 0.3013 Loss_G: 5.8404\n",
      "[12/25][352/782] Loss_D: 0.4110 Loss_G: 4.6269\n",
      "[12/25][353/782] Loss_D: 0.0547 Loss_G: 4.2584\n",
      "[12/25][354/782] Loss_D: 0.0268 Loss_G: 7.2850\n",
      "[12/25][355/782] Loss_D: 0.0508 Loss_G: 4.4427\n",
      "[12/25][356/782] Loss_D: 0.0136 Loss_G: 4.8405\n",
      "[12/25][357/782] Loss_D: 0.0361 Loss_G: 4.4918\n",
      "[12/25][358/782] Loss_D: 0.9913 Loss_G: 11.1250\n",
      "[12/25][359/782] Loss_D: 6.1775 Loss_G: 4.1902\n",
      "[12/25][360/782] Loss_D: 1.6387 Loss_G: 0.0531\n",
      "[12/25][361/782] Loss_D: 3.2264 Loss_G: 3.7786\n",
      "[12/25][362/782] Loss_D: 0.3877 Loss_G: 5.0757\n",
      "[12/25][363/782] Loss_D: 1.0689 Loss_G: 1.8733\n",
      "[12/25][364/782] Loss_D: 0.4982 Loss_G: 3.0752\n",
      "[12/25][365/782] Loss_D: 0.3309 Loss_G: 4.0376\n",
      "[12/25][366/782] Loss_D: 0.3382 Loss_G: 3.2265\n",
      "[12/25][367/782] Loss_D: 0.2497 Loss_G: 3.3942\n",
      "[12/25][368/782] Loss_D: 0.1702 Loss_G: 3.9751\n",
      "[12/25][369/782] Loss_D: 0.1786 Loss_G: 3.4165\n",
      "[12/25][370/782] Loss_D: 0.0423 Loss_G: 4.0150\n",
      "[12/25][371/782] Loss_D: 0.3348 Loss_G: 4.7096\n",
      "[12/25][372/782] Loss_D: 0.3706 Loss_G: 3.5524\n",
      "[12/25][373/782] Loss_D: 0.3895 Loss_G: 4.6190\n",
      "[12/25][374/782] Loss_D: 0.0886 Loss_G: 4.7333\n",
      "[12/25][375/782] Loss_D: 0.1645 Loss_G: 3.9701\n",
      "[12/25][376/782] Loss_D: 0.0644 Loss_G: 4.4211\n",
      "[12/25][377/782] Loss_D: 0.1731 Loss_G: 4.1058\n",
      "[12/25][378/782] Loss_D: 0.0486 Loss_G: 5.2734\n",
      "[12/25][379/782] Loss_D: 0.1829 Loss_G: 4.2331\n",
      "[12/25][380/782] Loss_D: 0.1213 Loss_G: 4.2457\n",
      "[12/25][381/782] Loss_D: 0.0484 Loss_G: 5.2117\n",
      "[12/25][382/782] Loss_D: 0.0884 Loss_G: 4.3663\n",
      "[12/25][383/782] Loss_D: 0.0274 Loss_G: 5.7999\n",
      "[12/25][384/782] Loss_D: 0.0831 Loss_G: 4.2654\n",
      "[12/25][385/782] Loss_D: 0.0723 Loss_G: 4.1988\n",
      "[12/25][386/782] Loss_D: 0.0327 Loss_G: 4.7084\n",
      "[12/25][387/782] Loss_D: 0.0536 Loss_G: 4.5121\n",
      "[12/25][388/782] Loss_D: 0.0664 Loss_G: 4.3733\n",
      "[12/25][389/782] Loss_D: 0.0950 Loss_G: 4.2506\n",
      "[12/25][390/782] Loss_D: 0.1101 Loss_G: 3.9069\n",
      "[12/25][391/782] Loss_D: 0.0377 Loss_G: 4.4954\n",
      "[12/25][392/782] Loss_D: 0.2156 Loss_G: 4.8692\n",
      "[12/25][393/782] Loss_D: 0.1314 Loss_G: 4.8568\n",
      "[12/25][394/782] Loss_D: 0.0419 Loss_G: 4.2790\n",
      "[12/25][395/782] Loss_D: 0.0178 Loss_G: 5.5704\n",
      "[12/25][396/782] Loss_D: 0.0820 Loss_G: 4.7485\n",
      "[12/25][397/782] Loss_D: 0.0357 Loss_G: 5.6630\n",
      "[12/25][398/782] Loss_D: 0.0971 Loss_G: 4.1305\n",
      "[12/25][399/782] Loss_D: 0.0682 Loss_G: 4.4216\n",
      "[12/25][400/782] Loss_D: 0.0688 Loss_G: 4.0899\n",
      "[12/25][401/782] Loss_D: 0.0491 Loss_G: 5.1669\n",
      "[12/25][402/782] Loss_D: 0.3860 Loss_G: 8.6292\n",
      "[12/25][403/782] Loss_D: 1.9271 Loss_G: 7.1983\n",
      "[12/25][404/782] Loss_D: 4.3877 Loss_G: 0.0053\n",
      "[12/25][405/782] Loss_D: 6.0331 Loss_G: 6.2650\n",
      "[12/25][406/782] Loss_D: 3.4274 Loss_G: 1.4050\n",
      "[12/25][407/782] Loss_D: 1.1423 Loss_G: 1.8238\n",
      "[12/25][408/782] Loss_D: 0.9600 Loss_G: 3.2233\n",
      "[12/25][409/782] Loss_D: 0.9577 Loss_G: 1.7306\n",
      "[12/25][410/782] Loss_D: 0.7925 Loss_G: 2.3827\n",
      "[12/25][411/782] Loss_D: 0.7133 Loss_G: 3.0801\n",
      "[12/25][412/782] Loss_D: 1.0305 Loss_G: 1.3085\n",
      "[12/25][413/782] Loss_D: 0.8111 Loss_G: 2.8000\n",
      "[12/25][414/782] Loss_D: 0.9382 Loss_G: 2.7152\n",
      "[12/25][415/782] Loss_D: 0.7897 Loss_G: 1.8989\n",
      "[12/25][416/782] Loss_D: 0.7984 Loss_G: 2.9790\n",
      "[12/25][417/782] Loss_D: 0.7045 Loss_G: 2.6640\n",
      "[12/25][418/782] Loss_D: 0.9569 Loss_G: 1.0120\n",
      "[12/25][419/782] Loss_D: 1.1922 Loss_G: 4.2327\n",
      "[12/25][420/782] Loss_D: 0.9240 Loss_G: 2.3798\n",
      "[12/25][421/782] Loss_D: 0.8169 Loss_G: 1.5449\n",
      "[12/25][422/782] Loss_D: 0.8000 Loss_G: 2.8139\n",
      "[12/25][423/782] Loss_D: 0.7223 Loss_G: 2.5824\n",
      "[12/25][424/782] Loss_D: 0.9991 Loss_G: 1.3874\n",
      "[12/25][425/782] Loss_D: 1.0041 Loss_G: 3.0089\n",
      "[12/25][426/782] Loss_D: 0.9389 Loss_G: 2.2755\n",
      "[12/25][427/782] Loss_D: 0.6951 Loss_G: 1.9138\n",
      "[12/25][428/782] Loss_D: 0.9561 Loss_G: 2.3162\n",
      "[12/25][429/782] Loss_D: 0.8851 Loss_G: 2.2013\n",
      "[12/25][430/782] Loss_D: 0.7459 Loss_G: 1.7972\n",
      "[12/25][431/782] Loss_D: 1.1220 Loss_G: 2.1310\n",
      "[12/25][432/782] Loss_D: 0.7169 Loss_G: 2.2418\n",
      "[12/25][433/782] Loss_D: 0.5544 Loss_G: 2.7441\n",
      "[12/25][434/782] Loss_D: 0.7122 Loss_G: 3.1120\n",
      "[12/25][435/782] Loss_D: 1.2578 Loss_G: 0.6117\n",
      "[12/25][436/782] Loss_D: 1.5015 Loss_G: 4.1671\n",
      "[12/25][437/782] Loss_D: 0.7617 Loss_G: 2.5959\n",
      "[12/25][438/782] Loss_D: 0.6843 Loss_G: 1.5440\n",
      "[12/25][439/782] Loss_D: 0.8719 Loss_G: 2.9112\n",
      "[12/25][440/782] Loss_D: 0.6957 Loss_G: 2.0185\n",
      "[12/25][441/782] Loss_D: 1.0113 Loss_G: 0.9563\n",
      "[12/25][442/782] Loss_D: 1.1950 Loss_G: 3.9110\n",
      "[12/25][443/782] Loss_D: 0.6289 Loss_G: 2.8784\n",
      "[12/25][444/782] Loss_D: 0.6052 Loss_G: 1.6801\n",
      "[12/25][445/782] Loss_D: 0.7578 Loss_G: 1.7200\n",
      "[12/25][446/782] Loss_D: 0.9179 Loss_G: 3.4832\n",
      "[12/25][447/782] Loss_D: 0.7850 Loss_G: 2.2685\n",
      "[12/25][448/782] Loss_D: 0.8451 Loss_G: 1.7055\n",
      "[12/25][449/782] Loss_D: 0.6590 Loss_G: 3.0069\n",
      "[12/25][450/782] Loss_D: 0.7985 Loss_G: 1.7480\n",
      "[12/25][451/782] Loss_D: 0.8329 Loss_G: 1.9536\n",
      "[12/25][452/782] Loss_D: 0.8920 Loss_G: 3.2260\n",
      "[12/25][453/782] Loss_D: 0.7716 Loss_G: 1.6025\n",
      "[12/25][454/782] Loss_D: 0.8114 Loss_G: 2.7384\n",
      "[12/25][455/782] Loss_D: 0.6352 Loss_G: 2.7122\n",
      "[12/25][456/782] Loss_D: 0.4593 Loss_G: 2.1188\n",
      "[12/25][457/782] Loss_D: 0.6836 Loss_G: 2.3793\n",
      "[12/25][458/782] Loss_D: 0.5356 Loss_G: 3.3269\n",
      "[12/25][459/782] Loss_D: 0.5979 Loss_G: 2.0696\n",
      "[12/25][460/782] Loss_D: 0.4814 Loss_G: 2.0498\n",
      "[12/25][461/782] Loss_D: 0.6063 Loss_G: 2.7686\n",
      "[12/25][462/782] Loss_D: 0.3738 Loss_G: 2.9012\n",
      "[12/25][463/782] Loss_D: 0.6028 Loss_G: 1.8662\n",
      "[12/25][464/782] Loss_D: 0.5427 Loss_G: 2.4175\n",
      "[12/25][465/782] Loss_D: 0.6002 Loss_G: 2.9254\n",
      "[12/25][466/782] Loss_D: 0.6359 Loss_G: 1.9749\n",
      "[12/25][467/782] Loss_D: 0.7098 Loss_G: 3.2382\n",
      "[12/25][468/782] Loss_D: 0.8018 Loss_G: 1.5790\n",
      "[12/25][469/782] Loss_D: 0.6144 Loss_G: 2.9794\n",
      "[12/25][470/782] Loss_D: 0.4375 Loss_G: 2.8933\n",
      "[12/25][471/782] Loss_D: 0.3724 Loss_G: 2.2266\n",
      "[12/25][472/782] Loss_D: 0.4732 Loss_G: 2.5696\n",
      "[12/25][473/782] Loss_D: 0.4174 Loss_G: 2.9817\n",
      "[12/25][474/782] Loss_D: 0.3446 Loss_G: 3.0951\n",
      "[12/25][475/782] Loss_D: 0.3731 Loss_G: 2.1437\n",
      "[12/25][476/782] Loss_D: 0.2866 Loss_G: 3.7506\n",
      "[12/25][477/782] Loss_D: 0.1616 Loss_G: 3.8701\n",
      "[12/25][478/782] Loss_D: 0.3052 Loss_G: 1.9280\n",
      "[12/25][479/782] Loss_D: 0.4778 Loss_G: 6.2290\n",
      "[12/25][480/782] Loss_D: 0.5659 Loss_G: 2.8549\n",
      "[12/25][481/782] Loss_D: 0.2314 Loss_G: 4.1482\n",
      "[12/25][482/782] Loss_D: 0.1641 Loss_G: 4.6151\n",
      "[12/25][483/782] Loss_D: 0.2558 Loss_G: 2.3582\n",
      "[12/25][484/782] Loss_D: 0.1703 Loss_G: 4.0212\n",
      "[12/25][485/782] Loss_D: 0.1998 Loss_G: 5.0845\n",
      "[12/25][486/782] Loss_D: 0.2270 Loss_G: 3.3233\n",
      "[12/25][487/782] Loss_D: 0.0751 Loss_G: 3.9302\n",
      "[12/25][488/782] Loss_D: 0.0683 Loss_G: 4.9627\n",
      "[12/25][489/782] Loss_D: 0.0609 Loss_G: 5.1201\n",
      "[12/25][490/782] Loss_D: 0.1003 Loss_G: 3.9672\n",
      "[12/25][491/782] Loss_D: 0.0460 Loss_G: 5.7256\n",
      "[12/25][492/782] Loss_D: 0.2680 Loss_G: 5.4685\n",
      "[12/25][493/782] Loss_D: 0.2337 Loss_G: 3.9526\n",
      "[12/25][494/782] Loss_D: 0.0734 Loss_G: 3.8999\n",
      "[12/25][495/782] Loss_D: 0.0331 Loss_G: 4.7763\n",
      "[12/25][496/782] Loss_D: 0.2024 Loss_G: 5.4584\n",
      "[12/25][497/782] Loss_D: 0.3403 Loss_G: 3.2395\n",
      "[12/25][498/782] Loss_D: 0.0484 Loss_G: 5.5248\n",
      "[12/25][499/782] Loss_D: 0.2219 Loss_G: 3.0596\n",
      "[12/25][500/782] Loss_D: 2.0262 Loss_G: 10.5412\n",
      "[12/25][501/782] Loss_D: 6.4682 Loss_G: 0.9488\n",
      "[12/25][502/782] Loss_D: 1.1618 Loss_G: 0.8193\n",
      "[12/25][503/782] Loss_D: 1.2579 Loss_G: 4.3366\n",
      "[12/25][504/782] Loss_D: 2.6510 Loss_G: 0.1728\n",
      "[12/25][505/782] Loss_D: 2.7143 Loss_G: 3.8677\n",
      "[12/25][506/782] Loss_D: 0.8707 Loss_G: 2.7382\n",
      "[12/25][507/782] Loss_D: 0.9296 Loss_G: 1.3488\n",
      "[12/25][508/782] Loss_D: 0.8837 Loss_G: 1.8082\n",
      "[12/25][509/782] Loss_D: 0.9105 Loss_G: 2.3299\n",
      "[12/25][510/782] Loss_D: 0.8883 Loss_G: 1.9328\n",
      "[12/25][511/782] Loss_D: 0.9792 Loss_G: 1.3304\n",
      "[12/25][512/782] Loss_D: 1.0237 Loss_G: 2.4280\n",
      "[12/25][513/782] Loss_D: 0.9342 Loss_G: 0.9102\n",
      "[12/25][514/782] Loss_D: 1.6577 Loss_G: 3.8759\n",
      "[12/25][515/782] Loss_D: 1.6032 Loss_G: 0.7737\n",
      "[12/25][516/782] Loss_D: 0.9950 Loss_G: 3.5000\n",
      "[12/25][517/782] Loss_D: 1.0500 Loss_G: 1.5859\n",
      "[12/25][518/782] Loss_D: 0.9542 Loss_G: 2.8779\n",
      "[12/25][519/782] Loss_D: 0.6501 Loss_G: 1.9468\n",
      "[12/25][520/782] Loss_D: 1.1416 Loss_G: 3.1979\n",
      "[12/25][521/782] Loss_D: 1.0891 Loss_G: 1.6211\n",
      "[12/25][522/782] Loss_D: 0.7896 Loss_G: 2.8081\n"
     ]
    }
   ],
   "source": [
    "# Training the DCGANs\n",
    "\n",
    "criterion = nn.BCELoss() # binary cross entropy (for target either 0 or 1)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999)) # betas: coefficients used for computing averages of gradient and its square.\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999)) \n",
    "\n",
    "for epoch in range(25): \n",
    "\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "        ### Step 1 : Train D ###\n",
    "\n",
    "        netD.zero_grad() # Zero the gradients with respect to the weights.\n",
    "         \n",
    "        # Train D on real images\n",
    "        real, _ = data \n",
    "        input = Variable(real) # Wrap it in a variable.\n",
    "        target = Variable(torch.ones(input.size()[0])) # Train D on real data, so set the target to be 1 (real).\n",
    "        output = netD(input) # Output is bewteen 0 and 1.\n",
    "        errD_real = criterion(output, target) \n",
    "        \n",
    "        # Train D on fake images generated from G\n",
    "        noise = Variable(torch.randn(input.size()[0], 100, 1, 1)) # Random input vector (noise) of the G.\n",
    "        fake = netG(noise) # G generates some fake images.\n",
    "        target = Variable(torch.zeros(input.size()[0])) # Train D on fake data, so set the target to be 0 (fake).\n",
    "        output = netD(fake.detach()) # Output is between 0 and 1. `.detach()` to save memory.\n",
    "        errD_fake = criterion(output, target) \n",
    "\n",
    "        # Backpropagating the total error\n",
    "        errD = errD_real + errD_fake # Total error.\n",
    "        errD.backward() # Backpropagate the loss error.\n",
    "        optimizerD.step() # Optimizer to update the weights by SGD.\n",
    "\n",
    "        ### Step 2: Train G ###\n",
    "\n",
    "        netG.zero_grad() # Zero the gradients with respect to the weights.\n",
    "        target = Variable(torch.ones(input.size()[0])) # Create all 1 targets.\n",
    "        output = netD(fake) # Do not detach, we have to keep the gradients of fake images. \n",
    "        errG = criterion(output, target) \n",
    "        errG.backward() \n",
    "        optimizerG.step() \n",
    "        \n",
    "        ### 3rd Step: Printing and saving ###\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i, len(dataloader), errD.data, errG.data)) # Print losses of the D and G.\n",
    "        if i % 100 == 0: # Every 100 steps:\n",
    "            vutils.save_image(real, '%s/real_samples.png' % \".\", normalize = True) # Save the real images.\n",
    "            fake = netG(noise) # Get generated fake images.s\n",
    "            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\".\", epoch), normalize = True) # Save the generated fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wb5-gUS2p3ew"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGANs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1022b1f98fb04113adea5ee1c7ddb5d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51bb2203b2c8436985123397a5322832": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554a039878ac4cafb2d238a84d480910": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "747c99e7cd314117b69b5889a16f3c81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d5e4f090f534819a4c2fa72d821c5d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f4015d442564d5f8fdb86eddfdf4eab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97b883069dcc4d80a5200827a618cd82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1022b1f98fb04113adea5ee1c7ddb5d4",
      "placeholder": "",
      "style": "IPY_MODEL_747c99e7cd314117b69b5889a16f3c81",
      "value": ""
     }
    },
    "c4c02e6c5cc1442da5f82e4fe8437b14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d17b5d3c58d4486b80e97259d5745125",
      "placeholder": "",
      "style": "IPY_MODEL_554a039878ac4cafb2d238a84d480910",
      "value": " 170499072/? [00:02&lt;00:00, 65140381.29it/s]"
     }
    },
    "d17b5d3c58d4486b80e97259d5745125": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3516e3930da478386af4320927303a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f4015d442564d5f8fdb86eddfdf4eab",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d5e4f090f534819a4c2fa72d821c5d0",
      "value": 170498071
     }
    },
    "ed65e8ac6d314af8b4c4908c8a5d3e0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_97b883069dcc4d80a5200827a618cd82",
       "IPY_MODEL_d3516e3930da478386af4320927303a5",
       "IPY_MODEL_c4c02e6c5cc1442da5f82e4fe8437b14"
      ],
      "layout": "IPY_MODEL_51bb2203b2c8436985123397a5322832"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
